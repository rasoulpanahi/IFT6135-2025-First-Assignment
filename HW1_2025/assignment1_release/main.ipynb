{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTv0D26B9W2h"
      },
      "source": [
        "# Assignment 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "qFHMMDtSwuW4",
        "outputId": "10635b44-b6f4-4ea8-c307-7dc1cb5f3e12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#@title Mount your Google Drive\n",
        "# If you run this notebook locally or on a cluster (i.e. not on Google Colab)\n",
        "# you can delete this cell which is specific to Google Colab. You may also\n",
        "# change the paths for data/logs in Arguments below.\n",
        "%matplotlib inline\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir -p /content/gdrive/MyDrive/Projects\n",
        "# cd /content/gdrive/MyDrive/Projects"
      ],
      "metadata": {
        "id": "DG95nDHr7wAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!git pull origin main"
      ],
      "metadata": {
        "id": "sAGINWKVDYCl",
        "outputId": "88c65f29-8f49-4624-91b1-5e32f185d7f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects:  11% (1/9)\u001b[K\rremote: Counting objects:  22% (2/9)\u001b[K\rremote: Counting objects:  33% (3/9)\u001b[K\rremote: Counting objects:  44% (4/9)\u001b[K\rremote: Counting objects:  55% (5/9)\u001b[K\rremote: Counting objects:  66% (6/9)\u001b[K\rremote: Counting objects:  77% (7/9)\u001b[K\rremote: Counting objects:  88% (8/9)\u001b[K\rremote: Counting objects: 100% (9/9)\u001b[K\rremote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects:  50% (1/2)\u001b[K\rremote: Compressing objects: 100% (2/2)\u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 5 (delta 3), reused 5 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  20% (1/5)\rUnpacking objects:  40% (2/5)\rUnpacking objects:  60% (3/5)\rUnpacking objects:  80% (4/5)\rUnpacking objects: 100% (5/5)\rUnpacking objects: 100% (5/5), 573 bytes | 573.00 KiB/s, done.\n",
            "From https://github.com/rasoulpanahi/IFT6135-2025-First-Assignment\n",
            " * branch            main       -> FETCH_HEAD\n",
            "   f6a1506..6025346  main       -> origin/main\n",
            "Updating f6a1506..6025346\n",
            "Fast-forward\n",
            " HW1_2025/assignment1_release/utils.py | 5 \u001b[32m++++\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 4 insertions(+), 1 deletion(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rm -rf IFT6135-2025-First-Assignment\n",
        "\n",
        "# # Clone the repository again\n",
        "# git clone https://github.com/yourusername/yourrepository.git IFT6135-2025-First-Assignment"
      ],
      "metadata": {
        "id": "gUj3PqrEDMLk",
        "outputId": "b21b01ac-80b5-4246-a10f-0dab80c82348",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-29-36015c6d42f1>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-29-36015c6d42f1>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    rm -rf IFT6135-2025-First-Assignment\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rasoulpanahi/IFT6135-2025-First-Assignment.git"
      ],
      "metadata": {
        "id": "NiTDBWXW5FDU",
        "outputId": "8f05725b-c99f-4575-cf00-8e69e9cc594c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'IFT6135-2025-First-Assignment' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "oODLwt1QzgGa"
      },
      "outputs": [],
      "source": [
        "#@title Link your assignment folder & install requirements\n",
        "#@markdown Enter the path to the assignment folder in your Google Drive\n",
        "# If you run this notebook locally or on a cluster (i.e. not on Google Colab)\n",
        "# you can delete this cell which is specific to Google Colab. You may also\n",
        "# change the paths for data/logs in Arguments below.\n",
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "import warnings\n",
        "\n",
        "folder = \"/content/drive/MyDrive/Projects/IFT6135-2025-First-Assignment/HW1_2025/assignment1_release\" #@param {type:\"string\"}\n",
        "!ln -Ts \"$folder\" /content/assignment 2> /dev/null\n",
        "\n",
        "# Add the assignment folder to Python path\n",
        "if '/content/assignment' not in sys.path:\n",
        "  sys.path.insert(0, '/content/assignment')\n",
        "\n",
        "# Check if CUDA is available\n",
        "import torch\n",
        "if not torch.cuda.is_available():\n",
        "  warnings.warn('CUDA is not available.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "dt3NTvpsy4Oc"
      },
      "source": [
        "### Running on GPU\n",
        "For this assignment, it will be necessary to run your experiments on GPU. To make sure the notebook is running on GPU, you can change the notebook settings with\n",
        "* (EN) `Edit > Notebook Settings`\n",
        "* (FR) `Modifier > Param√®tres du notebook`\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%cd /content/IFT6135-2025-First-Assignment/HW1_2025/assignment1_release"
      ],
      "metadata": {
        "id": "WPP2E4iu6iD6",
        "outputId": "6291447b-cb0c-46de-afb8-65cad52fe5f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/IFT6135-2025-First-Assignment/HW1_2025/assignment1_release\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "RLVSmv9HoMH5"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import warnings\n",
        "\n",
        "from dataclasses import dataclass\n",
        "import torch\n",
        "from torch import optim\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "from utils import seed_experiment, to_device, cross_entropy_loss, compute_accuracy\n",
        "from config import get_config_parser\n",
        "import json\n",
        "from mlp import MLP\n",
        "from resnet18 import ResNet18\n",
        "from mlpmixer import MLPMixer\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZy1J-0OroLg"
      },
      "source": [
        "# Local Test\n",
        "Before run the experiment, here are some local test cases you can run for sanity check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "wLEVxwLlroLh",
        "outputId": "be67a132-1776-4f42-f3c3-274d37e72949",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 0 tests in 0.000s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.runner.TextTestResult run=0 errors=0 failures=0>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "import unittest\n",
        "import test\n",
        "suite = unittest.TestLoader().loadTestsFromModule(test)\n",
        "unittest.TextTestRunner(verbosity=2).run(suite)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PtvL_yKp3PW"
      },
      "source": [
        "## Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWiJme7XaLiR"
      },
      "source": [
        "Below we define a few default arguments to get you started with your experiments. You are encouraged to modify the function `main_entry()`, as well as these arguments, to fit your needs (e.g. changing hyperparameters, the optimizer, adding regularizations)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pwd"
      ],
      "metadata": {
        "id": "zNFDZUwOyk0A",
        "outputId": "2a757fdf-5208-42d1-9031-1f3b714050af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/IFT6135-2025-First-Assignment/HW1_2025/assignment1_release'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "YUrqebfCobD1"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Arguments:\n",
        "  # Data\n",
        "  batch_size: int = 128\n",
        "  # Model\n",
        "  model: str = 'mlp'  # [mlp, resnet18, mlpmixer]\n",
        "  model_config: str = \"./model_configs/mlp.json\" # path to model config json file\n",
        "\n",
        "  # Optimization\n",
        "  optimizer: str = 'adamw'  # [sgd, momentum, adam, adamw]\n",
        "  epochs: int = 15\n",
        "  lr: float = 1e-3\n",
        "  momentum: float = 0.9\n",
        "  weight_decay: float = 5e-4\n",
        "\n",
        "  # Experiment\n",
        "  logdir: str = '/content/assignment/logs'\n",
        "  seed: int = 42\n",
        "\n",
        "  # Miscellaneous\n",
        "  device: str = 'cuda'\n",
        "  visualize : bool = False\n",
        "  print_every: int = 80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "g2rjoY-5phTY"
      },
      "outputs": [],
      "source": [
        "# Main code entry. Train the model and save the logs\n",
        "from main import train, evaluate\n",
        "def main_entry(args):\n",
        "    # Check for the device\n",
        "    if (args.device == \"cuda\") and not torch.cuda.is_available():\n",
        "        warnings.warn(\n",
        "            \"CUDA is not available, make that your environment is \"\n",
        "            \"running on GPU (e.g. in the Notebook Settings in Google Colab). \"\n",
        "            'Forcing device=\"cpu\".'\n",
        "        )\n",
        "        args.device = \"cpu\"\n",
        "\n",
        "    if args.device == \"cpu\":\n",
        "        warnings.warn(\n",
        "            \"You are about to run on CPU, and might run out of memory \"\n",
        "            \"shortly. You can try setting batch_size=1 to reduce memory usage.\"\n",
        "        )\n",
        "\n",
        "    # Seed the experiment, for repeatability\n",
        "    seed_experiment(args.seed)\n",
        "\n",
        "    test_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                     transforms.Normalize([0.49139968, 0.48215841, 0.44653091], [0.24703223, 0.24348513, 0.26158784])\n",
        "                                     ])\n",
        "    # For training, we add some augmentation. Networks are too powerful and would overfit.\n",
        "    train_transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
        "                                          transforms.RandomResizedCrop((32,32),scale=(0.8,1.0),ratio=(0.9,1.1)),\n",
        "                                          transforms.ToTensor(),\n",
        "                                          transforms.Normalize([0.49139968, 0.48215841, 0.44653091], [0.24703223, 0.24348513, 0.26158784])\n",
        "                                        ])\n",
        "    # Loading the training dataset. We need to split it into a training and validation part\n",
        "    # We need to do a little trick because the validation set should not use the augmentation.\n",
        "    train_dataset = CIFAR10(root='./data', train=True, transform=train_transform, download=True)\n",
        "    val_dataset = CIFAR10(root='./data', train=True, transform=test_transform, download=True)\n",
        "    train_set, _ = torch.utils.data.random_split(train_dataset, [45000, 5000])\n",
        "    _, val_set = torch.utils.data.random_split(val_dataset, [45000, 5000])\n",
        "\n",
        "    # Loading the test set\n",
        "    test_set = CIFAR10(root='./data', train=False, transform=test_transform, download=True)\n",
        "\n",
        "    # Load model\n",
        "    print(f'Build model {args.model.upper()}...')\n",
        "    if args.model_config is not None:\n",
        "        print(f'Loading model config from {args.model_config}')\n",
        "        with open(args.model_config) as f:\n",
        "            model_config = json.load(f)\n",
        "    else:\n",
        "        raise ValueError('Please provide a model config json')\n",
        "    print(f'########## {args.model.upper()} CONFIG ################')\n",
        "    for key, val in model_config.items():\n",
        "        print(f'{key}:\\t{val}')\n",
        "    print('############################################')\n",
        "    model_cls = {'mlp': MLP, 'resnet18': ResNet18, 'mlpmixer': MLPMixer}[args.model]\n",
        "    model = model_cls(**model_config)\n",
        "    model.to(args.device)\n",
        "\n",
        "    # Optimizer\n",
        "    if args.optimizer == \"adamw\":\n",
        "        optimizer = optim.AdamW(\n",
        "            model.parameters(), lr=args.lr, weight_decay=args.weight_decay\n",
        "        )\n",
        "    elif args.optimizer == \"adam\":\n",
        "        optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
        "    elif args.optimizer == \"sgd\":\n",
        "        optimizer = optim.SGD(\n",
        "            model.parameters(), lr=args.lr, weight_decay=args.weight_decay\n",
        "        )\n",
        "    elif args.optimizer == \"momentum\":\n",
        "        optimizer = optim.SGD(\n",
        "            model.parameters(),\n",
        "            lr=args.lr,\n",
        "            momentum=args.momentum,\n",
        "            weight_decay=args.weight_decay,\n",
        "        )\n",
        "\n",
        "    print(\n",
        "        f\"Initialized {args.model.upper()} model with {sum(p.numel() for p in model.parameters())} \"\n",
        "        f\"total parameters, of which {sum(p.numel() for p in model.parameters() if p.requires_grad)} are learnable.\"\n",
        "    )\n",
        "\n",
        "    train_losses, valid_losses = [], []\n",
        "    train_accs, valid_accs = [], []\n",
        "    train_times, valid_times = [], []\n",
        "\n",
        "    # We define a set of data loaders that we can use for various purposes later.\n",
        "    train_dataloader = DataLoader(train_set, batch_size=args.batch_size, shuffle=True, drop_last=True, pin_memory=True, num_workers=4)\n",
        "    valid_dataloader = DataLoader(val_set, batch_size=args.batch_size, shuffle=False, drop_last=False, num_workers=4)\n",
        "    test_dataloader = DataLoader(test_set, batch_size=args.batch_size, shuffle=False, drop_last=False, num_workers=4)\n",
        "    for epoch in range(args.epochs):\n",
        "        tqdm.write(f\"====== Epoch {epoch} ======>\")\n",
        "        loss, acc, wall_time = train(epoch, model, train_dataloader, optimizer,args)\n",
        "        train_losses.append(loss)\n",
        "        train_accs.append(acc)\n",
        "        train_times.append(wall_time)\n",
        "\n",
        "        loss, acc, wall_time = evaluate(epoch, model, valid_dataloader,args)\n",
        "        valid_losses.append(loss)\n",
        "        valid_accs.append(acc)\n",
        "        valid_times.append(wall_time)\n",
        "\n",
        "    test_loss, test_acc, test_time = evaluate(\n",
        "        epoch, model, test_dataloader, args, mode=\"test\"\n",
        "    )\n",
        "    print(f\"===== Best validation Accuracy: {max(valid_accs):.3f} =====>\")\n",
        "\n",
        "    # Save log if logdir provided\n",
        "    if args.logdir is not None:\n",
        "        print(f'Writing training logs to {args.logdir}...')\n",
        "        os.makedirs(args.logdir, exist_ok=True)\n",
        "        with open(os.path.join(args.logdir, 'results.json'), 'w') as f:\n",
        "            f.write(json.dumps(\n",
        "                {\n",
        "                    \"train_losses\": train_losses,\n",
        "                    \"valid_losses\": valid_losses,\n",
        "                    \"train_accs\": train_accs,\n",
        "                    \"valid_accs\": valid_accs,\n",
        "                    \"test_loss\": test_loss,\n",
        "                    \"test_acc\": test_acc\n",
        "                },\n",
        "                indent=4,\n",
        "            ))\n",
        "\n",
        "        # Visualize\n",
        "        if args.visualize and args.model in ['resnet18', 'mlpmixer']:\n",
        "            model.visualize(args.logdir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "ZyJPWO1ppcTx",
        "outputId": "5e483b71-44ff-4e9e-896f-50207039371b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Build model MLP...\n",
            "Loading model config from /content/IFT6135-2025-First-Assignment/HW1_2025/assignment1_release/model_configs/mlp.json\n",
            "########## MLP CONFIG ################\n",
            "input_size:\t3072\n",
            "hidden_sizes:\t[1024, 512, 64, 64]\n",
            "num_classes:\t10\n",
            "activation:\trelu\n",
            "############################################\n",
            "Initialized MLP model with 3709194 total parameters, of which 3709194 are learnable.\n",
            "====== Epoch 0 ======>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN] Epoch: 0, Iter: 0, Loss: 2.61241\n",
            "[TRAIN] Epoch: 0, Iter: 80, Loss: 1.77236\n",
            "[TRAIN] Epoch: 0, Iter: 160, Loss: 1.74864\n",
            "[TRAIN] Epoch: 0, Iter: 240, Loss: 1.54849\n",
            "[TRAIN] Epoch: 0, Iter: 320, Loss: 1.66133\n",
            "== [TRAIN] Epoch: 0, Accuracy: 0.358 ==>\n",
            "[VAL] Epoch: 0, Iter: 0, Loss: 1.69828\n",
            "=== [VAL] Epoch: 0, Iter: 39, Accuracy: 0.413 ===>\n",
            "====== Epoch 1 ======>\n",
            "[TRAIN] Epoch: 1, Iter: 0, Loss: 1.72243\n",
            "[TRAIN] Epoch: 1, Iter: 80, Loss: 1.56231\n",
            "[TRAIN] Epoch: 1, Iter: 160, Loss: 1.62889\n",
            "[TRAIN] Epoch: 1, Iter: 240, Loss: 1.76265\n",
            "[TRAIN] Epoch: 1, Iter: 320, Loss: 1.73134\n",
            "== [TRAIN] Epoch: 1, Accuracy: 0.430 ==>\n",
            "[VAL] Epoch: 1, Iter: 0, Loss: 1.57578\n",
            "=== [VAL] Epoch: 1, Iter: 39, Accuracy: 0.471 ===>\n",
            "====== Epoch 2 ======>\n",
            "[TRAIN] Epoch: 2, Iter: 0, Loss: 1.62931\n",
            "[TRAIN] Epoch: 2, Iter: 80, Loss: 1.73353\n",
            "[TRAIN] Epoch: 2, Iter: 160, Loss: 1.56528\n",
            "[TRAIN] Epoch: 2, Iter: 240, Loss: 1.48135\n",
            "[TRAIN] Epoch: 2, Iter: 320, Loss: 1.47238\n",
            "== [TRAIN] Epoch: 2, Accuracy: 0.458 ==>\n",
            "[VAL] Epoch: 2, Iter: 0, Loss: 1.52025\n",
            "=== [VAL] Epoch: 2, Iter: 39, Accuracy: 0.472 ===>\n",
            "====== Epoch 3 ======>\n",
            "[TRAIN] Epoch: 3, Iter: 0, Loss: 1.54703\n",
            "[TRAIN] Epoch: 3, Iter: 80, Loss: 1.48833\n",
            "[TRAIN] Epoch: 3, Iter: 160, Loss: 1.48759\n",
            "[TRAIN] Epoch: 3, Iter: 240, Loss: 1.35100\n",
            "[TRAIN] Epoch: 3, Iter: 320, Loss: 1.27538\n",
            "== [TRAIN] Epoch: 3, Accuracy: 0.481 ==>\n",
            "[VAL] Epoch: 3, Iter: 0, Loss: 1.50226\n",
            "=== [VAL] Epoch: 3, Iter: 39, Accuracy: 0.498 ===>\n",
            "====== Epoch 4 ======>\n",
            "[TRAIN] Epoch: 4, Iter: 0, Loss: 1.32552\n",
            "[TRAIN] Epoch: 4, Iter: 80, Loss: 1.47739\n",
            "[TRAIN] Epoch: 4, Iter: 160, Loss: 1.48174\n",
            "[TRAIN] Epoch: 4, Iter: 240, Loss: 1.46175\n",
            "[TRAIN] Epoch: 4, Iter: 320, Loss: 1.31292\n",
            "== [TRAIN] Epoch: 4, Accuracy: 0.499 ==>\n",
            "[VAL] Epoch: 4, Iter: 0, Loss: 1.36982\n",
            "=== [VAL] Epoch: 4, Iter: 39, Accuracy: 0.533 ===>\n",
            "====== Epoch 5 ======>\n",
            "[TRAIN] Epoch: 5, Iter: 0, Loss: 1.36681\n",
            "[TRAIN] Epoch: 5, Iter: 80, Loss: 1.29882\n",
            "[TRAIN] Epoch: 5, Iter: 160, Loss: 1.50413\n",
            "[TRAIN] Epoch: 5, Iter: 240, Loss: 1.49167\n",
            "[TRAIN] Epoch: 5, Iter: 320, Loss: 1.27725\n",
            "== [TRAIN] Epoch: 5, Accuracy: 0.514 ==>\n",
            "[VAL] Epoch: 5, Iter: 0, Loss: 1.39981\n",
            "=== [VAL] Epoch: 5, Iter: 39, Accuracy: 0.541 ===>\n",
            "====== Epoch 6 ======>\n",
            "[TRAIN] Epoch: 6, Iter: 0, Loss: 1.21998\n",
            "[TRAIN] Epoch: 6, Iter: 80, Loss: 1.12752\n",
            "[TRAIN] Epoch: 6, Iter: 160, Loss: 1.49317\n",
            "[TRAIN] Epoch: 6, Iter: 240, Loss: 1.37791\n",
            "[TRAIN] Epoch: 6, Iter: 320, Loss: 1.41642\n",
            "== [TRAIN] Epoch: 6, Accuracy: 0.528 ==>\n",
            "[VAL] Epoch: 6, Iter: 0, Loss: 1.31052\n",
            "=== [VAL] Epoch: 6, Iter: 39, Accuracy: 0.563 ===>\n",
            "====== Epoch 7 ======>\n",
            "[TRAIN] Epoch: 7, Iter: 0, Loss: 1.26710\n",
            "[TRAIN] Epoch: 7, Iter: 80, Loss: 1.25233\n",
            "[TRAIN] Epoch: 7, Iter: 160, Loss: 1.18205\n",
            "[TRAIN] Epoch: 7, Iter: 240, Loss: 1.40879\n",
            "[TRAIN] Epoch: 7, Iter: 320, Loss: 1.29530\n",
            "== [TRAIN] Epoch: 7, Accuracy: 0.537 ==>\n",
            "[VAL] Epoch: 7, Iter: 0, Loss: 1.21707\n",
            "=== [VAL] Epoch: 7, Iter: 39, Accuracy: 0.572 ===>\n",
            "====== Epoch 8 ======>\n",
            "[TRAIN] Epoch: 8, Iter: 0, Loss: 1.25683\n",
            "[TRAIN] Epoch: 8, Iter: 80, Loss: 1.31159\n",
            "[TRAIN] Epoch: 8, Iter: 160, Loss: 1.21264\n",
            "[TRAIN] Epoch: 8, Iter: 240, Loss: 1.29346\n",
            "[TRAIN] Epoch: 8, Iter: 320, Loss: 1.16549\n",
            "== [TRAIN] Epoch: 8, Accuracy: 0.546 ==>\n",
            "[VAL] Epoch: 8, Iter: 0, Loss: 1.23201\n",
            "=== [VAL] Epoch: 8, Iter: 39, Accuracy: 0.565 ===>\n",
            "====== Epoch 9 ======>\n",
            "[TRAIN] Epoch: 9, Iter: 0, Loss: 1.12786\n",
            "[TRAIN] Epoch: 9, Iter: 80, Loss: 1.04630\n",
            "[TRAIN] Epoch: 9, Iter: 160, Loss: 1.29415\n",
            "[TRAIN] Epoch: 9, Iter: 240, Loss: 1.18602\n",
            "[TRAIN] Epoch: 9, Iter: 320, Loss: 1.18782\n",
            "== [TRAIN] Epoch: 9, Accuracy: 0.556 ==>\n",
            "[VAL] Epoch: 9, Iter: 0, Loss: 1.30753\n",
            "=== [VAL] Epoch: 9, Iter: 39, Accuracy: 0.590 ===>\n",
            "[TEST] Epoch: 9, Iter: 0, Loss: 1.28711\n",
            "=== [TEST] Epoch: 9, Iter: 78, Accuracy: 0.546 ===>\n",
            "===== Best validation Accuracy: 0.590 =====>\n",
            "Writing training logs to exps/mlp_default...\n"
          ]
        }
      ],
      "source": [
        "# Example to run MLP with 15 epochs\n",
        "config = Arguments(model='mlp',\n",
        "                   model_config='/content/IFT6135-2025-First-Assignment/HW1_2025/assignment1_release/model_configs/mlp.json',\n",
        "                   epochs=10, logdir=\"exps/mlp_default\")\n",
        "main_entry(config)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2 (default, Feb 26 2020, 14:31:49) \n[GCC 6.3.0 20170516]"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "vscode": {
      "interpreter": {
        "hash": "81c564fb939afe7b3f114d194e01dc23538f9aaa81b9a9b61cd5d8751a87bdce"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}