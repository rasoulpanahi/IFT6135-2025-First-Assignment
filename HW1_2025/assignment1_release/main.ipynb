{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTv0D26B9W2h"
      },
      "source": [
        "# Assignment 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qFHMMDtSwuW4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95978ebb-effa-4767-d51b-850fec7c7f33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#@title Mount your Google Drive\n",
        "# If you run this notebook locally or on a cluster (i.e. not on Google Colab)\n",
        "# you can delete this cell which is specific to Google Colab. You may also\n",
        "# change the paths for data/logs in Arguments below.\n",
        "%matplotlib inline\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir -p /content/gdrive/MyDrive/Projects\n",
        "# cd /content/gdrive/MyDrive/Projects"
      ],
      "metadata": {
        "id": "DG95nDHr7wAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!git pull origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAGINWKVDYCl",
        "outputId": "47af0b74-1366-4123-d0b0-90dda0d7fc75"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects:  11% (1/9)\u001b[K\rremote: Counting objects:  22% (2/9)\u001b[K\rremote: Counting objects:  33% (3/9)\u001b[K\rremote: Counting objects:  44% (4/9)\u001b[K\rremote: Counting objects:  55% (5/9)\u001b[K\rremote: Counting objects:  66% (6/9)\u001b[K\rremote: Counting objects:  77% (7/9)\u001b[K\rremote: Counting objects:  88% (8/9)\u001b[K\rremote: Counting objects: 100% (9/9)\u001b[K\rremote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects:  50% (1/2)\u001b[K\rremote: Compressing objects: 100% (2/2)\u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 5 (delta 3), reused 5 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  20% (1/5)\rUnpacking objects:  40% (2/5)\rUnpacking objects:  60% (3/5)\rUnpacking objects:  80% (4/5)\rUnpacking objects: 100% (5/5)\rUnpacking objects: 100% (5/5), 552 bytes | 552.00 KiB/s, done.\n",
            "From https://github.com/rasoulpanahi/IFT6135-2025-First-Assignment\n",
            " * branch            main       -> FETCH_HEAD\n",
            "   a9d0357..7667e2a  main       -> origin/main\n",
            "Updating a9d0357..7667e2a\n",
            "Fast-forward\n",
            " HW1_2025/assignment1_release/mlpmixer.py | 4 \u001b[32m+++\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 3 insertions(+), 1 deletion(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rm -rf IFT6135-2025-First-Assignment\n",
        "\n",
        "# # Clone the repository again\n",
        "!git clone https://github.com/rasoulpanahi/IFT6135-2025-First-Assignment.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUj3PqrEDMLk",
        "outputId": "524ad358-8686-4c4c-dd94-aa08f86f7ce6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'IFT6135-2025-First-Assignment'...\n",
            "remote: Enumerating objects: 59, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
            "remote: Total 59 (delta 23), reused 53 (delta 20), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (59/59), 420.38 KiB | 1.69 MiB/s, done.\n",
            "Resolving deltas: 100% (23/23), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!git clone https://github.com/rasoulpanahi/IFT6135-2025-First-Assignment.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiTDBWXW5FDU",
        "outputId": "8f05725b-c99f-4575-cf00-8e69e9cc594c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'IFT6135-2025-First-Assignment' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "oODLwt1QzgGa"
      },
      "outputs": [],
      "source": [
        "#@title Link your assignment folder & install requirements\n",
        "#@markdown Enter the path to the assignment folder in your Google Drive\n",
        "# If you run this notebook locally or on a cluster (i.e. not on Google Colab)\n",
        "# you can delete this cell which is specific to Google Colab. You may also\n",
        "# change the paths for data/logs in Arguments below.\n",
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "import warnings\n",
        "\n",
        "folder = \"/content/drive/MyDrive/Projects/IFT6135-2025-First-Assignment/HW1_2025/assignment1_release\" #@param {type:\"string\"}\n",
        "!ln -Ts \"$folder\" /content/assignment 2> /dev/null\n",
        "\n",
        "# Add the assignment folder to Python path\n",
        "if '/content/assignment' not in sys.path:\n",
        "  sys.path.insert(0, '/content/assignment')\n",
        "\n",
        "# Check if CUDA is available\n",
        "import torch\n",
        "if not torch.cuda.is_available():\n",
        "  warnings.warn('CUDA is not available.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "dt3NTvpsy4Oc"
      },
      "source": [
        "### Running on GPU\n",
        "For this assignment, it will be necessary to run your experiments on GPU. To make sure the notebook is running on GPU, you can change the notebook settings with\n",
        "* (EN) `Edit > Notebook Settings`\n",
        "* (FR) `Modifier > Param√®tres du notebook`\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NfmKYOPkSkRx",
        "outputId": "4d70bf7a-7e51-49e3-f2b6-7c9c3c49e0d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assignment  gdrive  IFT6135-2025-First-Assignment  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%cd /content/IFT6135-2025-First-Assignment/HW1_2025/assignment1_release"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPP2E4iu6iD6",
        "outputId": "8373d525-9a30-4e95-f74b-29d745651978"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/IFT6135-2025-First-Assignment/HW1_2025/assignment1_release\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "RLVSmv9HoMH5"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import warnings\n",
        "\n",
        "from dataclasses import dataclass\n",
        "import torch\n",
        "from torch import optim\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "from utils import seed_experiment, to_device, cross_entropy_loss, compute_accuracy\n",
        "from config import get_config_parser\n",
        "import json\n",
        "from mlp import MLP\n",
        "from resnet18 import ResNet18\n",
        "from mlpmixer import MLPMixer\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZy1J-0OroLg"
      },
      "source": [
        "# Local Test\n",
        "Before run the experiment, here are some local test cases you can run for sanity check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "wLEVxwLlroLh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a6e7355-d44b-4a4a-e506-eaca56ec208d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 0 tests in 0.000s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.runner.TextTestResult run=0 errors=0 failures=0>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "import unittest\n",
        "import test\n",
        "suite = unittest.TestLoader().loadTestsFromModule(test)\n",
        "unittest.TextTestRunner(verbosity=2).run(suite)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PtvL_yKp3PW"
      },
      "source": [
        "## Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWiJme7XaLiR"
      },
      "source": [
        "Below we define a few default arguments to get you started with your experiments. You are encouraged to modify the function `main_entry()`, as well as these arguments, to fit your needs (e.g. changing hyperparameters, the optimizer, adding regularizations)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "YUrqebfCobD1"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Arguments:\n",
        "  # Data\n",
        "  batch_size: int = 128\n",
        "  # Model\n",
        "  model: str = 'mlp'  # [mlp, resnet18, mlpmixer]\n",
        "  model_config: str = \"./model_configs/mlp.json\" # path to model config json file\n",
        "\n",
        "  # Optimization\n",
        "  optimizer: str = 'adamw'  # [sgd, momentum, adam, adamw]\n",
        "  epochs: int = 15\n",
        "  lr: float = 1e-3\n",
        "  momentum: float = 0.9\n",
        "  weight_decay: float = 5e-4\n",
        "\n",
        "  # Experiment\n",
        "  logdir: str = '/content/assignment/logs'\n",
        "  seed: int = 42\n",
        "\n",
        "  # Miscellaneous\n",
        "  device: str = 'cuda'\n",
        "  visualize : bool = False\n",
        "  print_every: int = 80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "g2rjoY-5phTY"
      },
      "outputs": [],
      "source": [
        "# Main code entry. Train the model and save the logs\n",
        "from main import train, evaluate\n",
        "def main_entry(args):\n",
        "    # Check for the device\n",
        "    if (args.device == \"cuda\") and not torch.cuda.is_available():\n",
        "        warnings.warn(\n",
        "            \"CUDA is not available, make that your environment is \"\n",
        "            \"running on GPU (e.g. in the Notebook Settings in Google Colab). \"\n",
        "            'Forcing device=\"cpu\".'\n",
        "        )\n",
        "        args.device = \"cpu\"\n",
        "\n",
        "    if args.device == \"cpu\":\n",
        "        warnings.warn(\n",
        "            \"You are about to run on CPU, and might run out of memory \"\n",
        "            \"shortly. You can try setting batch_size=1 to reduce memory usage.\"\n",
        "        )\n",
        "\n",
        "    # Seed the experiment, for repeatability\n",
        "    seed_experiment(args.seed)\n",
        "\n",
        "    test_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                     transforms.Normalize([0.49139968, 0.48215841, 0.44653091], [0.24703223, 0.24348513, 0.26158784])\n",
        "                                     ])\n",
        "    # For training, we add some augmentation. Networks are too powerful and would overfit.\n",
        "    train_transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
        "                                          transforms.RandomResizedCrop((32,32),scale=(0.8,1.0),ratio=(0.9,1.1)),\n",
        "                                          transforms.ToTensor(),\n",
        "                                          transforms.Normalize([0.49139968, 0.48215841, 0.44653091], [0.24703223, 0.24348513, 0.26158784])\n",
        "                                        ])\n",
        "    # Loading the training dataset. We need to split it into a training and validation part\n",
        "    # We need to do a little trick because the validation set should not use the augmentation.\n",
        "    train_dataset = CIFAR10(root='./data', train=True, transform=train_transform, download=True)\n",
        "    val_dataset = CIFAR10(root='./data', train=True, transform=test_transform, download=True)\n",
        "    train_set, _ = torch.utils.data.random_split(train_dataset, [45000, 5000])\n",
        "    _, val_set = torch.utils.data.random_split(val_dataset, [45000, 5000])\n",
        "\n",
        "    # Loading the test set\n",
        "    test_set = CIFAR10(root='./data', train=False, transform=test_transform, download=True)\n",
        "\n",
        "    # Load model\n",
        "    print(f'Build model {args.model.upper()}...')\n",
        "    if args.model_config is not None:\n",
        "        print(f'Loading model config from {args.model_config}')\n",
        "        with open(args.model_config) as f:\n",
        "            model_config = json.load(f)\n",
        "    else:\n",
        "        raise ValueError('Please provide a model config json')\n",
        "    print(f'########## {args.model.upper()} CONFIG ################')\n",
        "    for key, val in model_config.items():\n",
        "        print(f'{key}:\\t{val}')\n",
        "    print('############################################')\n",
        "    model_cls = {'mlp': MLP, 'resnet18': ResNet18, 'mlpmixer': MLPMixer}[args.model]\n",
        "    model = model_cls(**model_config)\n",
        "    model.to(args.device)\n",
        "\n",
        "    # Optimizer\n",
        "    if args.optimizer == \"adamw\":\n",
        "        optimizer = optim.AdamW(\n",
        "            model.parameters(), lr=args.lr, weight_decay=args.weight_decay\n",
        "        )\n",
        "    elif args.optimizer == \"adam\":\n",
        "        optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
        "    elif args.optimizer == \"sgd\":\n",
        "        optimizer = optim.SGD(\n",
        "            model.parameters(), lr=args.lr, weight_decay=args.weight_decay\n",
        "        )\n",
        "    elif args.optimizer == \"momentum\":\n",
        "        optimizer = optim.SGD(\n",
        "            model.parameters(),\n",
        "            lr=args.lr,\n",
        "            momentum=args.momentum,\n",
        "            weight_decay=args.weight_decay,\n",
        "        )\n",
        "\n",
        "    print(\n",
        "        f\"Initialized {args.model.upper()} model with {sum(p.numel() for p in model.parameters())} \"\n",
        "        f\"total parameters, of which {sum(p.numel() for p in model.parameters() if p.requires_grad)} are learnable.\"\n",
        "    )\n",
        "\n",
        "    train_losses, valid_losses = [], []\n",
        "    train_accs, valid_accs = [], []\n",
        "    train_times, valid_times = [], []\n",
        "\n",
        "    # We define a set of data loaders that we can use for various purposes later.\n",
        "    train_dataloader = DataLoader(train_set, batch_size=args.batch_size, shuffle=True, drop_last=True, pin_memory=True, num_workers=4)\n",
        "    valid_dataloader = DataLoader(val_set, batch_size=args.batch_size, shuffle=False, drop_last=False, num_workers=4)\n",
        "    test_dataloader = DataLoader(test_set, batch_size=args.batch_size, shuffle=False, drop_last=False, num_workers=4)\n",
        "    for epoch in range(args.epochs):\n",
        "        tqdm.write(f\"====== Epoch {epoch} ======>\")\n",
        "        loss, acc, wall_time = train(epoch, model, train_dataloader, optimizer,args)\n",
        "        train_losses.append(loss)\n",
        "        train_accs.append(acc)\n",
        "        train_times.append(wall_time)\n",
        "\n",
        "        loss, acc, wall_time = evaluate(epoch, model, valid_dataloader,args)\n",
        "        valid_losses.append(loss)\n",
        "        valid_accs.append(acc)\n",
        "        valid_times.append(wall_time)\n",
        "\n",
        "    test_loss, test_acc, test_time = evaluate(\n",
        "        epoch, model, test_dataloader, args, mode=\"test\"\n",
        "    )\n",
        "    print(f\"===== Best validation Accuracy: {max(valid_accs):.3f} =====>\")\n",
        "\n",
        "    # Save log if logdir provided\n",
        "    if args.logdir is not None:\n",
        "        print(f'Writing training logs to {args.logdir}...')\n",
        "        os.makedirs(args.logdir, exist_ok=True)\n",
        "        with open(os.path.join(args.logdir, 'results.json'), 'w') as f:\n",
        "            f.write(json.dumps(\n",
        "                {\n",
        "                    \"train_losses\": train_losses,\n",
        "                    \"valid_losses\": valid_losses,\n",
        "                    \"train_accs\": train_accs,\n",
        "                    \"valid_accs\": valid_accs,\n",
        "                    \"test_loss\": test_loss,\n",
        "                    \"test_acc\": test_acc\n",
        "                },\n",
        "                indent=4,\n",
        "            ))\n",
        "\n",
        "        # Visualize\n",
        "        if args.visualize and args.model in ['resnet18', 'mlpmixer']:\n",
        "            model.visualize(args.logdir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ZyJPWO1ppcTx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86890e6f-c5ea-4e23-e995-67fe1efc3512"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 170M/170M [00:06<00:00, 25.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Build model MLP...\n",
            "Loading model config from /content/IFT6135-2025-First-Assignment/HW1_2025/assignment1_release/model_configs/mlp.json\n",
            "########## MLP CONFIG ################\n",
            "input_size:\t3072\n",
            "hidden_sizes:\t[1024, 512, 64, 64]\n",
            "num_classes:\t10\n",
            "activation:\trelu\n",
            "############################################\n",
            "Initialized MLP model with 3709194 total parameters, of which 3709194 are learnable.\n",
            "====== Epoch 0 ======>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN] Epoch: 0, Iter: 0, Loss: 2.61241\n",
            "[TRAIN] Epoch: 0, Iter: 80, Loss: 1.77236\n",
            "[TRAIN] Epoch: 0, Iter: 160, Loss: 1.74864\n",
            "[TRAIN] Epoch: 0, Iter: 240, Loss: 1.54849\n",
            "[TRAIN] Epoch: 0, Iter: 320, Loss: 1.66133\n",
            "== [TRAIN] Epoch: 0, Accuracy: 0.358 ==>\n",
            "[VAL] Epoch: 0, Iter: 0, Loss: 1.69828\n",
            "=== [VAL] Epoch: 0, Iter: 39, Accuracy: 0.413 ===>\n",
            "====== Epoch 1 ======>\n",
            "[TRAIN] Epoch: 1, Iter: 0, Loss: 1.72243\n",
            "[TRAIN] Epoch: 1, Iter: 80, Loss: 1.56231\n",
            "[TRAIN] Epoch: 1, Iter: 160, Loss: 1.62889\n",
            "[TRAIN] Epoch: 1, Iter: 240, Loss: 1.76265\n",
            "[TRAIN] Epoch: 1, Iter: 320, Loss: 1.73134\n",
            "== [TRAIN] Epoch: 1, Accuracy: 0.430 ==>\n",
            "[VAL] Epoch: 1, Iter: 0, Loss: 1.57578\n",
            "=== [VAL] Epoch: 1, Iter: 39, Accuracy: 0.471 ===>\n",
            "[TEST] Epoch: 1, Iter: 0, Loss: 1.37968\n",
            "=== [TEST] Epoch: 1, Iter: 78, Accuracy: 0.461 ===>\n",
            "===== Best validation Accuracy: 0.471 =====>\n",
            "Writing training logs to exps/mlp_default...\n"
          ]
        }
      ],
      "source": [
        "# Example to run MLP with 15 epochs\n",
        "config = Arguments(model='mlp',\n",
        "                   model_config='/content/IFT6135-2025-First-Assignment/HW1_2025/assignment1_release/model_configs/mlp.json',\n",
        "                   epochs=2, logdir=\"exps/mlp_default\")\n",
        "main_entry(config)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example to run MLP with 15 epochs\n",
        "config = Arguments(model='resnet18',\n",
        "                   model_config='/content/IFT6135-2025-First-Assignment/HW1_2025/assignment1_release/model_configs/resnet18.json',\n",
        "                   epochs=2, logdir=\"exps/resnet18\")\n",
        "main_entry(config)"
      ],
      "metadata": {
        "id": "h7N_mG0UUDcr",
        "outputId": "b53b7c39-3cee-46fa-8ad3-b6d4337c0fd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Build model RESNET18...\n",
            "Loading model config from /content/IFT6135-2025-First-Assignment/HW1_2025/assignment1_release/model_configs/resnet18.json\n",
            "########## RESNET18 CONFIG ################\n",
            "num_classes:\t10\n",
            "############################################\n",
            "Initialized RESNET18 model with 11173962 total parameters, of which 11173962 are learnable.\n",
            "====== Epoch 0 ======>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN] Epoch: 0, Iter: 0, Loss: 2.35414\n",
            "[TRAIN] Epoch: 0, Iter: 80, Loss: 1.51107\n",
            "[TRAIN] Epoch: 0, Iter: 160, Loss: 1.43727\n",
            "[TRAIN] Epoch: 0, Iter: 240, Loss: 1.30898\n",
            "[TRAIN] Epoch: 0, Iter: 320, Loss: 1.21086\n",
            "== [TRAIN] Epoch: 0, Accuracy: 0.473 ==>\n",
            "[VAL] Epoch: 0, Iter: 0, Loss: 1.41436\n",
            "=== [VAL] Epoch: 0, Iter: 39, Accuracy: 0.570 ===>\n",
            "====== Epoch 1 ======>\n",
            "[TRAIN] Epoch: 1, Iter: 0, Loss: 1.03957\n",
            "[TRAIN] Epoch: 1, Iter: 80, Loss: 1.02246\n",
            "[TRAIN] Epoch: 1, Iter: 160, Loss: 0.96548\n",
            "[TRAIN] Epoch: 1, Iter: 240, Loss: 0.92622\n",
            "[TRAIN] Epoch: 1, Iter: 320, Loss: 0.76036\n",
            "== [TRAIN] Epoch: 1, Accuracy: 0.657 ==>\n",
            "[VAL] Epoch: 1, Iter: 0, Loss: 0.92165\n",
            "=== [VAL] Epoch: 1, Iter: 39, Accuracy: 0.671 ===>\n",
            "[TEST] Epoch: 1, Iter: 0, Loss: 0.88246\n",
            "=== [TEST] Epoch: 1, Iter: 78, Accuracy: 0.655 ===>\n",
            "===== Best validation Accuracy: 0.671 =====>\n",
            "Writing training logs to exps/resnet18...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example to run MLP with 15 epochs\n",
        "config = Arguments(model='mlpmixer',\n",
        "                   model_config='/content/IFT6135-2025-First-Assignment/HW1_2025/assignment1_release/model_configs/mlpmixer.json',\n",
        "                   epochs=2, logdir=\"exps/mlpmixer\")\n",
        "main_entry(config)"
      ],
      "metadata": {
        "id": "LNCWBaethidT",
        "outputId": "bc0dfbc7-dd25-41ea-e81a-fc357b46fbf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Build model MLPMIXER...\n",
            "Loading model config from /content/IFT6135-2025-First-Assignment/HW1_2025/assignment1_release/model_configs/mlpmixer.json\n",
            "########## MLPMIXER CONFIG ################\n",
            "num_classes:\t10\n",
            "img_size:\t32\n",
            "patch_size:\t4\n",
            "embed_dim:\t256\n",
            "num_blocks:\t4\n",
            "drop_rate:\t0.0\n",
            "activation:\tgelu\n",
            "############################################\n",
            "Initialized MLPMIXER model with 2188298 total parameters, of which 2188298 are learnable.\n",
            "====== Epoch 0 ======>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN] Epoch: 0, Iter: 0, Loss: 2.31901\n",
            "[TRAIN] Epoch: 0, Iter: 80, Loss: 1.57623\n",
            "[TRAIN] Epoch: 0, Iter: 160, Loss: 1.61766\n",
            "[TRAIN] Epoch: 0, Iter: 240, Loss: 1.41238\n",
            "[TRAIN] Epoch: 0, Iter: 320, Loss: 1.47204\n",
            "== [TRAIN] Epoch: 0, Accuracy: 0.421 ==>\n",
            "[VAL] Epoch: 0, Iter: 0, Loss: 1.39669\n",
            "=== [VAL] Epoch: 0, Iter: 39, Accuracy: 0.522 ===>\n",
            "====== Epoch 1 ======>\n",
            "[TRAIN] Epoch: 1, Iter: 0, Loss: 1.21684\n",
            "[TRAIN] Epoch: 1, Iter: 80, Loss: 1.32808\n",
            "[TRAIN] Epoch: 1, Iter: 160, Loss: 1.19022\n",
            "[TRAIN] Epoch: 1, Iter: 240, Loss: 1.21163\n",
            "[TRAIN] Epoch: 1, Iter: 320, Loss: 1.03568\n",
            "== [TRAIN] Epoch: 1, Accuracy: 0.561 ==>\n",
            "[VAL] Epoch: 1, Iter: 0, Loss: 1.21091\n",
            "=== [VAL] Epoch: 1, Iter: 39, Accuracy: 0.610 ===>\n",
            "[TEST] Epoch: 1, Iter: 0, Loss: 1.00693\n",
            "=== [TEST] Epoch: 1, Iter: 78, Accuracy: 0.599 ===>\n",
            "===== Best validation Accuracy: 0.610 =====>\n",
            "Writing training logs to exps/mlpmixer...\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2 (default, Feb 26 2020, 14:31:49) \n[GCC 6.3.0 20170516]"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "vscode": {
      "interpreter": {
        "hash": "81c564fb939afe7b3f114d194e01dc23538f9aaa81b9a9b61cd5d8751a87bdce"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}