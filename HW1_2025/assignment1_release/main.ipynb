{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTv0D26B9W2h"
      },
      "source": [
        "# Assignment 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qFHMMDtSwuW4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86836b6d-f081-4477-e919-d8df5e2436bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#@title Mount your Google Drive\n",
        "# If you run this notebook locally or on a cluster (i.e. not on Google Colab)\n",
        "# you can delete this cell which is specific to Google Colab. You may also\n",
        "# change the paths for data/logs in Arguments below.\n",
        "%matplotlib inline\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/gdrive/MyDrive/Projects\n",
        "# cd /content/gdrive/MyDrive/Projects"
      ],
      "metadata": {
        "id": "DG95nDHr7wAC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!git pull origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAGINWKVDYCl",
        "outputId": "1b229824-f024-4612-defb-d5647651fbcc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rm -rf IFT6135-2025-First-Assignment\n",
        "\n",
        "# # Clone the repository again\n",
        "!git clone https://github.com/rasoulpanahi/IFT6135-2025-First-Assignment.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUj3PqrEDMLk",
        "outputId": "7e145707-36f9-4df5-d133-c8b9141a0881"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'IFT6135-2025-First-Assignment'...\n",
            "remote: Enumerating objects: 102, done.\u001b[K\n",
            "remote: Counting objects: 100% (102/102), done.\u001b[K\n",
            "remote: Compressing objects: 100% (62/62), done.\u001b[K\n",
            "remote: Total 102 (delta 49), reused 79 (delta 35), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (102/102), 427.08 KiB | 1.70 MiB/s, done.\n",
            "Resolving deltas: 100% (49/49), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!git clone https://github.com/rasoulpanahi/IFT6135-2025-First-Assignment.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiTDBWXW5FDU",
        "outputId": "8f05725b-c99f-4575-cf00-8e69e9cc594c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'IFT6135-2025-First-Assignment' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3WfO1DYtp3m",
        "outputId": "56b9fac6-f361-4154-cb3d-f08b08b6962c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gdrive\tIFT6135-2025-First-Assignment  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oODLwt1QzgGa"
      },
      "outputs": [],
      "source": [
        "#@title Link your assignment folder & install requirements\n",
        "#@markdown Enter the path to the assignment folder in your Google Drive\n",
        "# If you run this notebook locally or on a cluster (i.e. not on Google Colab)\n",
        "# you can delete this cell which is specific to Google Colab. You may also\n",
        "# change the paths for data/logs in Arguments below.\n",
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "import warnings\n",
        "\n",
        "folder = \"/content/drive/MyDrive/Projects/IFT6135-2025-First-Assignment/HW1_2025/assignment1_release\" #@param {type:\"string\"}\n",
        "!ln -Ts \"$folder\" /content/assignment 2> /dev/null\n",
        "\n",
        "# Add the assignment folder to Python path\n",
        "if '/content/assignment' not in sys.path:\n",
        "  sys.path.insert(0, '/content/assignment')\n",
        "\n",
        "# Check if CUDA is available\n",
        "import torch\n",
        "if not torch.cuda.is_available():\n",
        "  warnings.warn('CUDA is not available.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "dt3NTvpsy4Oc"
      },
      "source": [
        "### Running on GPU\n",
        "For this assignment, it will be necessary to run your experiments on GPU. To make sure the notebook is running on GPU, you can change the notebook settings with\n",
        "* (EN) `Edit > Notebook Settings`\n",
        "* (FR) `Modifier > Param√®tres du notebook`\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfmKYOPkSkRx",
        "outputId": "4d70bf7a-7e51-49e3-f2b6-7c9c3c49e0d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assignment  gdrive  IFT6135-2025-First-Assignment  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%cd /content/IFT6135-2025-First-Assignment/HW1_2025/assignment1_release"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPP2E4iu6iD6",
        "outputId": "ebab91a4-59c7-4749-bb36-1bbafc7a1280"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/IFT6135-2025-First-Assignment/HW1_2025/assignment1_release\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RLVSmv9HoMH5"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import warnings\n",
        "\n",
        "from dataclasses import dataclass\n",
        "import torch\n",
        "from torch import optim\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "from utils import seed_experiment, to_device, cross_entropy_loss, compute_accuracy\n",
        "from config import get_config_parser\n",
        "import json\n",
        "from mlp import MLP\n",
        "from resnet18 import ResNet18\n",
        "from mlpmixer import MLPMixer\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZy1J-0OroLg"
      },
      "source": [
        "# Local Test\n",
        "Before run the experiment, here are some local test cases you can run for sanity check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wLEVxwLlroLh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd2f4fc0-238c-4e0f-9c98-71cae647e19e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 0 tests in 0.000s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.runner.TextTestResult run=0 errors=0 failures=0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import unittest\n",
        "import test\n",
        "suite = unittest.TestLoader().loadTestsFromModule(test)\n",
        "unittest.TextTestRunner(verbosity=2).run(suite)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PtvL_yKp3PW"
      },
      "source": [
        "## Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWiJme7XaLiR"
      },
      "source": [
        "Below we define a few default arguments to get you started with your experiments. You are encouraged to modify the function `main_entry()`, as well as these arguments, to fit your needs (e.g. changing hyperparameters, the optimizer, adding regularizations)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YUrqebfCobD1"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Arguments:\n",
        "  # Data\n",
        "  batch_size: int = 128\n",
        "  # Model\n",
        "  model: str = 'mlp'  # [mlp, resnet18, mlpmixer]\n",
        "  model_config: str = \"./model_configs/mlp.json\" # path to model config json file\n",
        "\n",
        "  # Optimization\n",
        "  optimizer: str = 'adamw'  # [sgd, momentum, adam, adamw]\n",
        "  epochs: int = 15\n",
        "  lr: float = 1e-3\n",
        "  momentum: float = 0.9\n",
        "  weight_decay: float = 5e-4\n",
        "\n",
        "  # Experiment\n",
        "  logdir: str = '/content/assignment/logs'\n",
        "  seed: int = 42\n",
        "\n",
        "  # Miscellaneous\n",
        "  device: str = 'cuda'\n",
        "  visualize : bool = False\n",
        "  print_every: int = 80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "g2rjoY-5phTY"
      },
      "outputs": [],
      "source": [
        "# Main code entry. Train the model and save the logs\n",
        "from main import train, evaluate\n",
        "def main_entry(args):\n",
        "    # Check for the device\n",
        "    if (args.device == \"cuda\") and not torch.cuda.is_available():\n",
        "        warnings.warn(\n",
        "            \"CUDA is not available, make that your environment is \"\n",
        "            \"running on GPU (e.g. in the Notebook Settings in Google Colab). \"\n",
        "            'Forcing device=\"cpu\".'\n",
        "        )\n",
        "        args.device = \"cpu\"\n",
        "\n",
        "    if args.device == \"cpu\":\n",
        "        warnings.warn(\n",
        "            \"You are about to run on CPU, and might run out of memory \"\n",
        "            \"shortly. You can try setting batch_size=1 to reduce memory usage.\"\n",
        "        )\n",
        "\n",
        "    # Seed the experiment, for repeatability\n",
        "    seed_experiment(args.seed)\n",
        "\n",
        "    test_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                     transforms.Normalize([0.49139968, 0.48215841, 0.44653091], [0.24703223, 0.24348513, 0.26158784])\n",
        "                                     ])\n",
        "    # For training, we add some augmentation. Networks are too powerful and would overfit.\n",
        "    train_transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
        "                                          transforms.RandomResizedCrop((32,32),scale=(0.8,1.0),ratio=(0.9,1.1)),\n",
        "                                          transforms.ToTensor(),\n",
        "                                          transforms.Normalize([0.49139968, 0.48215841, 0.44653091], [0.24703223, 0.24348513, 0.26158784])\n",
        "                                        ])\n",
        "    # Loading the training dataset. We need to split it into a training and validation part\n",
        "    # We need to do a little trick because the validation set should not use the augmentation.\n",
        "    train_dataset = CIFAR10(root='./data', train=True, transform=train_transform, download=True)\n",
        "    val_dataset = CIFAR10(root='./data', train=True, transform=test_transform, download=True)\n",
        "    train_set, _ = torch.utils.data.random_split(train_dataset, [45000, 5000])\n",
        "    _, val_set = torch.utils.data.random_split(val_dataset, [45000, 5000])\n",
        "\n",
        "    # Loading the test set\n",
        "    test_set = CIFAR10(root='./data', train=False, transform=test_transform, download=True)\n",
        "\n",
        "    # Load model\n",
        "    print(f'Build model {args.model.upper()}...')\n",
        "    if args.model_config is not None:\n",
        "        print(f'Loading model config from {args.model_config}')\n",
        "        with open(args.model_config) as f:\n",
        "            model_config = json.load(f)\n",
        "    else:\n",
        "        raise ValueError('Please provide a model config json')\n",
        "    print(f'########## {args.model.upper()} CONFIG ################')\n",
        "    for key, val in model_config.items():\n",
        "        print(f'{key}:\\t{val}')\n",
        "    print('############################################')\n",
        "    model_cls = {'mlp': MLP, 'resnet18': ResNet18, 'mlpmixer': MLPMixer}[args.model]\n",
        "    model = model_cls(**model_config)\n",
        "    model.to(args.device)\n",
        "\n",
        "    # Optimizer\n",
        "    if args.optimizer == \"adamw\":\n",
        "        optimizer = optim.AdamW(\n",
        "            model.parameters(), lr=args.lr, weight_decay=args.weight_decay\n",
        "        )\n",
        "    elif args.optimizer == \"adam\":\n",
        "        optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
        "    elif args.optimizer == \"sgd\":\n",
        "        optimizer = optim.SGD(\n",
        "            model.parameters(), lr=args.lr, weight_decay=args.weight_decay\n",
        "        )\n",
        "    elif args.optimizer == \"momentum\":\n",
        "        optimizer = optim.SGD(\n",
        "            model.parameters(),\n",
        "            lr=args.lr,\n",
        "            momentum=args.momentum,\n",
        "            weight_decay=args.weight_decay,\n",
        "        )\n",
        "\n",
        "    print(\n",
        "        f\"Initialized {args.model.upper()} model with {sum(p.numel() for p in model.parameters())} \"\n",
        "        f\"total parameters, of which {sum(p.numel() for p in model.parameters() if p.requires_grad)} are learnable.\"\n",
        "    )\n",
        "\n",
        "    train_losses, valid_losses = [], []\n",
        "    train_accs, valid_accs = [], []\n",
        "    train_times, valid_times = [], []\n",
        "\n",
        "    # We define a set of data loaders that we can use for various purposes later.\n",
        "    train_dataloader = DataLoader(train_set, batch_size=args.batch_size, shuffle=True, drop_last=True, pin_memory=True, num_workers=4)\n",
        "    valid_dataloader = DataLoader(val_set, batch_size=args.batch_size, shuffle=False, drop_last=False, num_workers=4)\n",
        "    test_dataloader = DataLoader(test_set, batch_size=args.batch_size, shuffle=False, drop_last=False, num_workers=4)\n",
        "    for epoch in range(args.epochs):\n",
        "        tqdm.write(f\"====== Epoch {epoch} ======>\")\n",
        "        loss, acc, wall_time = train(epoch, model, train_dataloader, optimizer,args)\n",
        "        train_losses.append(loss)\n",
        "        train_accs.append(acc)\n",
        "        train_times.append(wall_time)\n",
        "\n",
        "        loss, acc, wall_time = evaluate(epoch, model, valid_dataloader,args)\n",
        "        valid_losses.append(loss)\n",
        "        valid_accs.append(acc)\n",
        "        valid_times.append(wall_time)\n",
        "\n",
        "    test_loss, test_acc, test_time = evaluate(\n",
        "        epoch, model, test_dataloader, args, mode=\"test\"\n",
        "    )\n",
        "    print(f\"===== Best validation Accuracy: {max(valid_accs):.3f} =====>\")\n",
        "    return train_losses, valid_losses, train_accs, valid_accs,\n",
        "\n",
        "    # Save log if logdir provided\n",
        "\n",
        "    if args.logdir is not None:\n",
        "        print(f'Writing training logs to {args.logdir}...')\n",
        "        os.makedirs(args.logdir, exist_ok=True)\n",
        "        with open(os.path.join(args.logdir, 'results.json'), 'w') as f:\n",
        "            f.write(json.dumps(\n",
        "                {\n",
        "                    \"train_losses\": train_losses,\n",
        "                    \"valid_losses\": valid_losses,\n",
        "                    \"train_accs\": train_accs,\n",
        "                    \"valid_accs\": valid_accs,\n",
        "                    \"test_loss\": test_loss,\n",
        "                    \"test_acc\": test_acc\n",
        "                },\n",
        "                indent=4,\n",
        "            ))\n",
        "\n",
        "        # Visualize\n",
        "        if args.visualize and args.model in ['resnet18', 'mlpmixer']:\n",
        "            model.visualize(args.logdir)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "X7weD_rk1UnL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example to run MLP with 15 epochs\n",
        "config = Arguments(model='mlp',\n",
        "                   model_config='/content/IFT6135-2025-First-Assignment/HW1_2025/assignment1_release/model_configs/mlp_sigmoid.json',\n",
        "                   epochs= 30, logdir=\"exps/mlp_sigmoid_default\")\n",
        "train_losses, valid_losses, train_accs, valid_accs = main_entry(config)\n",
        "\n",
        "df_sigmoid = pd.DataFrame({'Train Losses': train_losses, 'Valid Losses': valid_losses, 'Train accs': train_accs, 'Valid accs': valid_accs}).assign(Epoch=range(1, len(train_losses) + 1))\n",
        "df_sigmoid['Activation Function'] = 'Sigmoid'\n",
        "df_sigmoid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zGUfCp638Lyu",
        "outputId": "ce773bab-4c04-4cdd-fe2c-c40f6e32afac"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Build model MLP...\n",
            "Loading model config from /content/IFT6135-2025-First-Assignment/HW1_2025/assignment1_release/model_configs/mlp_sigmoid.json\n",
            "########## MLP CONFIG ################\n",
            "input_size:\t3072\n",
            "hidden_sizes:\t[1024, 512, 64, 64]\n",
            "num_classes:\t10\n",
            "activation:\tsigmoid\n",
            "############################################\n",
            "Initialized MLP model with 3709194 total parameters, of which 3709194 are learnable.\n",
            "====== Epoch 0 ======>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN] Epoch: 0, Iter: 0, Loss: 2.49124\n",
            "[TRAIN] Epoch: 0, Iter: 80, Loss: 1.98410\n",
            "[TRAIN] Epoch: 0, Iter: 160, Loss: 1.89980\n",
            "[TRAIN] Epoch: 0, Iter: 240, Loss: 1.76325\n",
            "[TRAIN] Epoch: 0, Iter: 320, Loss: 1.78070\n",
            "== [TRAIN] Epoch: 0, Accuracy: 0.299 ==>\n",
            "[VAL] Epoch: 0, Iter: 0, Loss: 1.81250\n",
            "=== [VAL] Epoch: 0, Iter: 39, Accuracy: 0.372 ===>\n",
            "====== Epoch 1 ======>\n",
            "[TRAIN] Epoch: 1, Iter: 0, Loss: 1.88219\n",
            "[TRAIN] Epoch: 1, Iter: 80, Loss: 1.69453\n",
            "[TRAIN] Epoch: 1, Iter: 160, Loss: 1.81452\n",
            "[TRAIN] Epoch: 1, Iter: 240, Loss: 1.71607\n",
            "[TRAIN] Epoch: 1, Iter: 320, Loss: 1.79211\n",
            "== [TRAIN] Epoch: 1, Accuracy: 0.388 ==>\n",
            "[VAL] Epoch: 1, Iter: 0, Loss: 1.70027\n",
            "=== [VAL] Epoch: 1, Iter: 39, Accuracy: 0.411 ===>\n",
            "====== Epoch 2 ======>\n",
            "[TRAIN] Epoch: 2, Iter: 0, Loss: 1.75566\n",
            "[TRAIN] Epoch: 2, Iter: 80, Loss: 1.68073\n",
            "[TRAIN] Epoch: 2, Iter: 160, Loss: 1.58526\n",
            "[TRAIN] Epoch: 2, Iter: 240, Loss: 1.66338\n",
            "[TRAIN] Epoch: 2, Iter: 320, Loss: 1.75171\n",
            "== [TRAIN] Epoch: 2, Accuracy: 0.417 ==>\n",
            "[VAL] Epoch: 2, Iter: 0, Loss: 1.59961\n",
            "=== [VAL] Epoch: 2, Iter: 39, Accuracy: 0.443 ===>\n",
            "====== Epoch 3 ======>\n",
            "[TRAIN] Epoch: 3, Iter: 0, Loss: 1.63005\n",
            "[TRAIN] Epoch: 3, Iter: 80, Loss: 1.53294\n",
            "[TRAIN] Epoch: 3, Iter: 160, Loss: 1.65220\n",
            "[TRAIN] Epoch: 3, Iter: 240, Loss: 1.43427\n",
            "[TRAIN] Epoch: 3, Iter: 320, Loss: 1.43687\n",
            "== [TRAIN] Epoch: 3, Accuracy: 0.438 ==>\n",
            "[VAL] Epoch: 3, Iter: 0, Loss: 1.48264\n",
            "=== [VAL] Epoch: 3, Iter: 39, Accuracy: 0.478 ===>\n",
            "====== Epoch 4 ======>\n",
            "[TRAIN] Epoch: 4, Iter: 0, Loss: 1.46413\n",
            "[TRAIN] Epoch: 4, Iter: 80, Loss: 1.67781\n",
            "[TRAIN] Epoch: 4, Iter: 160, Loss: 1.67358\n",
            "[TRAIN] Epoch: 4, Iter: 240, Loss: 1.51433\n",
            "[TRAIN] Epoch: 4, Iter: 320, Loss: 1.50580\n",
            "== [TRAIN] Epoch: 4, Accuracy: 0.457 ==>\n",
            "[VAL] Epoch: 4, Iter: 0, Loss: 1.48140\n",
            "=== [VAL] Epoch: 4, Iter: 39, Accuracy: 0.477 ===>\n",
            "====== Epoch 5 ======>\n",
            "[TRAIN] Epoch: 5, Iter: 0, Loss: 1.55997\n",
            "[TRAIN] Epoch: 5, Iter: 80, Loss: 1.45470\n",
            "[TRAIN] Epoch: 5, Iter: 160, Loss: 1.64863\n",
            "[TRAIN] Epoch: 5, Iter: 240, Loss: 1.57271\n",
            "[TRAIN] Epoch: 5, Iter: 320, Loss: 1.41712\n",
            "== [TRAIN] Epoch: 5, Accuracy: 0.468 ==>\n",
            "[VAL] Epoch: 5, Iter: 0, Loss: 1.50233\n",
            "=== [VAL] Epoch: 5, Iter: 39, Accuracy: 0.491 ===>\n",
            "====== Epoch 6 ======>\n",
            "[TRAIN] Epoch: 6, Iter: 0, Loss: 1.48655\n",
            "[TRAIN] Epoch: 6, Iter: 80, Loss: 1.28340\n",
            "[TRAIN] Epoch: 6, Iter: 160, Loss: 1.60460\n",
            "[TRAIN] Epoch: 6, Iter: 240, Loss: 1.44384\n",
            "[TRAIN] Epoch: 6, Iter: 320, Loss: 1.59092\n",
            "== [TRAIN] Epoch: 6, Accuracy: 0.478 ==>\n",
            "[VAL] Epoch: 6, Iter: 0, Loss: 1.48029\n",
            "=== [VAL] Epoch: 6, Iter: 39, Accuracy: 0.505 ===>\n",
            "====== Epoch 7 ======>\n",
            "[TRAIN] Epoch: 7, Iter: 0, Loss: 1.38803\n",
            "[TRAIN] Epoch: 7, Iter: 80, Loss: 1.34051\n",
            "[TRAIN] Epoch: 7, Iter: 160, Loss: 1.32379\n",
            "[TRAIN] Epoch: 7, Iter: 240, Loss: 1.52608\n",
            "[TRAIN] Epoch: 7, Iter: 320, Loss: 1.31099\n",
            "== [TRAIN] Epoch: 7, Accuracy: 0.488 ==>\n",
            "[VAL] Epoch: 7, Iter: 0, Loss: 1.38649\n",
            "=== [VAL] Epoch: 7, Iter: 39, Accuracy: 0.510 ===>\n",
            "====== Epoch 8 ======>\n",
            "[TRAIN] Epoch: 8, Iter: 0, Loss: 1.39622\n",
            "[TRAIN] Epoch: 8, Iter: 80, Loss: 1.46187\n",
            "[TRAIN] Epoch: 8, Iter: 160, Loss: 1.40443\n",
            "[TRAIN] Epoch: 8, Iter: 240, Loss: 1.47843\n",
            "[TRAIN] Epoch: 8, Iter: 320, Loss: 1.31434\n",
            "== [TRAIN] Epoch: 8, Accuracy: 0.496 ==>\n",
            "[VAL] Epoch: 8, Iter: 0, Loss: 1.40819\n",
            "=== [VAL] Epoch: 8, Iter: 39, Accuracy: 0.511 ===>\n",
            "====== Epoch 9 ======>\n",
            "[TRAIN] Epoch: 9, Iter: 0, Loss: 1.31109\n",
            "[TRAIN] Epoch: 9, Iter: 80, Loss: 1.19690\n",
            "[TRAIN] Epoch: 9, Iter: 160, Loss: 1.44713\n",
            "[TRAIN] Epoch: 9, Iter: 240, Loss: 1.30148\n",
            "[TRAIN] Epoch: 9, Iter: 320, Loss: 1.32196\n",
            "== [TRAIN] Epoch: 9, Accuracy: 0.502 ==>\n",
            "[VAL] Epoch: 9, Iter: 0, Loss: 1.35404\n",
            "=== [VAL] Epoch: 9, Iter: 39, Accuracy: 0.523 ===>\n",
            "====== Epoch 10 ======>\n",
            "[TRAIN] Epoch: 10, Iter: 0, Loss: 1.50740\n",
            "[TRAIN] Epoch: 10, Iter: 80, Loss: 1.32079\n",
            "[TRAIN] Epoch: 10, Iter: 160, Loss: 1.57374\n",
            "[TRAIN] Epoch: 10, Iter: 240, Loss: 1.26895\n",
            "[TRAIN] Epoch: 10, Iter: 320, Loss: 1.38963\n",
            "== [TRAIN] Epoch: 10, Accuracy: 0.509 ==>\n",
            "[VAL] Epoch: 10, Iter: 0, Loss: 1.34998\n",
            "=== [VAL] Epoch: 10, Iter: 39, Accuracy: 0.527 ===>\n",
            "====== Epoch 11 ======>\n",
            "[TRAIN] Epoch: 11, Iter: 0, Loss: 1.33330\n",
            "[TRAIN] Epoch: 11, Iter: 80, Loss: 1.17061\n",
            "[TRAIN] Epoch: 11, Iter: 160, Loss: 1.46371\n",
            "[TRAIN] Epoch: 11, Iter: 240, Loss: 1.26260\n",
            "[TRAIN] Epoch: 11, Iter: 320, Loss: 1.42657\n",
            "== [TRAIN] Epoch: 11, Accuracy: 0.514 ==>\n",
            "[VAL] Epoch: 11, Iter: 0, Loss: 1.36585\n",
            "=== [VAL] Epoch: 11, Iter: 39, Accuracy: 0.525 ===>\n",
            "====== Epoch 12 ======>\n",
            "[TRAIN] Epoch: 12, Iter: 0, Loss: 1.37682\n",
            "[TRAIN] Epoch: 12, Iter: 80, Loss: 1.36540\n",
            "[TRAIN] Epoch: 12, Iter: 160, Loss: 1.39816\n",
            "[TRAIN] Epoch: 12, Iter: 240, Loss: 1.33344\n",
            "[TRAIN] Epoch: 12, Iter: 320, Loss: 1.39824\n",
            "== [TRAIN] Epoch: 12, Accuracy: 0.522 ==>\n",
            "[VAL] Epoch: 12, Iter: 0, Loss: 1.39720\n",
            "=== [VAL] Epoch: 12, Iter: 39, Accuracy: 0.540 ===>\n",
            "====== Epoch 13 ======>\n",
            "[TRAIN] Epoch: 13, Iter: 0, Loss: 1.26959\n",
            "[TRAIN] Epoch: 13, Iter: 80, Loss: 1.40680\n",
            "[TRAIN] Epoch: 13, Iter: 160, Loss: 1.23882\n",
            "[TRAIN] Epoch: 13, Iter: 240, Loss: 1.27800\n",
            "[TRAIN] Epoch: 13, Iter: 320, Loss: 1.30123\n",
            "== [TRAIN] Epoch: 13, Accuracy: 0.526 ==>\n",
            "[VAL] Epoch: 13, Iter: 0, Loss: 1.38954\n",
            "=== [VAL] Epoch: 13, Iter: 39, Accuracy: 0.541 ===>\n",
            "====== Epoch 14 ======>\n",
            "[TRAIN] Epoch: 14, Iter: 0, Loss: 1.31916\n",
            "[TRAIN] Epoch: 14, Iter: 80, Loss: 1.24471\n",
            "[TRAIN] Epoch: 14, Iter: 160, Loss: 1.27792\n",
            "[TRAIN] Epoch: 14, Iter: 240, Loss: 1.31063\n",
            "[TRAIN] Epoch: 14, Iter: 320, Loss: 1.27609\n",
            "== [TRAIN] Epoch: 14, Accuracy: 0.529 ==>\n",
            "[VAL] Epoch: 14, Iter: 0, Loss: 1.32360\n",
            "=== [VAL] Epoch: 14, Iter: 39, Accuracy: 0.551 ===>\n",
            "====== Epoch 15 ======>\n",
            "[TRAIN] Epoch: 15, Iter: 0, Loss: 1.27652\n",
            "[TRAIN] Epoch: 15, Iter: 80, Loss: 1.07265\n",
            "[TRAIN] Epoch: 15, Iter: 160, Loss: 1.22345\n",
            "[TRAIN] Epoch: 15, Iter: 240, Loss: 1.23992\n",
            "[TRAIN] Epoch: 15, Iter: 320, Loss: 1.32169\n",
            "== [TRAIN] Epoch: 15, Accuracy: 0.537 ==>\n",
            "[VAL] Epoch: 15, Iter: 0, Loss: 1.34975\n",
            "=== [VAL] Epoch: 15, Iter: 39, Accuracy: 0.551 ===>\n",
            "====== Epoch 16 ======>\n",
            "[TRAIN] Epoch: 16, Iter: 0, Loss: 1.41945\n",
            "[TRAIN] Epoch: 16, Iter: 80, Loss: 1.55955\n",
            "[TRAIN] Epoch: 16, Iter: 160, Loss: 1.33608\n",
            "[TRAIN] Epoch: 16, Iter: 240, Loss: 1.37175\n",
            "[TRAIN] Epoch: 16, Iter: 320, Loss: 1.32479\n",
            "== [TRAIN] Epoch: 16, Accuracy: 0.542 ==>\n",
            "[VAL] Epoch: 16, Iter: 0, Loss: 1.28052\n",
            "=== [VAL] Epoch: 16, Iter: 39, Accuracy: 0.555 ===>\n",
            "====== Epoch 17 ======>\n",
            "[TRAIN] Epoch: 17, Iter: 0, Loss: 1.23028\n",
            "[TRAIN] Epoch: 17, Iter: 80, Loss: 1.38177\n",
            "[TRAIN] Epoch: 17, Iter: 160, Loss: 1.25497\n",
            "[TRAIN] Epoch: 17, Iter: 240, Loss: 1.30333\n",
            "[TRAIN] Epoch: 17, Iter: 320, Loss: 1.18679\n",
            "== [TRAIN] Epoch: 17, Accuracy: 0.549 ==>\n",
            "[VAL] Epoch: 17, Iter: 0, Loss: 1.20693\n",
            "=== [VAL] Epoch: 17, Iter: 39, Accuracy: 0.551 ===>\n",
            "====== Epoch 18 ======>\n",
            "[TRAIN] Epoch: 18, Iter: 0, Loss: 1.30193\n",
            "[TRAIN] Epoch: 18, Iter: 80, Loss: 1.29923\n",
            "[TRAIN] Epoch: 18, Iter: 160, Loss: 1.19595\n",
            "[TRAIN] Epoch: 18, Iter: 240, Loss: 1.29825\n",
            "[TRAIN] Epoch: 18, Iter: 320, Loss: 1.29812\n",
            "== [TRAIN] Epoch: 18, Accuracy: 0.550 ==>\n",
            "[VAL] Epoch: 18, Iter: 0, Loss: 1.32369\n",
            "=== [VAL] Epoch: 18, Iter: 39, Accuracy: 0.571 ===>\n",
            "====== Epoch 19 ======>\n",
            "[TRAIN] Epoch: 19, Iter: 0, Loss: 1.23798\n",
            "[TRAIN] Epoch: 19, Iter: 80, Loss: 1.29796\n",
            "[TRAIN] Epoch: 19, Iter: 160, Loss: 1.25198\n",
            "[TRAIN] Epoch: 19, Iter: 240, Loss: 1.11449\n",
            "[TRAIN] Epoch: 19, Iter: 320, Loss: 1.33812\n",
            "== [TRAIN] Epoch: 19, Accuracy: 0.554 ==>\n",
            "[VAL] Epoch: 19, Iter: 0, Loss: 1.30415\n",
            "=== [VAL] Epoch: 19, Iter: 39, Accuracy: 0.571 ===>\n",
            "====== Epoch 20 ======>\n",
            "[TRAIN] Epoch: 20, Iter: 0, Loss: 1.22887\n",
            "[TRAIN] Epoch: 20, Iter: 80, Loss: 1.24499\n",
            "[TRAIN] Epoch: 20, Iter: 160, Loss: 1.17682\n",
            "[TRAIN] Epoch: 20, Iter: 240, Loss: 1.26676\n",
            "[TRAIN] Epoch: 20, Iter: 320, Loss: 1.37309\n",
            "== [TRAIN] Epoch: 20, Accuracy: 0.556 ==>\n",
            "[VAL] Epoch: 20, Iter: 0, Loss: 1.21675\n",
            "=== [VAL] Epoch: 20, Iter: 39, Accuracy: 0.574 ===>\n",
            "====== Epoch 21 ======>\n",
            "[TRAIN] Epoch: 21, Iter: 0, Loss: 1.28216\n",
            "[TRAIN] Epoch: 21, Iter: 80, Loss: 1.23516\n",
            "[TRAIN] Epoch: 21, Iter: 160, Loss: 1.19984\n",
            "[TRAIN] Epoch: 21, Iter: 240, Loss: 1.22119\n",
            "[TRAIN] Epoch: 21, Iter: 320, Loss: 1.13988\n",
            "== [TRAIN] Epoch: 21, Accuracy: 0.562 ==>\n",
            "[VAL] Epoch: 21, Iter: 0, Loss: 1.23631\n",
            "=== [VAL] Epoch: 21, Iter: 39, Accuracy: 0.573 ===>\n",
            "====== Epoch 22 ======>\n",
            "[TRAIN] Epoch: 22, Iter: 0, Loss: 1.13180\n",
            "[TRAIN] Epoch: 22, Iter: 80, Loss: 1.25423\n",
            "[TRAIN] Epoch: 22, Iter: 160, Loss: 1.24929\n",
            "[TRAIN] Epoch: 22, Iter: 240, Loss: 1.24353\n",
            "[TRAIN] Epoch: 22, Iter: 320, Loss: 1.08882\n",
            "== [TRAIN] Epoch: 22, Accuracy: 0.565 ==>\n",
            "[VAL] Epoch: 22, Iter: 0, Loss: 1.25119\n",
            "=== [VAL] Epoch: 22, Iter: 39, Accuracy: 0.581 ===>\n",
            "====== Epoch 23 ======>\n",
            "[TRAIN] Epoch: 23, Iter: 0, Loss: 1.06786\n",
            "[TRAIN] Epoch: 23, Iter: 80, Loss: 1.28771\n",
            "[TRAIN] Epoch: 23, Iter: 160, Loss: 1.20267\n",
            "[TRAIN] Epoch: 23, Iter: 240, Loss: 1.21854\n",
            "[TRAIN] Epoch: 23, Iter: 320, Loss: 1.32183\n",
            "== [TRAIN] Epoch: 23, Accuracy: 0.569 ==>\n",
            "[VAL] Epoch: 23, Iter: 0, Loss: 1.26293\n",
            "=== [VAL] Epoch: 23, Iter: 39, Accuracy: 0.584 ===>\n",
            "====== Epoch 24 ======>\n",
            "[TRAIN] Epoch: 24, Iter: 0, Loss: 1.26532\n",
            "[TRAIN] Epoch: 24, Iter: 80, Loss: 1.34505\n",
            "[TRAIN] Epoch: 24, Iter: 160, Loss: 1.14466\n",
            "[TRAIN] Epoch: 24, Iter: 240, Loss: 1.23136\n",
            "[TRAIN] Epoch: 24, Iter: 320, Loss: 1.02518\n",
            "== [TRAIN] Epoch: 24, Accuracy: 0.574 ==>\n",
            "[VAL] Epoch: 24, Iter: 0, Loss: 1.32171\n",
            "=== [VAL] Epoch: 24, Iter: 39, Accuracy: 0.588 ===>\n",
            "====== Epoch 25 ======>\n",
            "[TRAIN] Epoch: 25, Iter: 0, Loss: 1.07065\n",
            "[TRAIN] Epoch: 25, Iter: 80, Loss: 1.07047\n",
            "[TRAIN] Epoch: 25, Iter: 160, Loss: 1.17867\n",
            "[TRAIN] Epoch: 25, Iter: 240, Loss: 1.24446\n",
            "[TRAIN] Epoch: 25, Iter: 320, Loss: 1.18725\n",
            "== [TRAIN] Epoch: 25, Accuracy: 0.578 ==>\n",
            "[VAL] Epoch: 25, Iter: 0, Loss: 1.15019\n",
            "=== [VAL] Epoch: 25, Iter: 39, Accuracy: 0.588 ===>\n",
            "====== Epoch 26 ======>\n",
            "[TRAIN] Epoch: 26, Iter: 0, Loss: 1.05980\n",
            "[TRAIN] Epoch: 26, Iter: 80, Loss: 1.14770\n",
            "[TRAIN] Epoch: 26, Iter: 160, Loss: 1.18244\n",
            "[TRAIN] Epoch: 26, Iter: 240, Loss: 1.31031\n",
            "[TRAIN] Epoch: 26, Iter: 320, Loss: 1.06238\n",
            "== [TRAIN] Epoch: 26, Accuracy: 0.576 ==>\n",
            "[VAL] Epoch: 26, Iter: 0, Loss: 1.24905\n",
            "=== [VAL] Epoch: 26, Iter: 39, Accuracy: 0.599 ===>\n",
            "====== Epoch 27 ======>\n",
            "[TRAIN] Epoch: 27, Iter: 0, Loss: 1.12273\n",
            "[TRAIN] Epoch: 27, Iter: 80, Loss: 1.11786\n",
            "[TRAIN] Epoch: 27, Iter: 160, Loss: 1.14970\n",
            "[TRAIN] Epoch: 27, Iter: 240, Loss: 1.09809\n",
            "[TRAIN] Epoch: 27, Iter: 320, Loss: 1.32135\n",
            "== [TRAIN] Epoch: 27, Accuracy: 0.585 ==>\n",
            "[VAL] Epoch: 27, Iter: 0, Loss: 1.29989\n",
            "=== [VAL] Epoch: 27, Iter: 39, Accuracy: 0.598 ===>\n",
            "====== Epoch 28 ======>\n",
            "[TRAIN] Epoch: 28, Iter: 0, Loss: 1.12456\n",
            "[TRAIN] Epoch: 28, Iter: 80, Loss: 1.06577\n",
            "[TRAIN] Epoch: 28, Iter: 160, Loss: 1.43570\n",
            "[TRAIN] Epoch: 28, Iter: 240, Loss: 1.16351\n",
            "[TRAIN] Epoch: 28, Iter: 320, Loss: 1.20252\n",
            "== [TRAIN] Epoch: 28, Accuracy: 0.586 ==>\n",
            "[VAL] Epoch: 28, Iter: 0, Loss: 1.17899\n",
            "=== [VAL] Epoch: 28, Iter: 39, Accuracy: 0.612 ===>\n",
            "====== Epoch 29 ======>\n",
            "[TRAIN] Epoch: 29, Iter: 0, Loss: 1.21329\n",
            "[TRAIN] Epoch: 29, Iter: 80, Loss: 1.06422\n",
            "[TRAIN] Epoch: 29, Iter: 160, Loss: 1.22632\n",
            "[TRAIN] Epoch: 29, Iter: 240, Loss: 1.21842\n",
            "[TRAIN] Epoch: 29, Iter: 320, Loss: 1.03323\n",
            "== [TRAIN] Epoch: 29, Accuracy: 0.592 ==>\n",
            "[VAL] Epoch: 29, Iter: 0, Loss: 1.13767\n",
            "=== [VAL] Epoch: 29, Iter: 39, Accuracy: 0.601 ===>\n",
            "[TEST] Epoch: 29, Iter: 0, Loss: 1.20578\n",
            "=== [TEST] Epoch: 29, Iter: 78, Accuracy: 0.528 ===>\n",
            "===== Best validation Accuracy: 0.612 =====>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Train Losses  Valid Losses  Train accs  Valid accs  Epoch  \\\n",
              "0       1.929532      1.778379    0.299012    0.372461      1   \n",
              "1       1.715692      1.648512    0.388444    0.411328      2   \n",
              "2       1.631715      1.573093    0.416511    0.443164      3   \n",
              "3       1.572858      1.513617    0.437767    0.477930      4   \n",
              "4       1.529260      1.486383    0.457465    0.476953      5   \n",
              "5       1.493623      1.445000    0.468127    0.491406      6   \n",
              "6       1.470069      1.429963    0.477742    0.505469      7   \n",
              "7       1.442939      1.396051    0.487847    0.509570      8   \n",
              "8       1.418792      1.386294    0.496261    0.511133      9   \n",
              "9       1.400922      1.364998    0.501647    0.522852     10   \n",
              "10      1.382181      1.350231    0.509103    0.526563     11   \n",
              "11      1.366171      1.341337    0.514245    0.525391     12   \n",
              "12      1.348987      1.306105    0.522436    0.540039     13   \n",
              "13      1.331814      1.299440    0.525953    0.541211     14   \n",
              "14      1.320573      1.280256    0.528601    0.550586     15   \n",
              "15      1.301923      1.255102    0.536547    0.550781     16   \n",
              "16      1.292962      1.243023    0.541733    0.555273     17   \n",
              "17      1.276105      1.238297    0.548834    0.550977     18   \n",
              "18      1.262410      1.236312    0.550459    0.570898     19   \n",
              "19      1.252625      1.208997    0.554198    0.570703     20   \n",
              "20      1.244691      1.199616    0.555645    0.573828     21   \n",
              "21      1.232259      1.195903    0.562255    0.572852     22   \n",
              "22      1.216466      1.182374    0.565460    0.580664     23   \n",
              "23      1.211655      1.157977    0.568999    0.584375     24   \n",
              "24      1.198416      1.167159    0.573629    0.588477     25   \n",
              "25      1.194053      1.144319    0.577702    0.587891     26   \n",
              "26      1.186656      1.136623    0.576011    0.599219     27   \n",
              "27      1.171975      1.116275    0.584513    0.598242     28   \n",
              "28      1.164724      1.111781    0.585581    0.612109     29   \n",
              "29      1.150780      1.116257    0.591880    0.600781     30   \n",
              "\n",
              "   Activation Function  \n",
              "0                 Tanh  \n",
              "1                 Tanh  \n",
              "2                 Tanh  \n",
              "3                 Tanh  \n",
              "4                 Tanh  \n",
              "5                 Tanh  \n",
              "6                 Tanh  \n",
              "7                 Tanh  \n",
              "8                 Tanh  \n",
              "9                 Tanh  \n",
              "10                Tanh  \n",
              "11                Tanh  \n",
              "12                Tanh  \n",
              "13                Tanh  \n",
              "14                Tanh  \n",
              "15                Tanh  \n",
              "16                Tanh  \n",
              "17                Tanh  \n",
              "18                Tanh  \n",
              "19                Tanh  \n",
              "20                Tanh  \n",
              "21                Tanh  \n",
              "22                Tanh  \n",
              "23                Tanh  \n",
              "24                Tanh  \n",
              "25                Tanh  \n",
              "26                Tanh  \n",
              "27                Tanh  \n",
              "28                Tanh  \n",
              "29                Tanh  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8500d971-5fec-456f-bb6d-63f65a500d4b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train Losses</th>\n",
              "      <th>Valid Losses</th>\n",
              "      <th>Train accs</th>\n",
              "      <th>Valid accs</th>\n",
              "      <th>Epoch</th>\n",
              "      <th>Activation Function</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.929532</td>\n",
              "      <td>1.778379</td>\n",
              "      <td>0.299012</td>\n",
              "      <td>0.372461</td>\n",
              "      <td>1</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.715692</td>\n",
              "      <td>1.648512</td>\n",
              "      <td>0.388444</td>\n",
              "      <td>0.411328</td>\n",
              "      <td>2</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.631715</td>\n",
              "      <td>1.573093</td>\n",
              "      <td>0.416511</td>\n",
              "      <td>0.443164</td>\n",
              "      <td>3</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.572858</td>\n",
              "      <td>1.513617</td>\n",
              "      <td>0.437767</td>\n",
              "      <td>0.477930</td>\n",
              "      <td>4</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.529260</td>\n",
              "      <td>1.486383</td>\n",
              "      <td>0.457465</td>\n",
              "      <td>0.476953</td>\n",
              "      <td>5</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.493623</td>\n",
              "      <td>1.445000</td>\n",
              "      <td>0.468127</td>\n",
              "      <td>0.491406</td>\n",
              "      <td>6</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.470069</td>\n",
              "      <td>1.429963</td>\n",
              "      <td>0.477742</td>\n",
              "      <td>0.505469</td>\n",
              "      <td>7</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.442939</td>\n",
              "      <td>1.396051</td>\n",
              "      <td>0.487847</td>\n",
              "      <td>0.509570</td>\n",
              "      <td>8</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.418792</td>\n",
              "      <td>1.386294</td>\n",
              "      <td>0.496261</td>\n",
              "      <td>0.511133</td>\n",
              "      <td>9</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.400922</td>\n",
              "      <td>1.364998</td>\n",
              "      <td>0.501647</td>\n",
              "      <td>0.522852</td>\n",
              "      <td>10</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1.382181</td>\n",
              "      <td>1.350231</td>\n",
              "      <td>0.509103</td>\n",
              "      <td>0.526563</td>\n",
              "      <td>11</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.366171</td>\n",
              "      <td>1.341337</td>\n",
              "      <td>0.514245</td>\n",
              "      <td>0.525391</td>\n",
              "      <td>12</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1.348987</td>\n",
              "      <td>1.306105</td>\n",
              "      <td>0.522436</td>\n",
              "      <td>0.540039</td>\n",
              "      <td>13</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1.331814</td>\n",
              "      <td>1.299440</td>\n",
              "      <td>0.525953</td>\n",
              "      <td>0.541211</td>\n",
              "      <td>14</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1.320573</td>\n",
              "      <td>1.280256</td>\n",
              "      <td>0.528601</td>\n",
              "      <td>0.550586</td>\n",
              "      <td>15</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1.301923</td>\n",
              "      <td>1.255102</td>\n",
              "      <td>0.536547</td>\n",
              "      <td>0.550781</td>\n",
              "      <td>16</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1.292962</td>\n",
              "      <td>1.243023</td>\n",
              "      <td>0.541733</td>\n",
              "      <td>0.555273</td>\n",
              "      <td>17</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.276105</td>\n",
              "      <td>1.238297</td>\n",
              "      <td>0.548834</td>\n",
              "      <td>0.550977</td>\n",
              "      <td>18</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1.262410</td>\n",
              "      <td>1.236312</td>\n",
              "      <td>0.550459</td>\n",
              "      <td>0.570898</td>\n",
              "      <td>19</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1.252625</td>\n",
              "      <td>1.208997</td>\n",
              "      <td>0.554198</td>\n",
              "      <td>0.570703</td>\n",
              "      <td>20</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1.244691</td>\n",
              "      <td>1.199616</td>\n",
              "      <td>0.555645</td>\n",
              "      <td>0.573828</td>\n",
              "      <td>21</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1.232259</td>\n",
              "      <td>1.195903</td>\n",
              "      <td>0.562255</td>\n",
              "      <td>0.572852</td>\n",
              "      <td>22</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1.216466</td>\n",
              "      <td>1.182374</td>\n",
              "      <td>0.565460</td>\n",
              "      <td>0.580664</td>\n",
              "      <td>23</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1.211655</td>\n",
              "      <td>1.157977</td>\n",
              "      <td>0.568999</td>\n",
              "      <td>0.584375</td>\n",
              "      <td>24</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1.198416</td>\n",
              "      <td>1.167159</td>\n",
              "      <td>0.573629</td>\n",
              "      <td>0.588477</td>\n",
              "      <td>25</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1.194053</td>\n",
              "      <td>1.144319</td>\n",
              "      <td>0.577702</td>\n",
              "      <td>0.587891</td>\n",
              "      <td>26</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1.186656</td>\n",
              "      <td>1.136623</td>\n",
              "      <td>0.576011</td>\n",
              "      <td>0.599219</td>\n",
              "      <td>27</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1.171975</td>\n",
              "      <td>1.116275</td>\n",
              "      <td>0.584513</td>\n",
              "      <td>0.598242</td>\n",
              "      <td>28</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1.164724</td>\n",
              "      <td>1.111781</td>\n",
              "      <td>0.585581</td>\n",
              "      <td>0.612109</td>\n",
              "      <td>29</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1.150780</td>\n",
              "      <td>1.116257</td>\n",
              "      <td>0.591880</td>\n",
              "      <td>0.600781</td>\n",
              "      <td>30</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8500d971-5fec-456f-bb6d-63f65a500d4b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8500d971-5fec-456f-bb6d-63f65a500d4b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8500d971-5fec-456f-bb6d-63f65a500d4b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b0ea120b-c7bd-4fd9-8c58-c7de7dc284e8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b0ea120b-c7bd-4fd9-8c58-c7de7dc284e8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b0ea120b-c7bd-4fd9-8c58-c7de7dc284e8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e39d459d-0bd4-45ab-b9d4-971732213e77\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_sigmoid')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e39d459d-0bd4-45ab-b9d4-971732213e77 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_sigmoid');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_sigmoid",
              "summary": "{\n  \"name\": \"df_sigmoid\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": \"Train Losses\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18123447227962575,\n        \"min\": 1.1507804201878715,\n        \"max\": 1.9295316428540434,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          1.1719746993817488,\n          1.3019231289540258,\n          1.2116548835042535\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Valid Losses\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16747392387654764,\n        \"min\": 1.1117814823985102,\n        \"max\": 1.7783790856599808,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          1.1162746116518971,\n          1.2551015406847,\n          1.1579770773649214\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train accs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06645482651186758,\n        \"min\": 0.2990117521367515,\n        \"max\": 0.591880341880342,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          0.5845129985754989,\n          0.5365473646723645,\n          0.5689992877492881\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Valid accs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.057620256560332,\n        \"min\": 0.37246093750000003,\n        \"max\": 0.6121093750000001,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          0.5982421874999999,\n          0.55078125,\n          0.5843750000000001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 1,\n        \"max\": 30,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          28,\n          16,\n          24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Activation Function\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Tanh\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example to run MLP with 15 epochs\n",
        "config = Arguments(model='mlp',\n",
        "                   model_config='/content/IFT6135-2025-First-Assignment/HW1_2025/assignment1_release/model_configs/mlp.json',\n",
        "                   epochs= 30, logdir=\"exps/mlp_default\")\n",
        "train_losses, valid_losses, train_accs, valid_accs = main_entry(config)\n",
        "\n",
        "df_relu = pd.DataFrame({'Train Losses': train_losses, 'Valid Losses': valid_losses, 'Train accs': train_accs, 'Valid accs': valid_accs}).assign(Epoch=range(1, len(train_losses) + 1))\n",
        "df_relu['Activation Function'] = 'ReLU'\n",
        "df_relu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZN7JFPOh3-0C",
        "outputId": "a279114c-3472-445d-f3b9-64bdbb6f4e7f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Build model MLP...\n",
            "Loading model config from /content/IFT6135-2025-First-Assignment/HW1_2025/assignment1_release/model_configs/mlp.json\n",
            "########## MLP CONFIG ################\n",
            "input_size:\t3072\n",
            "hidden_sizes:\t[1024, 512, 64, 64]\n",
            "num_classes:\t10\n",
            "activation:\trelu\n",
            "############################################\n",
            "Initialized MLP model with 3709194 total parameters, of which 3709194 are learnable.\n",
            "====== Epoch 0 ======>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN] Epoch: 0, Iter: 0, Loss: 2.61241\n",
            "[TRAIN] Epoch: 0, Iter: 80, Loss: 1.77236\n",
            "[TRAIN] Epoch: 0, Iter: 160, Loss: 1.74864\n",
            "[TRAIN] Epoch: 0, Iter: 240, Loss: 1.54849\n",
            "[TRAIN] Epoch: 0, Iter: 320, Loss: 1.66133\n",
            "== [TRAIN] Epoch: 0, Accuracy: 0.358 ==>\n",
            "[VAL] Epoch: 0, Iter: 0, Loss: 1.69828\n",
            "=== [VAL] Epoch: 0, Iter: 39, Accuracy: 0.413 ===>\n",
            "====== Epoch 1 ======>\n",
            "[TRAIN] Epoch: 1, Iter: 0, Loss: 1.72243\n",
            "[TRAIN] Epoch: 1, Iter: 80, Loss: 1.56231\n",
            "[TRAIN] Epoch: 1, Iter: 160, Loss: 1.62889\n",
            "[TRAIN] Epoch: 1, Iter: 240, Loss: 1.76265\n",
            "[TRAIN] Epoch: 1, Iter: 320, Loss: 1.73134\n",
            "== [TRAIN] Epoch: 1, Accuracy: 0.430 ==>\n",
            "[VAL] Epoch: 1, Iter: 0, Loss: 1.57578\n",
            "=== [VAL] Epoch: 1, Iter: 39, Accuracy: 0.471 ===>\n",
            "====== Epoch 2 ======>\n",
            "[TRAIN] Epoch: 2, Iter: 0, Loss: 1.62931\n",
            "[TRAIN] Epoch: 2, Iter: 80, Loss: 1.73353\n",
            "[TRAIN] Epoch: 2, Iter: 160, Loss: 1.56528\n",
            "[TRAIN] Epoch: 2, Iter: 240, Loss: 1.48135\n",
            "[TRAIN] Epoch: 2, Iter: 320, Loss: 1.47238\n",
            "== [TRAIN] Epoch: 2, Accuracy: 0.458 ==>\n",
            "[VAL] Epoch: 2, Iter: 0, Loss: 1.52025\n",
            "=== [VAL] Epoch: 2, Iter: 39, Accuracy: 0.472 ===>\n",
            "====== Epoch 3 ======>\n",
            "[TRAIN] Epoch: 3, Iter: 0, Loss: 1.54703\n",
            "[TRAIN] Epoch: 3, Iter: 80, Loss: 1.48833\n",
            "[TRAIN] Epoch: 3, Iter: 160, Loss: 1.48759\n",
            "[TRAIN] Epoch: 3, Iter: 240, Loss: 1.35100\n",
            "[TRAIN] Epoch: 3, Iter: 320, Loss: 1.27538\n",
            "== [TRAIN] Epoch: 3, Accuracy: 0.481 ==>\n",
            "[VAL] Epoch: 3, Iter: 0, Loss: 1.50226\n",
            "=== [VAL] Epoch: 3, Iter: 39, Accuracy: 0.498 ===>\n",
            "====== Epoch 4 ======>\n",
            "[TRAIN] Epoch: 4, Iter: 0, Loss: 1.32552\n",
            "[TRAIN] Epoch: 4, Iter: 80, Loss: 1.47739\n",
            "[TRAIN] Epoch: 4, Iter: 160, Loss: 1.48174\n",
            "[TRAIN] Epoch: 4, Iter: 240, Loss: 1.46175\n",
            "[TRAIN] Epoch: 4, Iter: 320, Loss: 1.31292\n",
            "== [TRAIN] Epoch: 4, Accuracy: 0.499 ==>\n",
            "[VAL] Epoch: 4, Iter: 0, Loss: 1.36982\n",
            "=== [VAL] Epoch: 4, Iter: 39, Accuracy: 0.533 ===>\n",
            "====== Epoch 5 ======>\n",
            "[TRAIN] Epoch: 5, Iter: 0, Loss: 1.36681\n",
            "[TRAIN] Epoch: 5, Iter: 80, Loss: 1.29882\n",
            "[TRAIN] Epoch: 5, Iter: 160, Loss: 1.50413\n",
            "[TRAIN] Epoch: 5, Iter: 240, Loss: 1.49167\n",
            "[TRAIN] Epoch: 5, Iter: 320, Loss: 1.27725\n",
            "== [TRAIN] Epoch: 5, Accuracy: 0.514 ==>\n",
            "[VAL] Epoch: 5, Iter: 0, Loss: 1.39981\n",
            "=== [VAL] Epoch: 5, Iter: 39, Accuracy: 0.541 ===>\n",
            "====== Epoch 6 ======>\n",
            "[TRAIN] Epoch: 6, Iter: 0, Loss: 1.21998\n",
            "[TRAIN] Epoch: 6, Iter: 80, Loss: 1.12752\n",
            "[TRAIN] Epoch: 6, Iter: 160, Loss: 1.49317\n",
            "[TRAIN] Epoch: 6, Iter: 240, Loss: 1.37791\n",
            "[TRAIN] Epoch: 6, Iter: 320, Loss: 1.41642\n",
            "== [TRAIN] Epoch: 6, Accuracy: 0.528 ==>\n",
            "[VAL] Epoch: 6, Iter: 0, Loss: 1.31052\n",
            "=== [VAL] Epoch: 6, Iter: 39, Accuracy: 0.563 ===>\n",
            "====== Epoch 7 ======>\n",
            "[TRAIN] Epoch: 7, Iter: 0, Loss: 1.26710\n",
            "[TRAIN] Epoch: 7, Iter: 80, Loss: 1.25233\n",
            "[TRAIN] Epoch: 7, Iter: 160, Loss: 1.18205\n",
            "[TRAIN] Epoch: 7, Iter: 240, Loss: 1.40879\n",
            "[TRAIN] Epoch: 7, Iter: 320, Loss: 1.29530\n",
            "== [TRAIN] Epoch: 7, Accuracy: 0.537 ==>\n",
            "[VAL] Epoch: 7, Iter: 0, Loss: 1.21707\n",
            "=== [VAL] Epoch: 7, Iter: 39, Accuracy: 0.572 ===>\n",
            "====== Epoch 8 ======>\n",
            "[TRAIN] Epoch: 8, Iter: 0, Loss: 1.25683\n",
            "[TRAIN] Epoch: 8, Iter: 80, Loss: 1.31159\n",
            "[TRAIN] Epoch: 8, Iter: 160, Loss: 1.21264\n",
            "[TRAIN] Epoch: 8, Iter: 240, Loss: 1.29346\n",
            "[TRAIN] Epoch: 8, Iter: 320, Loss: 1.16549\n",
            "== [TRAIN] Epoch: 8, Accuracy: 0.546 ==>\n",
            "[VAL] Epoch: 8, Iter: 0, Loss: 1.23201\n",
            "=== [VAL] Epoch: 8, Iter: 39, Accuracy: 0.565 ===>\n",
            "====== Epoch 9 ======>\n",
            "[TRAIN] Epoch: 9, Iter: 0, Loss: 1.12786\n",
            "[TRAIN] Epoch: 9, Iter: 80, Loss: 1.04630\n",
            "[TRAIN] Epoch: 9, Iter: 160, Loss: 1.29415\n",
            "[TRAIN] Epoch: 9, Iter: 240, Loss: 1.18602\n",
            "[TRAIN] Epoch: 9, Iter: 320, Loss: 1.18782\n",
            "== [TRAIN] Epoch: 9, Accuracy: 0.556 ==>\n",
            "[VAL] Epoch: 9, Iter: 0, Loss: 1.30753\n",
            "=== [VAL] Epoch: 9, Iter: 39, Accuracy: 0.590 ===>\n",
            "====== Epoch 10 ======>\n",
            "[TRAIN] Epoch: 10, Iter: 0, Loss: 1.38063\n",
            "[TRAIN] Epoch: 10, Iter: 80, Loss: 1.09556\n",
            "[TRAIN] Epoch: 10, Iter: 160, Loss: 1.41527\n",
            "[TRAIN] Epoch: 10, Iter: 240, Loss: 1.03163\n",
            "[TRAIN] Epoch: 10, Iter: 320, Loss: 1.20586\n",
            "== [TRAIN] Epoch: 10, Accuracy: 0.562 ==>\n",
            "[VAL] Epoch: 10, Iter: 0, Loss: 1.26946\n",
            "=== [VAL] Epoch: 10, Iter: 39, Accuracy: 0.573 ===>\n",
            "====== Epoch 11 ======>\n",
            "[TRAIN] Epoch: 11, Iter: 0, Loss: 1.12967\n",
            "[TRAIN] Epoch: 11, Iter: 80, Loss: 1.00464\n",
            "[TRAIN] Epoch: 11, Iter: 160, Loss: 1.29561\n",
            "[TRAIN] Epoch: 11, Iter: 240, Loss: 1.25400\n",
            "[TRAIN] Epoch: 11, Iter: 320, Loss: 1.27119\n",
            "== [TRAIN] Epoch: 11, Accuracy: 0.571 ==>\n",
            "[VAL] Epoch: 11, Iter: 0, Loss: 1.20090\n",
            "=== [VAL] Epoch: 11, Iter: 39, Accuracy: 0.596 ===>\n",
            "====== Epoch 12 ======>\n",
            "[TRAIN] Epoch: 12, Iter: 0, Loss: 1.18169\n",
            "[TRAIN] Epoch: 12, Iter: 80, Loss: 1.23608\n",
            "[TRAIN] Epoch: 12, Iter: 160, Loss: 1.22595\n",
            "[TRAIN] Epoch: 12, Iter: 240, Loss: 1.24553\n",
            "[TRAIN] Epoch: 12, Iter: 320, Loss: 1.27582\n",
            "== [TRAIN] Epoch: 12, Accuracy: 0.580 ==>\n",
            "[VAL] Epoch: 12, Iter: 0, Loss: 1.23430\n",
            "=== [VAL] Epoch: 12, Iter: 39, Accuracy: 0.614 ===>\n",
            "====== Epoch 13 ======>\n",
            "[TRAIN] Epoch: 13, Iter: 0, Loss: 1.10075\n",
            "[TRAIN] Epoch: 13, Iter: 80, Loss: 1.34136\n",
            "[TRAIN] Epoch: 13, Iter: 160, Loss: 0.96405\n",
            "[TRAIN] Epoch: 13, Iter: 240, Loss: 1.18039\n",
            "[TRAIN] Epoch: 13, Iter: 320, Loss: 1.16741\n",
            "== [TRAIN] Epoch: 13, Accuracy: 0.587 ==>\n",
            "[VAL] Epoch: 13, Iter: 0, Loss: 1.08801\n",
            "=== [VAL] Epoch: 13, Iter: 39, Accuracy: 0.620 ===>\n",
            "====== Epoch 14 ======>\n",
            "[TRAIN] Epoch: 14, Iter: 0, Loss: 1.11382\n",
            "[TRAIN] Epoch: 14, Iter: 80, Loss: 1.18863\n",
            "[TRAIN] Epoch: 14, Iter: 160, Loss: 1.06402\n",
            "[TRAIN] Epoch: 14, Iter: 240, Loss: 1.18267\n",
            "[TRAIN] Epoch: 14, Iter: 320, Loss: 1.12985\n",
            "== [TRAIN] Epoch: 14, Accuracy: 0.592 ==>\n",
            "[VAL] Epoch: 14, Iter: 0, Loss: 1.13694\n",
            "=== [VAL] Epoch: 14, Iter: 39, Accuracy: 0.619 ===>\n",
            "====== Epoch 15 ======>\n",
            "[TRAIN] Epoch: 15, Iter: 0, Loss: 0.99409\n",
            "[TRAIN] Epoch: 15, Iter: 80, Loss: 0.92077\n",
            "[TRAIN] Epoch: 15, Iter: 160, Loss: 1.10097\n",
            "[TRAIN] Epoch: 15, Iter: 240, Loss: 1.11930\n",
            "[TRAIN] Epoch: 15, Iter: 320, Loss: 1.09797\n",
            "== [TRAIN] Epoch: 15, Accuracy: 0.597 ==>\n",
            "[VAL] Epoch: 15, Iter: 0, Loss: 1.08268\n",
            "=== [VAL] Epoch: 15, Iter: 39, Accuracy: 0.625 ===>\n",
            "====== Epoch 16 ======>\n",
            "[TRAIN] Epoch: 16, Iter: 0, Loss: 1.31890\n",
            "[TRAIN] Epoch: 16, Iter: 80, Loss: 1.44936\n",
            "[TRAIN] Epoch: 16, Iter: 160, Loss: 1.09174\n",
            "[TRAIN] Epoch: 16, Iter: 240, Loss: 1.25561\n",
            "[TRAIN] Epoch: 16, Iter: 320, Loss: 1.12181\n",
            "== [TRAIN] Epoch: 16, Accuracy: 0.602 ==>\n",
            "[VAL] Epoch: 16, Iter: 0, Loss: 1.06008\n",
            "=== [VAL] Epoch: 16, Iter: 39, Accuracy: 0.632 ===>\n",
            "====== Epoch 17 ======>\n",
            "[TRAIN] Epoch: 17, Iter: 0, Loss: 1.08192\n",
            "[TRAIN] Epoch: 17, Iter: 80, Loss: 1.32050\n",
            "[TRAIN] Epoch: 17, Iter: 160, Loss: 1.11690\n",
            "[TRAIN] Epoch: 17, Iter: 240, Loss: 1.02718\n",
            "[TRAIN] Epoch: 17, Iter: 320, Loss: 1.01140\n",
            "== [TRAIN] Epoch: 17, Accuracy: 0.607 ==>\n",
            "[VAL] Epoch: 17, Iter: 0, Loss: 1.07840\n",
            "=== [VAL] Epoch: 17, Iter: 39, Accuracy: 0.639 ===>\n",
            "====== Epoch 18 ======>\n",
            "[TRAIN] Epoch: 18, Iter: 0, Loss: 1.12407\n",
            "[TRAIN] Epoch: 18, Iter: 80, Loss: 1.06859\n",
            "[TRAIN] Epoch: 18, Iter: 160, Loss: 1.02481\n",
            "[TRAIN] Epoch: 18, Iter: 240, Loss: 1.10520\n",
            "[TRAIN] Epoch: 18, Iter: 320, Loss: 1.09184\n",
            "== [TRAIN] Epoch: 18, Accuracy: 0.614 ==>\n",
            "[VAL] Epoch: 18, Iter: 0, Loss: 1.03186\n",
            "=== [VAL] Epoch: 18, Iter: 39, Accuracy: 0.635 ===>\n",
            "====== Epoch 19 ======>\n",
            "[TRAIN] Epoch: 19, Iter: 0, Loss: 1.06717\n",
            "[TRAIN] Epoch: 19, Iter: 80, Loss: 1.11207\n",
            "[TRAIN] Epoch: 19, Iter: 160, Loss: 1.10214\n",
            "[TRAIN] Epoch: 19, Iter: 240, Loss: 0.92614\n",
            "[TRAIN] Epoch: 19, Iter: 320, Loss: 1.09459\n",
            "== [TRAIN] Epoch: 19, Accuracy: 0.620 ==>\n",
            "[VAL] Epoch: 19, Iter: 0, Loss: 1.07116\n",
            "=== [VAL] Epoch: 19, Iter: 39, Accuracy: 0.651 ===>\n",
            "====== Epoch 20 ======>\n",
            "[TRAIN] Epoch: 20, Iter: 0, Loss: 1.18058\n",
            "[TRAIN] Epoch: 20, Iter: 80, Loss: 0.97076\n",
            "[TRAIN] Epoch: 20, Iter: 160, Loss: 0.89474\n",
            "[TRAIN] Epoch: 20, Iter: 240, Loss: 0.97681\n",
            "[TRAIN] Epoch: 20, Iter: 320, Loss: 1.25204\n",
            "== [TRAIN] Epoch: 20, Accuracy: 0.620 ==>\n",
            "[VAL] Epoch: 20, Iter: 0, Loss: 1.01458\n",
            "=== [VAL] Epoch: 20, Iter: 39, Accuracy: 0.653 ===>\n",
            "====== Epoch 21 ======>\n",
            "[TRAIN] Epoch: 21, Iter: 0, Loss: 1.05141\n",
            "[TRAIN] Epoch: 21, Iter: 80, Loss: 1.03139\n",
            "[TRAIN] Epoch: 21, Iter: 160, Loss: 1.07157\n",
            "[TRAIN] Epoch: 21, Iter: 240, Loss: 1.04333\n",
            "[TRAIN] Epoch: 21, Iter: 320, Loss: 0.96213\n",
            "== [TRAIN] Epoch: 21, Accuracy: 0.630 ==>\n",
            "[VAL] Epoch: 21, Iter: 0, Loss: 1.00058\n",
            "=== [VAL] Epoch: 21, Iter: 39, Accuracy: 0.656 ===>\n",
            "====== Epoch 22 ======>\n",
            "[TRAIN] Epoch: 22, Iter: 0, Loss: 0.90879\n",
            "[TRAIN] Epoch: 22, Iter: 80, Loss: 1.11697\n",
            "[TRAIN] Epoch: 22, Iter: 160, Loss: 1.22682\n",
            "[TRAIN] Epoch: 22, Iter: 240, Loss: 1.06777\n",
            "[TRAIN] Epoch: 22, Iter: 320, Loss: 1.03169\n",
            "== [TRAIN] Epoch: 22, Accuracy: 0.638 ==>\n",
            "[VAL] Epoch: 22, Iter: 0, Loss: 1.00631\n",
            "=== [VAL] Epoch: 22, Iter: 39, Accuracy: 0.672 ===>\n",
            "====== Epoch 23 ======>\n",
            "[TRAIN] Epoch: 23, Iter: 0, Loss: 0.74774\n",
            "[TRAIN] Epoch: 23, Iter: 80, Loss: 1.04247\n",
            "[TRAIN] Epoch: 23, Iter: 160, Loss: 0.97584\n",
            "[TRAIN] Epoch: 23, Iter: 240, Loss: 0.84829\n",
            "[TRAIN] Epoch: 23, Iter: 320, Loss: 1.07142\n",
            "== [TRAIN] Epoch: 23, Accuracy: 0.641 ==>\n",
            "[VAL] Epoch: 23, Iter: 0, Loss: 0.92360\n",
            "=== [VAL] Epoch: 23, Iter: 39, Accuracy: 0.670 ===>\n",
            "====== Epoch 24 ======>\n",
            "[TRAIN] Epoch: 24, Iter: 0, Loss: 1.05695\n",
            "[TRAIN] Epoch: 24, Iter: 80, Loss: 1.11687\n",
            "[TRAIN] Epoch: 24, Iter: 160, Loss: 0.88338\n",
            "[TRAIN] Epoch: 24, Iter: 240, Loss: 0.98073\n",
            "[TRAIN] Epoch: 24, Iter: 320, Loss: 0.86713\n",
            "== [TRAIN] Epoch: 24, Accuracy: 0.646 ==>\n",
            "[VAL] Epoch: 24, Iter: 0, Loss: 0.96794\n",
            "=== [VAL] Epoch: 24, Iter: 39, Accuracy: 0.673 ===>\n",
            "====== Epoch 25 ======>\n",
            "[TRAIN] Epoch: 25, Iter: 0, Loss: 0.76764\n",
            "[TRAIN] Epoch: 25, Iter: 80, Loss: 0.84743\n",
            "[TRAIN] Epoch: 25, Iter: 160, Loss: 0.86184\n",
            "[TRAIN] Epoch: 25, Iter: 240, Loss: 0.98610\n",
            "[TRAIN] Epoch: 25, Iter: 320, Loss: 1.08985\n",
            "== [TRAIN] Epoch: 25, Accuracy: 0.647 ==>\n",
            "[VAL] Epoch: 25, Iter: 0, Loss: 0.87166\n",
            "=== [VAL] Epoch: 25, Iter: 39, Accuracy: 0.677 ===>\n",
            "====== Epoch 26 ======>\n",
            "[TRAIN] Epoch: 26, Iter: 0, Loss: 0.90656\n",
            "[TRAIN] Epoch: 26, Iter: 80, Loss: 0.99314\n",
            "[TRAIN] Epoch: 26, Iter: 160, Loss: 0.95778\n",
            "[TRAIN] Epoch: 26, Iter: 240, Loss: 1.01269\n",
            "[TRAIN] Epoch: 26, Iter: 320, Loss: 0.85794\n",
            "== [TRAIN] Epoch: 26, Accuracy: 0.655 ==>\n",
            "[VAL] Epoch: 26, Iter: 0, Loss: 0.86972\n",
            "=== [VAL] Epoch: 26, Iter: 39, Accuracy: 0.679 ===>\n",
            "====== Epoch 27 ======>\n",
            "[TRAIN] Epoch: 27, Iter: 0, Loss: 0.95322\n",
            "[TRAIN] Epoch: 27, Iter: 80, Loss: 0.85552\n",
            "[TRAIN] Epoch: 27, Iter: 160, Loss: 0.96087\n",
            "[TRAIN] Epoch: 27, Iter: 240, Loss: 0.86813\n",
            "[TRAIN] Epoch: 27, Iter: 320, Loss: 1.10758\n",
            "== [TRAIN] Epoch: 27, Accuracy: 0.657 ==>\n",
            "[VAL] Epoch: 27, Iter: 0, Loss: 0.84338\n",
            "=== [VAL] Epoch: 27, Iter: 39, Accuracy: 0.690 ===>\n",
            "====== Epoch 28 ======>\n",
            "[TRAIN] Epoch: 28, Iter: 0, Loss: 0.91563\n",
            "[TRAIN] Epoch: 28, Iter: 80, Loss: 1.02294\n",
            "[TRAIN] Epoch: 28, Iter: 160, Loss: 1.11381\n",
            "[TRAIN] Epoch: 28, Iter: 240, Loss: 0.81749\n",
            "[TRAIN] Epoch: 28, Iter: 320, Loss: 1.01080\n",
            "== [TRAIN] Epoch: 28, Accuracy: 0.666 ==>\n",
            "[VAL] Epoch: 28, Iter: 0, Loss: 0.79803\n",
            "=== [VAL] Epoch: 28, Iter: 39, Accuracy: 0.698 ===>\n",
            "====== Epoch 29 ======>\n",
            "[TRAIN] Epoch: 29, Iter: 0, Loss: 0.80925\n",
            "[TRAIN] Epoch: 29, Iter: 80, Loss: 0.80105\n",
            "[TRAIN] Epoch: 29, Iter: 160, Loss: 1.07164\n",
            "[TRAIN] Epoch: 29, Iter: 240, Loss: 0.92607\n",
            "[TRAIN] Epoch: 29, Iter: 320, Loss: 0.84940\n",
            "== [TRAIN] Epoch: 29, Accuracy: 0.667 ==>\n",
            "[VAL] Epoch: 29, Iter: 0, Loss: 0.90007\n",
            "=== [VAL] Epoch: 29, Iter: 39, Accuracy: 0.698 ===>\n",
            "[TEST] Epoch: 29, Iter: 0, Loss: 1.16654\n",
            "=== [TEST] Epoch: 29, Iter: 78, Accuracy: 0.575 ===>\n",
            "===== Best validation Accuracy: 0.698 =====>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Train Losses  Valid Losses  Train accs  Valid accs  Epoch  \\\n",
              "0       1.803233      1.646389    0.358351    0.413281      1   \n",
              "1       1.598008      1.509481    0.429754    0.470508      2   \n",
              "2       1.516049      1.468630    0.457755    0.471875      3   \n",
              "3       1.454481      1.411595    0.480970    0.498047      4   \n",
              "4       1.403588      1.340204    0.498598    0.533008      5   \n",
              "5       1.368076      1.307345    0.513867    0.540625      6   \n",
              "6       1.329773      1.247441    0.528178    0.563477      7   \n",
              "7       1.308459      1.235954    0.536903    0.572461      8   \n",
              "8       1.278932      1.222591    0.546497    0.565234      9   \n",
              "9       1.251271      1.184694    0.556023    0.589648     10   \n",
              "10      1.234088      1.173652    0.561521    0.573242     11   \n",
              "11      1.208830      1.155473    0.571025    0.595703     12   \n",
              "12      1.188082      1.127641    0.579594    0.613672     13   \n",
              "13      1.165859      1.085494    0.586850    0.619531     14   \n",
              "14      1.149613      1.073280    0.591725    0.618555     15   \n",
              "15      1.133237      1.063408    0.597066    0.625195     16   \n",
              "16      1.120155      1.031045    0.601807    0.632227     17   \n",
              "17      1.100682      1.020062    0.606927    0.638672     18   \n",
              "18      1.078973      1.028373    0.614494    0.634766     19   \n",
              "19      1.068699      0.995424    0.620281    0.651367     20   \n",
              "20      1.057734      0.971332    0.620459    0.652734     21   \n",
              "21      1.041965      0.958212    0.630253    0.656445     22   \n",
              "22      1.025301      0.931256    0.638355    0.672070     23   \n",
              "23      1.012890      0.925086    0.641471    0.669531     24   \n",
              "24      1.000560      0.925821    0.646145    0.673438     25   \n",
              "25      0.987718      0.924745    0.647280    0.676562     26   \n",
              "26      0.975746      0.893142    0.655137    0.679102     27   \n",
              "27      0.962686      0.878649    0.657140    0.689648     28   \n",
              "28      0.944336      0.857370    0.665687    0.697656     29   \n",
              "29      0.939555      0.851859    0.667179    0.698242     30   \n",
              "\n",
              "   Activation Function  \n",
              "0                 ReLU  \n",
              "1                 ReLU  \n",
              "2                 ReLU  \n",
              "3                 ReLU  \n",
              "4                 ReLU  \n",
              "5                 ReLU  \n",
              "6                 ReLU  \n",
              "7                 ReLU  \n",
              "8                 ReLU  \n",
              "9                 ReLU  \n",
              "10                ReLU  \n",
              "11                ReLU  \n",
              "12                ReLU  \n",
              "13                ReLU  \n",
              "14                ReLU  \n",
              "15                ReLU  \n",
              "16                ReLU  \n",
              "17                ReLU  \n",
              "18                ReLU  \n",
              "19                ReLU  \n",
              "20                ReLU  \n",
              "21                ReLU  \n",
              "22                ReLU  \n",
              "23                ReLU  \n",
              "24                ReLU  \n",
              "25                ReLU  \n",
              "26                ReLU  \n",
              "27                ReLU  \n",
              "28                ReLU  \n",
              "29                ReLU  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1ba5990f-af55-40d7-9586-a19824992848\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train Losses</th>\n",
              "      <th>Valid Losses</th>\n",
              "      <th>Train accs</th>\n",
              "      <th>Valid accs</th>\n",
              "      <th>Epoch</th>\n",
              "      <th>Activation Function</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.803233</td>\n",
              "      <td>1.646389</td>\n",
              "      <td>0.358351</td>\n",
              "      <td>0.413281</td>\n",
              "      <td>1</td>\n",
              "      <td>ReLU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.598008</td>\n",
              "      <td>1.509481</td>\n",
              "      <td>0.429754</td>\n",
              "      <td>0.470508</td>\n",
              "      <td>2</td>\n",
              "      <td>ReLU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.516049</td>\n",
              "      <td>1.468630</td>\n",
              "      <td>0.457755</td>\n",
              "      <td>0.471875</td>\n",
              "      <td>3</td>\n",
              "      <td>ReLU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.454481</td>\n",
              "      <td>1.411595</td>\n",
              "      <td>0.480970</td>\n",
              "      <td>0.498047</td>\n",
              "      <td>4</td>\n",
              "      <td>ReLU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.403588</td>\n",
              "      <td>1.340204</td>\n",
              "      <td>0.498598</td>\n",
              "      <td>0.533008</td>\n",
              "      <td>5</td>\n",
              "      <td>ReLU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.368076</td>\n",
              "      <td>1.307345</td>\n",
              "      <td>0.513867</td>\n",
              "      <td>0.540625</td>\n",
              "      <td>6</td>\n",
              "      <td>ReLU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.329773</td>\n",
              "      <td>1.247441</td>\n",
              "      <td>0.528178</td>\n",
              "      <td>0.563477</td>\n",
              "      <td>7</td>\n",
              "      <td>ReLU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.308459</td>\n",
              "      <td>1.235954</td>\n",
              "      <td>0.536903</td>\n",
              "      <td>0.572461</td>\n",
              "      <td>8</td>\n",
              "      <td>ReLU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.278932</td>\n",
              "      <td>1.222591</td>\n",
              "      <td>0.546497</td>\n",
              "      <td>0.565234</td>\n",
              "      <td>9</td>\n",
              "      <td>ReLU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.251271</td>\n",
              "      <td>1.184694</td>\n",
              "      <td>0.556023</td>\n",
              "      <td>0.589648</td>\n",
              "      <td>10</td>\n",
              "      <td>ReLU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1.234088</td>\n",
              "      <td>1.173652</td>\n",
              "      <td>0.561521</td>\n",
              "      <td>0.573242</td>\n",
              "      <td>11</td>\n",
              "      <td>ReLU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.208830</td>\n",
              "      <td>1.155473</td>\n",
              "      <td>0.571025</td>\n",
              "      <td>0.595703</td>\n",
              "      <td>12</td>\n",
              "      <td>ReLU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1.188082</td>\n",
              "      <td>1.127641</td>\n",
              "      <td>0.579594</td>\n",
              "      <td>0.613672</td>\n",
              "      <td>13</td>\n",
              "      <td>ReLU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1.165859</td>\n",
              "      <td>1.085494</td>\n",
              "      <td>0.586850</td>\n",
              "      <td>0.619531</td>\n",
              "      <td>14</td>\n",
              "      <td>ReLU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1.149613</td>\n",
              "      <td>1.073280</td>\n",
              "      <td>0.591725</td>\n",
              "      <td>0.618555</td>\n",
              "      <td>15</td>\n",
              "      <td>ReLU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1.133237</td>\n",
              "      <td>1.063408</td>\n",
              "      <td>0.597066</td>\n",
              "      <td>0.625195</td>\n",
              "      <td>16</td>\n",
              "      <td>ReLU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1.120155</td>\n",
              "      <td>1.031045</td>\n",
              "      <td>0.601807</td>\n",
              "      <td>0.632227</td>\n",
              "      <td>17</td>\n",
              "      <td>ReLU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.100682</td>\n",
              "      <td>1.020062</td>\n",
              "      <td>0.606927</td>\n",
              "      <td>0.638672</td>\n",
              "      <td>18</td>\n",
              "      <td>ReLU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1.078973</td>\n",
              "      <td>1.028373</td>\n",
              "      <td>0.614494</td>\n",
              "      <td>0.634766</td>\n",
              "      <td>19</td>\n",
              "      <td>ReLU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1.068699</td>\n",
              "      <td>0.995424</td>\n",
              "      <td>0.620281</td>\n",
              "      <td>0.651367</td>\n",
              "      <td>20</td>\n",
              "      <td>ReLU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1.057734</td>\n",
              "      <td>0.971332</td>\n",
              "      <td>0.620459</td>\n",
              "      <td>0.652734</td>\n",
              "      <td>21</td>\n",
              "      <td>ReLU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1.041965</td>\n",
              "      <td>0.958212</td>\n",
              "      <td>0.630253</td>\n",
              "      <td>0.656445</td>\n",
              "      <td>22</td>\n",
              "      <td>ReLU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1.025301</td>\n",
              "      <td>0.931256</td>\n",
              "      <td>0.638355</td>\n",
              "      <td>0.672070</td>\n",
              "      <td>23</td>\n",
              "      <td>ReLU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1.012890</td>\n",
              "      <td>0.925086</td>\n",
              "      <td>0.641471</td>\n",
              "      <td>0.669531</td>\n",
              "      <td>24</td>\n",
              "      <td>ReLU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1.000560</td>\n",
              "      <td>0.925821</td>\n",
              "      <td>0.646145</td>\n",
              "      <td>0.673438</td>\n",
              "      <td>25</td>\n",
              "      <td>ReLU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.987718</td>\n",
              "      <td>0.924745</td>\n",
              "      <td>0.647280</td>\n",
              "      <td>0.676562</td>\n",
              "      <td>26</td>\n",
              "      <td>ReLU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.975746</td>\n",
              "      <td>0.893142</td>\n",
              "      <td>0.655137</td>\n",
              "      <td>0.679102</td>\n",
              "      <td>27</td>\n",
              "      <td>ReLU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.962686</td>\n",
              "      <td>0.878649</td>\n",
              "      <td>0.657140</td>\n",
              "      <td>0.689648</td>\n",
              "      <td>28</td>\n",
              "      <td>ReLU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.944336</td>\n",
              "      <td>0.857370</td>\n",
              "      <td>0.665687</td>\n",
              "      <td>0.697656</td>\n",
              "      <td>29</td>\n",
              "      <td>ReLU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.939555</td>\n",
              "      <td>0.851859</td>\n",
              "      <td>0.667179</td>\n",
              "      <td>0.698242</td>\n",
              "      <td>30</td>\n",
              "      <td>ReLU</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ba5990f-af55-40d7-9586-a19824992848')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1ba5990f-af55-40d7-9586-a19824992848 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1ba5990f-af55-40d7-9586-a19824992848');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3daba569-65a0-4117-9b5b-f7f8baf0a093\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3daba569-65a0-4117-9b5b-f7f8baf0a093')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3daba569-65a0-4117-9b5b-f7f8baf0a093 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_17c1fa86-6a1c-484a-ad12-db649d56b787\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_relu')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_17c1fa86-6a1c-484a-ad12-db649d56b787 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_relu');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_relu",
              "summary": "{\n  \"name\": \"df_relu\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": \"Train Losses\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21044582068217205,\n        \"min\": 0.9395548224109536,\n        \"max\": 1.8032325876404405,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          0.9626856879291367,\n          1.133237011751897,\n          1.0128900322139764\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Valid Losses\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20872679756483373,\n        \"min\": 0.8518591746687891,\n        \"max\": 1.6463890045881275,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          0.8786493405699726,\n          1.0634083211421967,\n          0.9250860407948492\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train accs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07545359787173025,\n        \"min\": 0.3583511396011393,\n        \"max\": 0.667178596866096,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          0.6571403133903132,\n          0.5970664173789177,\n          0.6414707977207976\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Valid accs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07383587657386337,\n        \"min\": 0.41328125,\n        \"max\": 0.6982421874999999,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          0.6896484374999999,\n          0.6251953125000002,\n          0.6695312499999999\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 1,\n        \"max\": 30,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          28,\n          16,\n          24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Activation Function\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"ReLU\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ZyJPWO1ppcTx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aa9a83cc-54f8-4cde-e98d-42e17214c3d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Build model MLP...\n",
            "Loading model config from /content/IFT6135-2025-First-Assignment/HW1_2025/assignment1_release/model_configs/mlp_tanh.json\n",
            "########## MLP CONFIG ################\n",
            "input_size:\t3072\n",
            "hidden_sizes:\t[1024, 512, 64, 64]\n",
            "num_classes:\t10\n",
            "activation:\ttanh\n",
            "############################################\n",
            "Initialized MLP model with 3709194 total parameters, of which 3709194 are learnable.\n",
            "====== Epoch 0 ======>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN] Epoch: 0, Iter: 0, Loss: 2.48179\n",
            "[TRAIN] Epoch: 0, Iter: 80, Loss: 1.90319\n",
            "[TRAIN] Epoch: 0, Iter: 160, Loss: 1.67422\n",
            "[TRAIN] Epoch: 0, Iter: 240, Loss: 1.71224\n",
            "[TRAIN] Epoch: 0, Iter: 320, Loss: 1.88699\n",
            "== [TRAIN] Epoch: 0, Accuracy: 0.341 ==>\n",
            "[VAL] Epoch: 0, Iter: 0, Loss: 1.88315\n",
            "=== [VAL] Epoch: 0, Iter: 39, Accuracy: 0.378 ===>\n",
            "====== Epoch 1 ======>\n",
            "[TRAIN] Epoch: 1, Iter: 0, Loss: 1.84177\n",
            "[TRAIN] Epoch: 1, Iter: 80, Loss: 1.67996\n",
            "[TRAIN] Epoch: 1, Iter: 160, Loss: 1.81169\n",
            "[TRAIN] Epoch: 1, Iter: 240, Loss: 1.81872\n",
            "[TRAIN] Epoch: 1, Iter: 320, Loss: 1.84161\n",
            "== [TRAIN] Epoch: 1, Accuracy: 0.385 ==>\n",
            "[VAL] Epoch: 1, Iter: 0, Loss: 1.69675\n",
            "=== [VAL] Epoch: 1, Iter: 39, Accuracy: 0.404 ===>\n",
            "====== Epoch 2 ======>\n",
            "[TRAIN] Epoch: 2, Iter: 0, Loss: 1.72600\n",
            "[TRAIN] Epoch: 2, Iter: 80, Loss: 1.83291\n",
            "[TRAIN] Epoch: 2, Iter: 160, Loss: 1.60202\n",
            "[TRAIN] Epoch: 2, Iter: 240, Loss: 1.75192\n",
            "[TRAIN] Epoch: 2, Iter: 320, Loss: 1.80821\n",
            "== [TRAIN] Epoch: 2, Accuracy: 0.400 ==>\n",
            "[VAL] Epoch: 2, Iter: 0, Loss: 1.68978\n",
            "=== [VAL] Epoch: 2, Iter: 39, Accuracy: 0.419 ===>\n",
            "====== Epoch 3 ======>\n",
            "[TRAIN] Epoch: 3, Iter: 0, Loss: 1.75641\n",
            "[TRAIN] Epoch: 3, Iter: 80, Loss: 1.63581\n",
            "[TRAIN] Epoch: 3, Iter: 160, Loss: 1.76197\n",
            "[TRAIN] Epoch: 3, Iter: 240, Loss: 1.60200\n",
            "[TRAIN] Epoch: 3, Iter: 320, Loss: 1.54162\n",
            "== [TRAIN] Epoch: 3, Accuracy: 0.415 ==>\n",
            "[VAL] Epoch: 3, Iter: 0, Loss: 1.62841\n",
            "=== [VAL] Epoch: 3, Iter: 39, Accuracy: 0.430 ===>\n",
            "====== Epoch 4 ======>\n",
            "[TRAIN] Epoch: 4, Iter: 0, Loss: 1.53521\n",
            "[TRAIN] Epoch: 4, Iter: 80, Loss: 1.68016\n",
            "[TRAIN] Epoch: 4, Iter: 160, Loss: 1.87447\n",
            "[TRAIN] Epoch: 4, Iter: 240, Loss: 1.60830\n",
            "[TRAIN] Epoch: 4, Iter: 320, Loss: 1.60755\n",
            "== [TRAIN] Epoch: 4, Accuracy: 0.426 ==>\n",
            "[VAL] Epoch: 4, Iter: 0, Loss: 1.61981\n",
            "=== [VAL] Epoch: 4, Iter: 39, Accuracy: 0.452 ===>\n",
            "====== Epoch 5 ======>\n",
            "[TRAIN] Epoch: 5, Iter: 0, Loss: 1.72056\n",
            "[TRAIN] Epoch: 5, Iter: 80, Loss: 1.61453\n",
            "[TRAIN] Epoch: 5, Iter: 160, Loss: 1.78300\n",
            "[TRAIN] Epoch: 5, Iter: 240, Loss: 1.65011\n",
            "[TRAIN] Epoch: 5, Iter: 320, Loss: 1.59539\n",
            "== [TRAIN] Epoch: 5, Accuracy: 0.426 ==>\n",
            "[VAL] Epoch: 5, Iter: 0, Loss: 1.61916\n",
            "=== [VAL] Epoch: 5, Iter: 39, Accuracy: 0.445 ===>\n",
            "====== Epoch 6 ======>\n",
            "[TRAIN] Epoch: 6, Iter: 0, Loss: 1.48910\n",
            "[TRAIN] Epoch: 6, Iter: 80, Loss: 1.51635\n",
            "[TRAIN] Epoch: 6, Iter: 160, Loss: 1.74220\n",
            "[TRAIN] Epoch: 6, Iter: 240, Loss: 1.64196\n",
            "[TRAIN] Epoch: 6, Iter: 320, Loss: 1.70508\n",
            "== [TRAIN] Epoch: 6, Accuracy: 0.435 ==>\n",
            "[VAL] Epoch: 6, Iter: 0, Loss: 1.64808\n",
            "=== [VAL] Epoch: 6, Iter: 39, Accuracy: 0.450 ===>\n",
            "====== Epoch 7 ======>\n",
            "[TRAIN] Epoch: 7, Iter: 0, Loss: 1.54593\n",
            "[TRAIN] Epoch: 7, Iter: 80, Loss: 1.51907\n",
            "[TRAIN] Epoch: 7, Iter: 160, Loss: 1.48141\n",
            "[TRAIN] Epoch: 7, Iter: 240, Loss: 1.67469\n",
            "[TRAIN] Epoch: 7, Iter: 320, Loss: 1.54198\n",
            "== [TRAIN] Epoch: 7, Accuracy: 0.435 ==>\n",
            "[VAL] Epoch: 7, Iter: 0, Loss: 1.60484\n",
            "=== [VAL] Epoch: 7, Iter: 39, Accuracy: 0.459 ===>\n",
            "====== Epoch 8 ======>\n",
            "[TRAIN] Epoch: 8, Iter: 0, Loss: 1.52079\n",
            "[TRAIN] Epoch: 8, Iter: 80, Loss: 1.70693\n",
            "[TRAIN] Epoch: 8, Iter: 160, Loss: 1.60410\n",
            "[TRAIN] Epoch: 8, Iter: 240, Loss: 1.61662\n",
            "[TRAIN] Epoch: 8, Iter: 320, Loss: 1.45670\n",
            "== [TRAIN] Epoch: 8, Accuracy: 0.441 ==>\n",
            "[VAL] Epoch: 8, Iter: 0, Loss: 1.57761\n",
            "=== [VAL] Epoch: 8, Iter: 39, Accuracy: 0.460 ===>\n",
            "====== Epoch 9 ======>\n",
            "[TRAIN] Epoch: 9, Iter: 0, Loss: 1.49358\n",
            "[TRAIN] Epoch: 9, Iter: 80, Loss: 1.43264\n",
            "[TRAIN] Epoch: 9, Iter: 160, Loss: 1.57617\n",
            "[TRAIN] Epoch: 9, Iter: 240, Loss: 1.47112\n",
            "[TRAIN] Epoch: 9, Iter: 320, Loss: 1.56013\n",
            "== [TRAIN] Epoch: 9, Accuracy: 0.445 ==>\n",
            "[VAL] Epoch: 9, Iter: 0, Loss: 1.54165\n",
            "=== [VAL] Epoch: 9, Iter: 39, Accuracy: 0.457 ===>\n",
            "====== Epoch 10 ======>\n",
            "[TRAIN] Epoch: 10, Iter: 0, Loss: 1.71432\n",
            "[TRAIN] Epoch: 10, Iter: 80, Loss: 1.46700\n",
            "[TRAIN] Epoch: 10, Iter: 160, Loss: 1.70262\n",
            "[TRAIN] Epoch: 10, Iter: 240, Loss: 1.54969\n",
            "[TRAIN] Epoch: 10, Iter: 320, Loss: 1.57956\n",
            "== [TRAIN] Epoch: 10, Accuracy: 0.448 ==>\n",
            "[VAL] Epoch: 10, Iter: 0, Loss: 1.69784\n",
            "=== [VAL] Epoch: 10, Iter: 39, Accuracy: 0.448 ===>\n",
            "====== Epoch 11 ======>\n",
            "[TRAIN] Epoch: 11, Iter: 0, Loss: 1.55526\n",
            "[TRAIN] Epoch: 11, Iter: 80, Loss: 1.38614\n",
            "[TRAIN] Epoch: 11, Iter: 160, Loss: 1.64587\n",
            "[TRAIN] Epoch: 11, Iter: 240, Loss: 1.49481\n",
            "[TRAIN] Epoch: 11, Iter: 320, Loss: 1.64515\n",
            "== [TRAIN] Epoch: 11, Accuracy: 0.453 ==>\n",
            "[VAL] Epoch: 11, Iter: 0, Loss: 1.56569\n",
            "=== [VAL] Epoch: 11, Iter: 39, Accuracy: 0.446 ===>\n",
            "====== Epoch 12 ======>\n",
            "[TRAIN] Epoch: 12, Iter: 0, Loss: 1.62605\n",
            "[TRAIN] Epoch: 12, Iter: 80, Loss: 1.58925\n",
            "[TRAIN] Epoch: 12, Iter: 160, Loss: 1.57588\n",
            "[TRAIN] Epoch: 12, Iter: 240, Loss: 1.50423\n",
            "[TRAIN] Epoch: 12, Iter: 320, Loss: 1.53374\n",
            "== [TRAIN] Epoch: 12, Accuracy: 0.454 ==>\n",
            "[VAL] Epoch: 12, Iter: 0, Loss: 1.52410\n",
            "=== [VAL] Epoch: 12, Iter: 39, Accuracy: 0.477 ===>\n",
            "====== Epoch 13 ======>\n",
            "[TRAIN] Epoch: 13, Iter: 0, Loss: 1.46896\n",
            "[TRAIN] Epoch: 13, Iter: 80, Loss: 1.61645\n",
            "[TRAIN] Epoch: 13, Iter: 160, Loss: 1.40240\n",
            "[TRAIN] Epoch: 13, Iter: 240, Loss: 1.60393\n",
            "[TRAIN] Epoch: 13, Iter: 320, Loss: 1.54143\n",
            "== [TRAIN] Epoch: 13, Accuracy: 0.458 ==>\n",
            "[VAL] Epoch: 13, Iter: 0, Loss: 1.61112\n",
            "=== [VAL] Epoch: 13, Iter: 39, Accuracy: 0.460 ===>\n",
            "====== Epoch 14 ======>\n",
            "[TRAIN] Epoch: 14, Iter: 0, Loss: 1.56584\n",
            "[TRAIN] Epoch: 14, Iter: 80, Loss: 1.49033\n",
            "[TRAIN] Epoch: 14, Iter: 160, Loss: 1.48920\n",
            "[TRAIN] Epoch: 14, Iter: 240, Loss: 1.47067\n",
            "[TRAIN] Epoch: 14, Iter: 320, Loss: 1.40121\n",
            "== [TRAIN] Epoch: 14, Accuracy: 0.458 ==>\n",
            "[VAL] Epoch: 14, Iter: 0, Loss: 1.59963\n",
            "=== [VAL] Epoch: 14, Iter: 39, Accuracy: 0.470 ===>\n",
            "====== Epoch 15 ======>\n",
            "[TRAIN] Epoch: 15, Iter: 0, Loss: 1.44061\n",
            "[TRAIN] Epoch: 15, Iter: 80, Loss: 1.30457\n",
            "[TRAIN] Epoch: 15, Iter: 160, Loss: 1.51408\n",
            "[TRAIN] Epoch: 15, Iter: 240, Loss: 1.57183\n",
            "[TRAIN] Epoch: 15, Iter: 320, Loss: 1.50231\n",
            "== [TRAIN] Epoch: 15, Accuracy: 0.462 ==>\n",
            "[VAL] Epoch: 15, Iter: 0, Loss: 1.55137\n",
            "=== [VAL] Epoch: 15, Iter: 39, Accuracy: 0.478 ===>\n",
            "====== Epoch 16 ======>\n",
            "[TRAIN] Epoch: 16, Iter: 0, Loss: 1.76016\n",
            "[TRAIN] Epoch: 16, Iter: 80, Loss: 1.81020\n",
            "[TRAIN] Epoch: 16, Iter: 160, Loss: 1.64347\n",
            "[TRAIN] Epoch: 16, Iter: 240, Loss: 1.73161\n",
            "[TRAIN] Epoch: 16, Iter: 320, Loss: 1.49902\n",
            "== [TRAIN] Epoch: 16, Accuracy: 0.463 ==>\n",
            "[VAL] Epoch: 16, Iter: 0, Loss: 1.47190\n",
            "=== [VAL] Epoch: 16, Iter: 39, Accuracy: 0.495 ===>\n",
            "====== Epoch 17 ======>\n",
            "[TRAIN] Epoch: 17, Iter: 0, Loss: 1.50164\n",
            "[TRAIN] Epoch: 17, Iter: 80, Loss: 1.68912\n",
            "[TRAIN] Epoch: 17, Iter: 160, Loss: 1.43200\n",
            "[TRAIN] Epoch: 17, Iter: 240, Loss: 1.45090\n",
            "[TRAIN] Epoch: 17, Iter: 320, Loss: 1.41704\n",
            "== [TRAIN] Epoch: 17, Accuracy: 0.469 ==>\n",
            "[VAL] Epoch: 17, Iter: 0, Loss: 1.45881\n",
            "=== [VAL] Epoch: 17, Iter: 39, Accuracy: 0.470 ===>\n",
            "====== Epoch 18 ======>\n",
            "[TRAIN] Epoch: 18, Iter: 0, Loss: 1.54326\n",
            "[TRAIN] Epoch: 18, Iter: 80, Loss: 1.53829\n",
            "[TRAIN] Epoch: 18, Iter: 160, Loss: 1.43190\n",
            "[TRAIN] Epoch: 18, Iter: 240, Loss: 1.58653\n",
            "[TRAIN] Epoch: 18, Iter: 320, Loss: 1.56982\n",
            "== [TRAIN] Epoch: 18, Accuracy: 0.468 ==>\n",
            "[VAL] Epoch: 18, Iter: 0, Loss: 1.54378\n",
            "=== [VAL] Epoch: 18, Iter: 39, Accuracy: 0.486 ===>\n",
            "====== Epoch 19 ======>\n",
            "[TRAIN] Epoch: 19, Iter: 0, Loss: 1.46193\n",
            "[TRAIN] Epoch: 19, Iter: 80, Loss: 1.43489\n",
            "[TRAIN] Epoch: 19, Iter: 160, Loss: 1.43068\n",
            "[TRAIN] Epoch: 19, Iter: 240, Loss: 1.28853\n",
            "[TRAIN] Epoch: 19, Iter: 320, Loss: 1.58812\n",
            "== [TRAIN] Epoch: 19, Accuracy: 0.469 ==>\n",
            "[VAL] Epoch: 19, Iter: 0, Loss: 1.51825\n",
            "=== [VAL] Epoch: 19, Iter: 39, Accuracy: 0.488 ===>\n",
            "====== Epoch 20 ======>\n",
            "[TRAIN] Epoch: 20, Iter: 0, Loss: 1.34444\n",
            "[TRAIN] Epoch: 20, Iter: 80, Loss: 1.37011\n",
            "[TRAIN] Epoch: 20, Iter: 160, Loss: 1.40702\n",
            "[TRAIN] Epoch: 20, Iter: 240, Loss: 1.53699\n",
            "[TRAIN] Epoch: 20, Iter: 320, Loss: 1.63960\n",
            "== [TRAIN] Epoch: 20, Accuracy: 0.470 ==>\n",
            "[VAL] Epoch: 20, Iter: 0, Loss: 1.49404\n",
            "=== [VAL] Epoch: 20, Iter: 39, Accuracy: 0.469 ===>\n",
            "====== Epoch 21 ======>\n",
            "[TRAIN] Epoch: 21, Iter: 0, Loss: 1.53168\n",
            "[TRAIN] Epoch: 21, Iter: 80, Loss: 1.49903\n",
            "[TRAIN] Epoch: 21, Iter: 160, Loss: 1.40314\n",
            "[TRAIN] Epoch: 21, Iter: 240, Loss: 1.46448\n",
            "[TRAIN] Epoch: 21, Iter: 320, Loss: 1.37737\n",
            "== [TRAIN] Epoch: 21, Accuracy: 0.469 ==>\n",
            "[VAL] Epoch: 21, Iter: 0, Loss: 1.42317\n",
            "=== [VAL] Epoch: 21, Iter: 39, Accuracy: 0.483 ===>\n",
            "====== Epoch 22 ======>\n",
            "[TRAIN] Epoch: 22, Iter: 0, Loss: 1.44922\n",
            "[TRAIN] Epoch: 22, Iter: 80, Loss: 1.57068\n",
            "[TRAIN] Epoch: 22, Iter: 160, Loss: 1.72101\n",
            "[TRAIN] Epoch: 22, Iter: 240, Loss: 1.56683\n",
            "[TRAIN] Epoch: 22, Iter: 320, Loss: 1.54372\n",
            "== [TRAIN] Epoch: 22, Accuracy: 0.472 ==>\n",
            "[VAL] Epoch: 22, Iter: 0, Loss: 1.46381\n",
            "=== [VAL] Epoch: 22, Iter: 39, Accuracy: 0.493 ===>\n",
            "====== Epoch 23 ======>\n",
            "[TRAIN] Epoch: 23, Iter: 0, Loss: 1.29522\n",
            "[TRAIN] Epoch: 23, Iter: 80, Loss: 1.52379\n",
            "[TRAIN] Epoch: 23, Iter: 160, Loss: 1.48933\n",
            "[TRAIN] Epoch: 23, Iter: 240, Loss: 1.52105\n",
            "[TRAIN] Epoch: 23, Iter: 320, Loss: 1.64296\n",
            "== [TRAIN] Epoch: 23, Accuracy: 0.473 ==>\n",
            "[VAL] Epoch: 23, Iter: 0, Loss: 1.45090\n",
            "=== [VAL] Epoch: 23, Iter: 39, Accuracy: 0.481 ===>\n",
            "====== Epoch 24 ======>\n",
            "[TRAIN] Epoch: 24, Iter: 0, Loss: 1.51784\n",
            "[TRAIN] Epoch: 24, Iter: 80, Loss: 1.64822\n",
            "[TRAIN] Epoch: 24, Iter: 160, Loss: 1.44058\n",
            "[TRAIN] Epoch: 24, Iter: 240, Loss: 1.54072\n",
            "[TRAIN] Epoch: 24, Iter: 320, Loss: 1.34883\n",
            "== [TRAIN] Epoch: 24, Accuracy: 0.476 ==>\n",
            "[VAL] Epoch: 24, Iter: 0, Loss: 1.50224\n",
            "=== [VAL] Epoch: 24, Iter: 39, Accuracy: 0.501 ===>\n",
            "====== Epoch 25 ======>\n",
            "[TRAIN] Epoch: 25, Iter: 0, Loss: 1.34907\n",
            "[TRAIN] Epoch: 25, Iter: 80, Loss: 1.37111\n",
            "[TRAIN] Epoch: 25, Iter: 160, Loss: 1.52634\n",
            "[TRAIN] Epoch: 25, Iter: 240, Loss: 1.52675\n",
            "[TRAIN] Epoch: 25, Iter: 320, Loss: 1.46944\n",
            "== [TRAIN] Epoch: 25, Accuracy: 0.475 ==>\n",
            "[VAL] Epoch: 25, Iter: 0, Loss: 1.42729\n",
            "=== [VAL] Epoch: 25, Iter: 39, Accuracy: 0.493 ===>\n",
            "====== Epoch 26 ======>\n",
            "[TRAIN] Epoch: 26, Iter: 0, Loss: 1.42164\n",
            "[TRAIN] Epoch: 26, Iter: 80, Loss: 1.51593\n",
            "[TRAIN] Epoch: 26, Iter: 160, Loss: 1.41041\n",
            "[TRAIN] Epoch: 26, Iter: 240, Loss: 1.56037\n",
            "[TRAIN] Epoch: 26, Iter: 320, Loss: 1.28853\n",
            "== [TRAIN] Epoch: 26, Accuracy: 0.478 ==>\n",
            "[VAL] Epoch: 26, Iter: 0, Loss: 1.47170\n",
            "=== [VAL] Epoch: 26, Iter: 39, Accuracy: 0.480 ===>\n",
            "====== Epoch 27 ======>\n",
            "[TRAIN] Epoch: 27, Iter: 0, Loss: 1.38200\n",
            "[TRAIN] Epoch: 27, Iter: 80, Loss: 1.38391\n",
            "[TRAIN] Epoch: 27, Iter: 160, Loss: 1.44471\n",
            "[TRAIN] Epoch: 27, Iter: 240, Loss: 1.44816\n",
            "[TRAIN] Epoch: 27, Iter: 320, Loss: 1.66593\n",
            "== [TRAIN] Epoch: 27, Accuracy: 0.480 ==>\n",
            "[VAL] Epoch: 27, Iter: 0, Loss: 1.54015\n",
            "=== [VAL] Epoch: 27, Iter: 39, Accuracy: 0.488 ===>\n",
            "====== Epoch 28 ======>\n",
            "[TRAIN] Epoch: 28, Iter: 0, Loss: 1.41706\n",
            "[TRAIN] Epoch: 28, Iter: 80, Loss: 1.43614\n",
            "[TRAIN] Epoch: 28, Iter: 160, Loss: 1.66574\n",
            "[TRAIN] Epoch: 28, Iter: 240, Loss: 1.49169\n",
            "[TRAIN] Epoch: 28, Iter: 320, Loss: 1.60472\n",
            "== [TRAIN] Epoch: 28, Accuracy: 0.482 ==>\n",
            "[VAL] Epoch: 28, Iter: 0, Loss: 1.47389\n",
            "=== [VAL] Epoch: 28, Iter: 39, Accuracy: 0.489 ===>\n",
            "====== Epoch 29 ======>\n",
            "[TRAIN] Epoch: 29, Iter: 0, Loss: 1.37443\n",
            "[TRAIN] Epoch: 29, Iter: 80, Loss: 1.52219\n",
            "[TRAIN] Epoch: 29, Iter: 160, Loss: 1.50615\n",
            "[TRAIN] Epoch: 29, Iter: 240, Loss: 1.69530\n",
            "[TRAIN] Epoch: 29, Iter: 320, Loss: 1.40429\n",
            "== [TRAIN] Epoch: 29, Accuracy: 0.480 ==>\n",
            "[VAL] Epoch: 29, Iter: 0, Loss: 1.42255\n",
            "=== [VAL] Epoch: 29, Iter: 39, Accuracy: 0.497 ===>\n",
            "[TEST] Epoch: 29, Iter: 0, Loss: 1.40367\n",
            "=== [TEST] Epoch: 29, Iter: 78, Accuracy: 0.464 ===>\n",
            "===== Best validation Accuracy: 0.501 =====>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Train Losses  Valid Losses  Train accs  Valid accs  Epoch  \\\n",
              "0       1.876780      1.809609    0.341168    0.377539      1   \n",
              "1       1.759014      1.711079    0.384882    0.404102      2   \n",
              "2       1.714775      1.688537    0.399884    0.418555      3   \n",
              "3       1.681303      1.650801    0.414953    0.429883      4   \n",
              "4       1.646929      1.611948    0.426416    0.451562      5   \n",
              "5       1.632255      1.597633    0.425681    0.445117      6   \n",
              "6       1.609509      1.589829    0.435274    0.450000      7   \n",
              "7       1.600469      1.579528    0.435430    0.458789      8   \n",
              "8       1.586251      1.561523    0.441262    0.459570      9   \n",
              "9       1.577234      1.537864    0.444867    0.456836     10   \n",
              "10      1.565930      1.556164    0.448340    0.447852     11   \n",
              "11      1.554686      1.583141    0.453058    0.445898     12   \n",
              "12      1.548303      1.508175    0.454216    0.476953     13   \n",
              "13      1.539030      1.520092    0.458022    0.459766     14   \n",
              "14      1.532655      1.515030    0.458200    0.470313     15   \n",
              "15      1.527008      1.503747    0.461717    0.477734     16   \n",
              "16      1.522385      1.483038    0.463030    0.494922     17   \n",
              "17      1.508073      1.491117    0.468616    0.470117     18   \n",
              "18      1.508093      1.473685    0.468105    0.485742     19   \n",
              "19      1.502093      1.470278    0.468928    0.487695     20   \n",
              "20      1.504595      1.480172    0.469774    0.468945     21   \n",
              "21      1.499327      1.444624    0.469151    0.483008     22   \n",
              "22      1.489463      1.439754    0.471510    0.492578     23   \n",
              "23      1.483464      1.449387    0.473402    0.481445     24   \n",
              "24      1.480341      1.433990    0.475962    0.500977     25   \n",
              "25      1.481281      1.442207    0.475093    0.492969     26   \n",
              "26      1.474561      1.452414    0.477787    0.479687     27   \n",
              "27      1.470400      1.446057    0.479723    0.487891     28   \n",
              "28      1.463271      1.446365    0.481927    0.488672     29   \n",
              "29      1.465692      1.434260    0.479990    0.496680     30   \n",
              "\n",
              "   Activation Function  \n",
              "0                 Tanh  \n",
              "1                 Tanh  \n",
              "2                 Tanh  \n",
              "3                 Tanh  \n",
              "4                 Tanh  \n",
              "5                 Tanh  \n",
              "6                 Tanh  \n",
              "7                 Tanh  \n",
              "8                 Tanh  \n",
              "9                 Tanh  \n",
              "10                Tanh  \n",
              "11                Tanh  \n",
              "12                Tanh  \n",
              "13                Tanh  \n",
              "14                Tanh  \n",
              "15                Tanh  \n",
              "16                Tanh  \n",
              "17                Tanh  \n",
              "18                Tanh  \n",
              "19                Tanh  \n",
              "20                Tanh  \n",
              "21                Tanh  \n",
              "22                Tanh  \n",
              "23                Tanh  \n",
              "24                Tanh  \n",
              "25                Tanh  \n",
              "26                Tanh  \n",
              "27                Tanh  \n",
              "28                Tanh  \n",
              "29                Tanh  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd8e78db-cae6-4988-bce0-eab92c0af0ac\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train Losses</th>\n",
              "      <th>Valid Losses</th>\n",
              "      <th>Train accs</th>\n",
              "      <th>Valid accs</th>\n",
              "      <th>Epoch</th>\n",
              "      <th>Activation Function</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.876780</td>\n",
              "      <td>1.809609</td>\n",
              "      <td>0.341168</td>\n",
              "      <td>0.377539</td>\n",
              "      <td>1</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.759014</td>\n",
              "      <td>1.711079</td>\n",
              "      <td>0.384882</td>\n",
              "      <td>0.404102</td>\n",
              "      <td>2</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.714775</td>\n",
              "      <td>1.688537</td>\n",
              "      <td>0.399884</td>\n",
              "      <td>0.418555</td>\n",
              "      <td>3</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.681303</td>\n",
              "      <td>1.650801</td>\n",
              "      <td>0.414953</td>\n",
              "      <td>0.429883</td>\n",
              "      <td>4</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.646929</td>\n",
              "      <td>1.611948</td>\n",
              "      <td>0.426416</td>\n",
              "      <td>0.451562</td>\n",
              "      <td>5</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.632255</td>\n",
              "      <td>1.597633</td>\n",
              "      <td>0.425681</td>\n",
              "      <td>0.445117</td>\n",
              "      <td>6</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.609509</td>\n",
              "      <td>1.589829</td>\n",
              "      <td>0.435274</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>7</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.600469</td>\n",
              "      <td>1.579528</td>\n",
              "      <td>0.435430</td>\n",
              "      <td>0.458789</td>\n",
              "      <td>8</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.586251</td>\n",
              "      <td>1.561523</td>\n",
              "      <td>0.441262</td>\n",
              "      <td>0.459570</td>\n",
              "      <td>9</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.577234</td>\n",
              "      <td>1.537864</td>\n",
              "      <td>0.444867</td>\n",
              "      <td>0.456836</td>\n",
              "      <td>10</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1.565930</td>\n",
              "      <td>1.556164</td>\n",
              "      <td>0.448340</td>\n",
              "      <td>0.447852</td>\n",
              "      <td>11</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.554686</td>\n",
              "      <td>1.583141</td>\n",
              "      <td>0.453058</td>\n",
              "      <td>0.445898</td>\n",
              "      <td>12</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1.548303</td>\n",
              "      <td>1.508175</td>\n",
              "      <td>0.454216</td>\n",
              "      <td>0.476953</td>\n",
              "      <td>13</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1.539030</td>\n",
              "      <td>1.520092</td>\n",
              "      <td>0.458022</td>\n",
              "      <td>0.459766</td>\n",
              "      <td>14</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1.532655</td>\n",
              "      <td>1.515030</td>\n",
              "      <td>0.458200</td>\n",
              "      <td>0.470313</td>\n",
              "      <td>15</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1.527008</td>\n",
              "      <td>1.503747</td>\n",
              "      <td>0.461717</td>\n",
              "      <td>0.477734</td>\n",
              "      <td>16</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1.522385</td>\n",
              "      <td>1.483038</td>\n",
              "      <td>0.463030</td>\n",
              "      <td>0.494922</td>\n",
              "      <td>17</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.508073</td>\n",
              "      <td>1.491117</td>\n",
              "      <td>0.468616</td>\n",
              "      <td>0.470117</td>\n",
              "      <td>18</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1.508093</td>\n",
              "      <td>1.473685</td>\n",
              "      <td>0.468105</td>\n",
              "      <td>0.485742</td>\n",
              "      <td>19</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1.502093</td>\n",
              "      <td>1.470278</td>\n",
              "      <td>0.468928</td>\n",
              "      <td>0.487695</td>\n",
              "      <td>20</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1.504595</td>\n",
              "      <td>1.480172</td>\n",
              "      <td>0.469774</td>\n",
              "      <td>0.468945</td>\n",
              "      <td>21</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1.499327</td>\n",
              "      <td>1.444624</td>\n",
              "      <td>0.469151</td>\n",
              "      <td>0.483008</td>\n",
              "      <td>22</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1.489463</td>\n",
              "      <td>1.439754</td>\n",
              "      <td>0.471510</td>\n",
              "      <td>0.492578</td>\n",
              "      <td>23</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1.483464</td>\n",
              "      <td>1.449387</td>\n",
              "      <td>0.473402</td>\n",
              "      <td>0.481445</td>\n",
              "      <td>24</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1.480341</td>\n",
              "      <td>1.433990</td>\n",
              "      <td>0.475962</td>\n",
              "      <td>0.500977</td>\n",
              "      <td>25</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1.481281</td>\n",
              "      <td>1.442207</td>\n",
              "      <td>0.475093</td>\n",
              "      <td>0.492969</td>\n",
              "      <td>26</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1.474561</td>\n",
              "      <td>1.452414</td>\n",
              "      <td>0.477787</td>\n",
              "      <td>0.479687</td>\n",
              "      <td>27</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1.470400</td>\n",
              "      <td>1.446057</td>\n",
              "      <td>0.479723</td>\n",
              "      <td>0.487891</td>\n",
              "      <td>28</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1.463271</td>\n",
              "      <td>1.446365</td>\n",
              "      <td>0.481927</td>\n",
              "      <td>0.488672</td>\n",
              "      <td>29</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1.465692</td>\n",
              "      <td>1.434260</td>\n",
              "      <td>0.479990</td>\n",
              "      <td>0.496680</td>\n",
              "      <td>30</td>\n",
              "      <td>Tanh</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd8e78db-cae6-4988-bce0-eab92c0af0ac')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dd8e78db-cae6-4988-bce0-eab92c0af0ac button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dd8e78db-cae6-4988-bce0-eab92c0af0ac');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ecba0a72-cd68-46b6-89ff-b572a9ef79d0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ecba0a72-cd68-46b6-89ff-b572a9ef79d0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ecba0a72-cd68-46b6-89ff-b572a9ef79d0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_31df1915-41a9-4a62-8433-9f579c8eb286\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_31df1915-41a9-4a62-8433-9f579c8eb286 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": \"Train Losses\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09699228401882116,\n        \"min\": 1.4632712565256316,\n        \"max\": 1.8767799465065316,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          1.470399632413163,\n          1.527008389475679,\n          1.4834635960750098\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Valid Losses\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09378804249907353,\n        \"min\": 1.4339902788400647,\n        \"max\": 1.8096094012260437,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          1.446056509017944,\n          1.5037469148635865,\n          1.4493869483470918\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train accs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03197513746235616,\n        \"min\": 0.341168091168091,\n        \"max\": 0.481926638176638,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          0.47972311253561295,\n          0.4617165242165242,\n          0.4734018874643872\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Valid accs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02895851664515493,\n        \"min\": 0.37753906249999997,\n        \"max\": 0.5009765625000001,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          0.487890625,\n          0.47773437500000004,\n          0.4814453125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 1,\n        \"max\": 30,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          28,\n          16,\n          24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Activation Function\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Tanh\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Example to run MLP with 15 epochs\n",
        "config = Arguments(model='mlp',\n",
        "                   model_config='/content/IFT6135-2025-First-Assignment/HW1_2025/assignment1_release/model_configs/mlp_tanh.json',\n",
        "                   epochs= 30, logdir=\"exps/mlp_tanh_default\")\n",
        "train_losses, valid_losses, train_accs, valid_accs = main_entry(config)\n",
        "\n",
        "df = pd.DataFrame({'Train Losses': train_losses, 'Valid Losses': valid_losses, 'Train accs': train_accs, 'Valid accs': valid_accs}).assign(Epoch=range(1, len(train_losses) + 1))\n",
        "df['Activation Function'] = 'Tanh'\n",
        "df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_all = pd.concat([df_sigmoid, df_relu, df])\n",
        "df_all.to_csv('df_mlp_with_diff_activation.csv')"
      ],
      "metadata": {
        "id": "dbFhS3yNvShd"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "1e-3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "547JIgY1m4v9",
        "outputId": "a41bf8e0-2714-4a33-e458-e37071e1da23"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.001"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example to run MLP with 15 epochs\n",
        "import pandas as pd\n",
        "df_all_resnet = []\n",
        "for lr in [1e-1 , 1e-2 , 1e-3, 1e-4, 1e-5]:\n",
        "  config = Arguments(model='resnet18',\n",
        "                    model_config='/content/IFT6135-2025-First-Assignment/HW1_2025/assignment1_release/model_configs/resnet18.json',\n",
        "                    epochs= 40, logdir=\"exps/resnet18\" , lr = lr )\n",
        "  train_losses, valid_losses, train_accs, valid_accs = main_entry(config)\n",
        "\n",
        "  df = pd.DataFrame({'Train Losses': train_losses, 'Valid Losses': valid_losses, 'Train accs': train_accs, 'Valid accs': valid_accs}).assign(Epoch=range(1, len(train_losses) + 1))\n",
        "  df['Learning Rate'] = lr\n",
        "  df_all_resnet.append(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7N_mG0UUDcr",
        "outputId": "0e217ee6-7565-41ee-9bc3-e32d2d52a895"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Build model RESNET18...\n",
            "Loading model config from /content/IFT6135-2025-First-Assignment/HW1_2025/assignment1_release/model_configs/resnet18.json\n",
            "########## RESNET18 CONFIG ################\n",
            "num_classes:\t10\n",
            "############################################\n",
            "Initialized RESNET18 model with 11173962 total parameters, of which 11173962 are learnable.\n",
            "====== Epoch 0 ======>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN] Epoch: 0, Iter: 0, Loss: 2.35414\n",
            "[TRAIN] Epoch: 0, Iter: 80, Loss: 2.13083\n",
            "[TRAIN] Epoch: 0, Iter: 160, Loss: 2.04942\n",
            "[TRAIN] Epoch: 0, Iter: 240, Loss: 1.88022\n",
            "[TRAIN] Epoch: 0, Iter: 320, Loss: 1.81179\n",
            "== [TRAIN] Epoch: 0, Accuracy: 0.225 ==>\n",
            "[VAL] Epoch: 0, Iter: 0, Loss: 1.81541\n",
            "=== [VAL] Epoch: 0, Iter: 39, Accuracy: 0.337 ===>\n",
            "====== Epoch 1 ======>\n",
            "[TRAIN] Epoch: 1, Iter: 0, Loss: 1.85740\n",
            "[TRAIN] Epoch: 1, Iter: 80, Loss: 1.56908\n",
            "[TRAIN] Epoch: 1, Iter: 160, Loss: 1.65282\n",
            "[TRAIN] Epoch: 1, Iter: 240, Loss: 1.58355\n",
            "[TRAIN] Epoch: 1, Iter: 320, Loss: 1.45478\n",
            "== [TRAIN] Epoch: 1, Accuracy: 0.379 ==>\n",
            "[VAL] Epoch: 1, Iter: 0, Loss: 1.69174\n",
            "=== [VAL] Epoch: 1, Iter: 39, Accuracy: 0.390 ===>\n",
            "====== Epoch 2 ======>\n",
            "[TRAIN] Epoch: 2, Iter: 0, Loss: 1.79429\n",
            "[TRAIN] Epoch: 2, Iter: 80, Loss: 1.60298\n",
            "[TRAIN] Epoch: 2, Iter: 160, Loss: 1.68818\n",
            "[TRAIN] Epoch: 2, Iter: 240, Loss: 1.56135\n",
            "[TRAIN] Epoch: 2, Iter: 320, Loss: 1.39268\n",
            "== [TRAIN] Epoch: 2, Accuracy: 0.448 ==>\n",
            "[VAL] Epoch: 2, Iter: 0, Loss: 1.45086\n",
            "=== [VAL] Epoch: 2, Iter: 39, Accuracy: 0.476 ===>\n",
            "====== Epoch 3 ======>\n",
            "[TRAIN] Epoch: 3, Iter: 0, Loss: 1.57150\n",
            "[TRAIN] Epoch: 3, Iter: 80, Loss: 1.29727\n",
            "[TRAIN] Epoch: 3, Iter: 160, Loss: 1.44429\n",
            "[TRAIN] Epoch: 3, Iter: 240, Loss: 1.21613\n",
            "[TRAIN] Epoch: 3, Iter: 320, Loss: 1.43776\n",
            "== [TRAIN] Epoch: 3, Accuracy: 0.509 ==>\n",
            "[VAL] Epoch: 3, Iter: 0, Loss: 1.17858\n",
            "=== [VAL] Epoch: 3, Iter: 39, Accuracy: 0.558 ===>\n",
            "====== Epoch 4 ======>\n",
            "[TRAIN] Epoch: 4, Iter: 0, Loss: 1.32948\n",
            "[TRAIN] Epoch: 4, Iter: 80, Loss: 1.31291\n",
            "[TRAIN] Epoch: 4, Iter: 160, Loss: 1.43452\n",
            "[TRAIN] Epoch: 4, Iter: 240, Loss: 1.19737\n",
            "[TRAIN] Epoch: 4, Iter: 320, Loss: 1.32256\n",
            "== [TRAIN] Epoch: 4, Accuracy: 0.557 ==>\n",
            "[VAL] Epoch: 4, Iter: 0, Loss: 1.12568\n",
            "=== [VAL] Epoch: 4, Iter: 39, Accuracy: 0.581 ===>\n",
            "====== Epoch 5 ======>\n",
            "[TRAIN] Epoch: 5, Iter: 0, Loss: 1.17117\n",
            "[TRAIN] Epoch: 5, Iter: 80, Loss: 0.99363\n",
            "[TRAIN] Epoch: 5, Iter: 160, Loss: 1.04875\n",
            "[TRAIN] Epoch: 5, Iter: 240, Loss: 1.25193\n",
            "[TRAIN] Epoch: 5, Iter: 320, Loss: 0.86425\n",
            "== [TRAIN] Epoch: 5, Accuracy: 0.599 ==>\n",
            "[VAL] Epoch: 5, Iter: 0, Loss: 1.21777\n",
            "=== [VAL] Epoch: 5, Iter: 39, Accuracy: 0.571 ===>\n",
            "====== Epoch 6 ======>\n",
            "[TRAIN] Epoch: 6, Iter: 0, Loss: 1.13811\n",
            "[TRAIN] Epoch: 6, Iter: 80, Loss: 1.05405\n",
            "[TRAIN] Epoch: 6, Iter: 160, Loss: 1.09570\n",
            "[TRAIN] Epoch: 6, Iter: 240, Loss: 1.04202\n",
            "[TRAIN] Epoch: 6, Iter: 320, Loss: 0.83979\n",
            "== [TRAIN] Epoch: 6, Accuracy: 0.627 ==>\n",
            "[VAL] Epoch: 6, Iter: 0, Loss: 0.99162\n",
            "=== [VAL] Epoch: 6, Iter: 39, Accuracy: 0.661 ===>\n",
            "====== Epoch 7 ======>\n",
            "[TRAIN] Epoch: 7, Iter: 0, Loss: 0.85051\n",
            "[TRAIN] Epoch: 7, Iter: 80, Loss: 1.10523\n",
            "[TRAIN] Epoch: 7, Iter: 160, Loss: 0.91492\n",
            "[TRAIN] Epoch: 7, Iter: 240, Loss: 0.83654\n",
            "[TRAIN] Epoch: 7, Iter: 320, Loss: 0.97367\n",
            "== [TRAIN] Epoch: 7, Accuracy: 0.659 ==>\n",
            "[VAL] Epoch: 7, Iter: 0, Loss: 1.07112\n",
            "=== [VAL] Epoch: 7, Iter: 39, Accuracy: 0.667 ===>\n",
            "====== Epoch 8 ======>\n",
            "[TRAIN] Epoch: 8, Iter: 0, Loss: 1.01146\n",
            "[TRAIN] Epoch: 8, Iter: 80, Loss: 0.88613\n",
            "[TRAIN] Epoch: 8, Iter: 160, Loss: 0.80994\n",
            "[TRAIN] Epoch: 8, Iter: 240, Loss: 0.79414\n",
            "[TRAIN] Epoch: 8, Iter: 320, Loss: 0.98960\n",
            "== [TRAIN] Epoch: 8, Accuracy: 0.694 ==>\n",
            "[VAL] Epoch: 8, Iter: 0, Loss: 1.07184\n",
            "=== [VAL] Epoch: 8, Iter: 39, Accuracy: 0.652 ===>\n",
            "====== Epoch 9 ======>\n",
            "[TRAIN] Epoch: 9, Iter: 0, Loss: 0.69571\n",
            "[TRAIN] Epoch: 9, Iter: 80, Loss: 1.06786\n",
            "[TRAIN] Epoch: 9, Iter: 160, Loss: 1.02447\n",
            "[TRAIN] Epoch: 9, Iter: 240, Loss: 0.84207\n",
            "[TRAIN] Epoch: 9, Iter: 320, Loss: 0.84610\n",
            "== [TRAIN] Epoch: 9, Accuracy: 0.715 ==>\n",
            "[VAL] Epoch: 9, Iter: 0, Loss: 0.72157\n",
            "=== [VAL] Epoch: 9, Iter: 39, Accuracy: 0.751 ===>\n",
            "====== Epoch 10 ======>\n",
            "[TRAIN] Epoch: 10, Iter: 0, Loss: 0.70995\n",
            "[TRAIN] Epoch: 10, Iter: 80, Loss: 0.74442\n",
            "[TRAIN] Epoch: 10, Iter: 160, Loss: 0.83853\n",
            "[TRAIN] Epoch: 10, Iter: 240, Loss: 0.89925\n",
            "[TRAIN] Epoch: 10, Iter: 320, Loss: 0.70803\n",
            "== [TRAIN] Epoch: 10, Accuracy: 0.737 ==>\n",
            "[VAL] Epoch: 10, Iter: 0, Loss: 0.66705\n",
            "=== [VAL] Epoch: 10, Iter: 39, Accuracy: 0.738 ===>\n",
            "====== Epoch 11 ======>\n",
            "[TRAIN] Epoch: 11, Iter: 0, Loss: 0.72779\n",
            "[TRAIN] Epoch: 11, Iter: 80, Loss: 0.72540\n",
            "[TRAIN] Epoch: 11, Iter: 160, Loss: 0.64725\n",
            "[TRAIN] Epoch: 11, Iter: 240, Loss: 0.48521\n",
            "[TRAIN] Epoch: 11, Iter: 320, Loss: 0.68718\n",
            "== [TRAIN] Epoch: 11, Accuracy: 0.763 ==>\n",
            "[VAL] Epoch: 11, Iter: 0, Loss: 0.79070\n",
            "=== [VAL] Epoch: 11, Iter: 39, Accuracy: 0.733 ===>\n",
            "====== Epoch 12 ======>\n",
            "[TRAIN] Epoch: 12, Iter: 0, Loss: 0.62029\n",
            "[TRAIN] Epoch: 12, Iter: 80, Loss: 0.60184\n",
            "[TRAIN] Epoch: 12, Iter: 160, Loss: 0.75897\n",
            "[TRAIN] Epoch: 12, Iter: 240, Loss: 0.61172\n",
            "[TRAIN] Epoch: 12, Iter: 320, Loss: 0.78422\n",
            "== [TRAIN] Epoch: 12, Accuracy: 0.774 ==>\n",
            "[VAL] Epoch: 12, Iter: 0, Loss: 0.76207\n",
            "=== [VAL] Epoch: 12, Iter: 39, Accuracy: 0.759 ===>\n",
            "====== Epoch 13 ======>\n",
            "[TRAIN] Epoch: 13, Iter: 0, Loss: 0.62372\n",
            "[TRAIN] Epoch: 13, Iter: 80, Loss: 0.65700\n",
            "[TRAIN] Epoch: 13, Iter: 160, Loss: 0.56417\n",
            "[TRAIN] Epoch: 13, Iter: 240, Loss: 0.60440\n",
            "[TRAIN] Epoch: 13, Iter: 320, Loss: 0.66322\n",
            "== [TRAIN] Epoch: 13, Accuracy: 0.790 ==>\n",
            "[VAL] Epoch: 13, Iter: 0, Loss: 0.55456\n",
            "=== [VAL] Epoch: 13, Iter: 39, Accuracy: 0.802 ===>\n",
            "====== Epoch 14 ======>\n",
            "[TRAIN] Epoch: 14, Iter: 0, Loss: 0.65390\n",
            "[TRAIN] Epoch: 14, Iter: 80, Loss: 0.90209\n",
            "[TRAIN] Epoch: 14, Iter: 160, Loss: 0.72157\n",
            "[TRAIN] Epoch: 14, Iter: 240, Loss: 0.52618\n",
            "[TRAIN] Epoch: 14, Iter: 320, Loss: 0.66956\n",
            "== [TRAIN] Epoch: 14, Accuracy: 0.798 ==>\n",
            "[VAL] Epoch: 14, Iter: 0, Loss: 0.57812\n",
            "=== [VAL] Epoch: 14, Iter: 39, Accuracy: 0.806 ===>\n",
            "====== Epoch 15 ======>\n",
            "[TRAIN] Epoch: 15, Iter: 0, Loss: 0.43893\n",
            "[TRAIN] Epoch: 15, Iter: 80, Loss: 0.48910\n",
            "[TRAIN] Epoch: 15, Iter: 160, Loss: 0.46729\n",
            "[TRAIN] Epoch: 15, Iter: 240, Loss: 0.60033\n",
            "[TRAIN] Epoch: 15, Iter: 320, Loss: 0.37025\n",
            "== [TRAIN] Epoch: 15, Accuracy: 0.810 ==>\n",
            "[VAL] Epoch: 15, Iter: 0, Loss: 0.69950\n",
            "=== [VAL] Epoch: 15, Iter: 39, Accuracy: 0.767 ===>\n",
            "====== Epoch 16 ======>\n",
            "[TRAIN] Epoch: 16, Iter: 0, Loss: 0.42277\n",
            "[TRAIN] Epoch: 16, Iter: 80, Loss: 0.49561\n",
            "[TRAIN] Epoch: 16, Iter: 160, Loss: 0.42235\n",
            "[TRAIN] Epoch: 16, Iter: 240, Loss: 0.55213\n",
            "[TRAIN] Epoch: 16, Iter: 320, Loss: 0.56624\n",
            "== [TRAIN] Epoch: 16, Accuracy: 0.818 ==>\n",
            "[VAL] Epoch: 16, Iter: 0, Loss: 0.63762\n",
            "=== [VAL] Epoch: 16, Iter: 39, Accuracy: 0.818 ===>\n",
            "====== Epoch 17 ======>\n",
            "[TRAIN] Epoch: 17, Iter: 0, Loss: 0.48733\n",
            "[TRAIN] Epoch: 17, Iter: 80, Loss: 0.46753\n",
            "[TRAIN] Epoch: 17, Iter: 160, Loss: 0.41040\n",
            "[TRAIN] Epoch: 17, Iter: 240, Loss: 0.50162\n",
            "[TRAIN] Epoch: 17, Iter: 320, Loss: 0.68136\n",
            "== [TRAIN] Epoch: 17, Accuracy: 0.825 ==>\n",
            "[VAL] Epoch: 17, Iter: 0, Loss: 0.52022\n",
            "=== [VAL] Epoch: 17, Iter: 39, Accuracy: 0.850 ===>\n",
            "====== Epoch 18 ======>\n",
            "[TRAIN] Epoch: 18, Iter: 0, Loss: 0.45810\n",
            "[TRAIN] Epoch: 18, Iter: 80, Loss: 0.57973\n",
            "[TRAIN] Epoch: 18, Iter: 160, Loss: 0.55514\n",
            "[TRAIN] Epoch: 18, Iter: 240, Loss: 0.41626\n",
            "[TRAIN] Epoch: 18, Iter: 320, Loss: 0.52872\n",
            "== [TRAIN] Epoch: 18, Accuracy: 0.833 ==>\n",
            "[VAL] Epoch: 18, Iter: 0, Loss: 0.55081\n",
            "=== [VAL] Epoch: 18, Iter: 39, Accuracy: 0.843 ===>\n",
            "====== Epoch 19 ======>\n",
            "[TRAIN] Epoch: 19, Iter: 0, Loss: 0.41043\n",
            "[TRAIN] Epoch: 19, Iter: 80, Loss: 0.43569\n",
            "[TRAIN] Epoch: 19, Iter: 160, Loss: 0.34664\n",
            "[TRAIN] Epoch: 19, Iter: 240, Loss: 0.36552\n",
            "[TRAIN] Epoch: 19, Iter: 320, Loss: 0.35027\n",
            "== [TRAIN] Epoch: 19, Accuracy: 0.839 ==>\n",
            "[VAL] Epoch: 19, Iter: 0, Loss: 0.44033\n",
            "=== [VAL] Epoch: 19, Iter: 39, Accuracy: 0.849 ===>\n",
            "====== Epoch 20 ======>\n",
            "[TRAIN] Epoch: 20, Iter: 0, Loss: 0.36904\n",
            "[TRAIN] Epoch: 20, Iter: 80, Loss: 0.35850\n",
            "[TRAIN] Epoch: 20, Iter: 160, Loss: 0.56099\n",
            "[TRAIN] Epoch: 20, Iter: 240, Loss: 0.32260\n",
            "[TRAIN] Epoch: 20, Iter: 320, Loss: 0.25405\n",
            "== [TRAIN] Epoch: 20, Accuracy: 0.848 ==>\n",
            "[VAL] Epoch: 20, Iter: 0, Loss: 0.45756\n",
            "=== [VAL] Epoch: 20, Iter: 39, Accuracy: 0.809 ===>\n",
            "====== Epoch 21 ======>\n",
            "[TRAIN] Epoch: 21, Iter: 0, Loss: 0.48685\n",
            "[TRAIN] Epoch: 21, Iter: 80, Loss: 0.43060\n",
            "[TRAIN] Epoch: 21, Iter: 160, Loss: 0.37612\n",
            "[TRAIN] Epoch: 21, Iter: 240, Loss: 0.48893\n",
            "[TRAIN] Epoch: 21, Iter: 320, Loss: 0.34998\n",
            "== [TRAIN] Epoch: 21, Accuracy: 0.855 ==>\n",
            "[VAL] Epoch: 21, Iter: 0, Loss: 0.46893\n",
            "=== [VAL] Epoch: 21, Iter: 39, Accuracy: 0.866 ===>\n",
            "====== Epoch 22 ======>\n",
            "[TRAIN] Epoch: 22, Iter: 0, Loss: 0.44992\n",
            "[TRAIN] Epoch: 22, Iter: 80, Loss: 0.33634\n",
            "[TRAIN] Epoch: 22, Iter: 160, Loss: 0.50259\n",
            "[TRAIN] Epoch: 22, Iter: 240, Loss: 0.41657\n",
            "[TRAIN] Epoch: 22, Iter: 320, Loss: 0.51205\n",
            "== [TRAIN] Epoch: 22, Accuracy: 0.858 ==>\n",
            "[VAL] Epoch: 22, Iter: 0, Loss: 0.45706\n",
            "=== [VAL] Epoch: 22, Iter: 39, Accuracy: 0.861 ===>\n",
            "====== Epoch 23 ======>\n",
            "[TRAIN] Epoch: 23, Iter: 0, Loss: 0.42110\n",
            "[TRAIN] Epoch: 23, Iter: 80, Loss: 0.42198\n",
            "[TRAIN] Epoch: 23, Iter: 160, Loss: 0.37228\n",
            "[TRAIN] Epoch: 23, Iter: 240, Loss: 0.32582\n",
            "[TRAIN] Epoch: 23, Iter: 320, Loss: 0.46439\n",
            "== [TRAIN] Epoch: 23, Accuracy: 0.862 ==>\n",
            "[VAL] Epoch: 23, Iter: 0, Loss: 0.37875\n",
            "=== [VAL] Epoch: 23, Iter: 39, Accuracy: 0.862 ===>\n",
            "====== Epoch 24 ======>\n",
            "[TRAIN] Epoch: 24, Iter: 0, Loss: 0.40477\n",
            "[TRAIN] Epoch: 24, Iter: 80, Loss: 0.36698\n",
            "[TRAIN] Epoch: 24, Iter: 160, Loss: 0.51853\n",
            "[TRAIN] Epoch: 24, Iter: 240, Loss: 0.34217\n",
            "[TRAIN] Epoch: 24, Iter: 320, Loss: 0.46514\n",
            "== [TRAIN] Epoch: 24, Accuracy: 0.868 ==>\n",
            "[VAL] Epoch: 24, Iter: 0, Loss: 0.45876\n",
            "=== [VAL] Epoch: 24, Iter: 39, Accuracy: 0.882 ===>\n",
            "====== Epoch 25 ======>\n",
            "[TRAIN] Epoch: 25, Iter: 0, Loss: 0.29742\n",
            "[TRAIN] Epoch: 25, Iter: 80, Loss: 0.24913\n",
            "[TRAIN] Epoch: 25, Iter: 160, Loss: 0.34389\n",
            "[TRAIN] Epoch: 25, Iter: 240, Loss: 0.25541\n",
            "[TRAIN] Epoch: 25, Iter: 320, Loss: 0.40987\n",
            "== [TRAIN] Epoch: 25, Accuracy: 0.874 ==>\n",
            "[VAL] Epoch: 25, Iter: 0, Loss: 0.38668\n",
            "=== [VAL] Epoch: 25, Iter: 39, Accuracy: 0.868 ===>\n",
            "====== Epoch 26 ======>\n",
            "[TRAIN] Epoch: 26, Iter: 0, Loss: 0.35707\n",
            "[TRAIN] Epoch: 26, Iter: 80, Loss: 0.34132\n",
            "[TRAIN] Epoch: 26, Iter: 160, Loss: 0.35811\n",
            "[TRAIN] Epoch: 26, Iter: 240, Loss: 0.33655\n",
            "[TRAIN] Epoch: 26, Iter: 320, Loss: 0.34124\n",
            "== [TRAIN] Epoch: 26, Accuracy: 0.877 ==>\n",
            "[VAL] Epoch: 26, Iter: 0, Loss: 0.45147\n",
            "=== [VAL] Epoch: 26, Iter: 39, Accuracy: 0.858 ===>\n",
            "====== Epoch 27 ======>\n",
            "[TRAIN] Epoch: 27, Iter: 0, Loss: 0.42877\n",
            "[TRAIN] Epoch: 27, Iter: 80, Loss: 0.28500\n",
            "[TRAIN] Epoch: 27, Iter: 160, Loss: 0.51183\n",
            "[TRAIN] Epoch: 27, Iter: 240, Loss: 0.52538\n",
            "[TRAIN] Epoch: 27, Iter: 320, Loss: 0.41843\n",
            "== [TRAIN] Epoch: 27, Accuracy: 0.882 ==>\n",
            "[VAL] Epoch: 27, Iter: 0, Loss: 0.40350\n",
            "=== [VAL] Epoch: 27, Iter: 39, Accuracy: 0.881 ===>\n",
            "====== Epoch 28 ======>\n",
            "[TRAIN] Epoch: 28, Iter: 0, Loss: 0.19207\n",
            "[TRAIN] Epoch: 28, Iter: 80, Loss: 0.30109\n",
            "[TRAIN] Epoch: 28, Iter: 160, Loss: 0.40506\n",
            "[TRAIN] Epoch: 28, Iter: 240, Loss: 0.38340\n",
            "[TRAIN] Epoch: 28, Iter: 320, Loss: 0.32750\n",
            "== [TRAIN] Epoch: 28, Accuracy: 0.886 ==>\n",
            "[VAL] Epoch: 28, Iter: 0, Loss: 0.28795\n",
            "=== [VAL] Epoch: 28, Iter: 39, Accuracy: 0.899 ===>\n",
            "====== Epoch 29 ======>\n",
            "[TRAIN] Epoch: 29, Iter: 0, Loss: 0.30604\n",
            "[TRAIN] Epoch: 29, Iter: 80, Loss: 0.33691\n",
            "[TRAIN] Epoch: 29, Iter: 160, Loss: 0.46935\n",
            "[TRAIN] Epoch: 29, Iter: 240, Loss: 0.43604\n",
            "[TRAIN] Epoch: 29, Iter: 320, Loss: 0.26722\n",
            "== [TRAIN] Epoch: 29, Accuracy: 0.888 ==>\n",
            "[VAL] Epoch: 29, Iter: 0, Loss: 0.27803\n",
            "=== [VAL] Epoch: 29, Iter: 39, Accuracy: 0.908 ===>\n",
            "====== Epoch 30 ======>\n",
            "[TRAIN] Epoch: 30, Iter: 0, Loss: 0.17769\n",
            "[TRAIN] Epoch: 30, Iter: 80, Loss: 0.28287\n",
            "[TRAIN] Epoch: 30, Iter: 160, Loss: 0.19184\n",
            "[TRAIN] Epoch: 30, Iter: 240, Loss: 0.34107\n",
            "[TRAIN] Epoch: 30, Iter: 320, Loss: 0.46311\n",
            "== [TRAIN] Epoch: 30, Accuracy: 0.893 ==>\n",
            "[VAL] Epoch: 30, Iter: 0, Loss: 0.50598\n",
            "=== [VAL] Epoch: 30, Iter: 39, Accuracy: 0.843 ===>\n",
            "====== Epoch 31 ======>\n",
            "[TRAIN] Epoch: 31, Iter: 0, Loss: 0.41545\n",
            "[TRAIN] Epoch: 31, Iter: 80, Loss: 0.24440\n",
            "[TRAIN] Epoch: 31, Iter: 160, Loss: 0.40770\n",
            "[TRAIN] Epoch: 31, Iter: 240, Loss: 0.19878\n",
            "[TRAIN] Epoch: 31, Iter: 320, Loss: 0.48579\n",
            "== [TRAIN] Epoch: 31, Accuracy: 0.896 ==>\n",
            "[VAL] Epoch: 31, Iter: 0, Loss: 0.27065\n",
            "=== [VAL] Epoch: 31, Iter: 39, Accuracy: 0.908 ===>\n",
            "====== Epoch 32 ======>\n",
            "[TRAIN] Epoch: 32, Iter: 0, Loss: 0.23904\n",
            "[TRAIN] Epoch: 32, Iter: 80, Loss: 0.20779\n",
            "[TRAIN] Epoch: 32, Iter: 160, Loss: 0.28496\n",
            "[TRAIN] Epoch: 32, Iter: 240, Loss: 0.31433\n",
            "[TRAIN] Epoch: 32, Iter: 320, Loss: 0.41828\n",
            "== [TRAIN] Epoch: 32, Accuracy: 0.899 ==>\n",
            "[VAL] Epoch: 32, Iter: 0, Loss: 0.21659\n",
            "=== [VAL] Epoch: 32, Iter: 39, Accuracy: 0.907 ===>\n",
            "====== Epoch 33 ======>\n",
            "[TRAIN] Epoch: 33, Iter: 0, Loss: 0.28552\n",
            "[TRAIN] Epoch: 33, Iter: 80, Loss: 0.25863\n",
            "[TRAIN] Epoch: 33, Iter: 160, Loss: 0.30938\n",
            "[TRAIN] Epoch: 33, Iter: 240, Loss: 0.29295\n",
            "[TRAIN] Epoch: 33, Iter: 320, Loss: 0.25903\n",
            "== [TRAIN] Epoch: 33, Accuracy: 0.901 ==>\n",
            "[VAL] Epoch: 33, Iter: 0, Loss: 0.35028\n",
            "=== [VAL] Epoch: 33, Iter: 39, Accuracy: 0.905 ===>\n",
            "====== Epoch 34 ======>\n",
            "[TRAIN] Epoch: 34, Iter: 0, Loss: 0.35490\n",
            "[TRAIN] Epoch: 34, Iter: 80, Loss: 0.29084\n",
            "[TRAIN] Epoch: 34, Iter: 160, Loss: 0.26360\n",
            "[TRAIN] Epoch: 34, Iter: 240, Loss: 0.20416\n",
            "[TRAIN] Epoch: 34, Iter: 320, Loss: 0.26189\n",
            "== [TRAIN] Epoch: 34, Accuracy: 0.905 ==>\n",
            "[VAL] Epoch: 34, Iter: 0, Loss: 0.28318\n",
            "=== [VAL] Epoch: 34, Iter: 39, Accuracy: 0.919 ===>\n",
            "====== Epoch 35 ======>\n",
            "[TRAIN] Epoch: 35, Iter: 0, Loss: 0.20609\n",
            "[TRAIN] Epoch: 35, Iter: 80, Loss: 0.14282\n",
            "[TRAIN] Epoch: 35, Iter: 160, Loss: 0.32958\n",
            "[TRAIN] Epoch: 35, Iter: 240, Loss: 0.27138\n",
            "[TRAIN] Epoch: 35, Iter: 320, Loss: 0.18108\n",
            "== [TRAIN] Epoch: 35, Accuracy: 0.905 ==>\n",
            "[VAL] Epoch: 35, Iter: 0, Loss: 0.32122\n",
            "=== [VAL] Epoch: 35, Iter: 39, Accuracy: 0.913 ===>\n",
            "====== Epoch 36 ======>\n",
            "[TRAIN] Epoch: 36, Iter: 0, Loss: 0.25110\n",
            "[TRAIN] Epoch: 36, Iter: 80, Loss: 0.29048\n",
            "[TRAIN] Epoch: 36, Iter: 160, Loss: 0.25016\n",
            "[TRAIN] Epoch: 36, Iter: 240, Loss: 0.16232\n",
            "[TRAIN] Epoch: 36, Iter: 320, Loss: 0.30617\n",
            "== [TRAIN] Epoch: 36, Accuracy: 0.911 ==>\n",
            "[VAL] Epoch: 36, Iter: 0, Loss: 0.27937\n",
            "=== [VAL] Epoch: 36, Iter: 39, Accuracy: 0.928 ===>\n",
            "====== Epoch 37 ======>\n",
            "[TRAIN] Epoch: 37, Iter: 0, Loss: 0.22013\n",
            "[TRAIN] Epoch: 37, Iter: 80, Loss: 0.26974\n",
            "[TRAIN] Epoch: 37, Iter: 160, Loss: 0.27334\n",
            "[TRAIN] Epoch: 37, Iter: 240, Loss: 0.25458\n",
            "[TRAIN] Epoch: 37, Iter: 320, Loss: 0.34052\n",
            "== [TRAIN] Epoch: 37, Accuracy: 0.911 ==>\n",
            "[VAL] Epoch: 37, Iter: 0, Loss: 0.25506\n",
            "=== [VAL] Epoch: 37, Iter: 39, Accuracy: 0.915 ===>\n",
            "====== Epoch 38 ======>\n",
            "[TRAIN] Epoch: 38, Iter: 0, Loss: 0.24849\n",
            "[TRAIN] Epoch: 38, Iter: 80, Loss: 0.19801\n",
            "[TRAIN] Epoch: 38, Iter: 160, Loss: 0.31782\n",
            "[TRAIN] Epoch: 38, Iter: 240, Loss: 0.36033\n",
            "[TRAIN] Epoch: 38, Iter: 320, Loss: 0.24546\n",
            "== [TRAIN] Epoch: 38, Accuracy: 0.915 ==>\n",
            "[VAL] Epoch: 38, Iter: 0, Loss: 0.24922\n",
            "=== [VAL] Epoch: 38, Iter: 39, Accuracy: 0.933 ===>\n",
            "====== Epoch 39 ======>\n",
            "[TRAIN] Epoch: 39, Iter: 0, Loss: 0.31012\n",
            "[TRAIN] Epoch: 39, Iter: 80, Loss: 0.20004\n",
            "[TRAIN] Epoch: 39, Iter: 160, Loss: 0.23270\n",
            "[TRAIN] Epoch: 39, Iter: 240, Loss: 0.22429\n",
            "[TRAIN] Epoch: 39, Iter: 320, Loss: 0.22588\n",
            "== [TRAIN] Epoch: 39, Accuracy: 0.915 ==>\n",
            "[VAL] Epoch: 39, Iter: 0, Loss: 0.27522\n",
            "=== [VAL] Epoch: 39, Iter: 39, Accuracy: 0.927 ===>\n",
            "[TEST] Epoch: 39, Iter: 0, Loss: 0.27699\n",
            "=== [TEST] Epoch: 39, Iter: 78, Accuracy: 0.860 ===>\n",
            "===== Best validation Accuracy: 0.933 =====>\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Build model RESNET18...\n",
            "Loading model config from /content/IFT6135-2025-First-Assignment/HW1_2025/assignment1_release/model_configs/resnet18.json\n",
            "########## RESNET18 CONFIG ################\n",
            "num_classes:\t10\n",
            "############################################\n",
            "Initialized RESNET18 model with 11173962 total parameters, of which 11173962 are learnable.\n",
            "====== Epoch 0 ======>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN] Epoch: 0, Iter: 0, Loss: 2.35414\n",
            "[TRAIN] Epoch: 0, Iter: 80, Loss: 1.80547\n",
            "[TRAIN] Epoch: 0, Iter: 160, Loss: 1.76577\n",
            "[TRAIN] Epoch: 0, Iter: 240, Loss: 1.61652\n",
            "[TRAIN] Epoch: 0, Iter: 320, Loss: 1.53608\n",
            "== [TRAIN] Epoch: 0, Accuracy: 0.351 ==>\n",
            "[VAL] Epoch: 0, Iter: 0, Loss: 1.45470\n",
            "=== [VAL] Epoch: 0, Iter: 39, Accuracy: 0.446 ===>\n",
            "====== Epoch 1 ======>\n",
            "[TRAIN] Epoch: 1, Iter: 0, Loss: 1.60079\n",
            "[TRAIN] Epoch: 1, Iter: 80, Loss: 1.33400\n",
            "[TRAIN] Epoch: 1, Iter: 160, Loss: 1.27345\n",
            "[TRAIN] Epoch: 1, Iter: 240, Loss: 1.30770\n",
            "[TRAIN] Epoch: 1, Iter: 320, Loss: 1.18779\n",
            "== [TRAIN] Epoch: 1, Accuracy: 0.509 ==>\n",
            "[VAL] Epoch: 1, Iter: 0, Loss: 1.34599\n",
            "=== [VAL] Epoch: 1, Iter: 39, Accuracy: 0.584 ===>\n",
            "====== Epoch 2 ======>\n",
            "[TRAIN] Epoch: 2, Iter: 0, Loss: 1.32911\n",
            "[TRAIN] Epoch: 2, Iter: 80, Loss: 1.21138\n",
            "[TRAIN] Epoch: 2, Iter: 160, Loss: 1.26636\n",
            "[TRAIN] Epoch: 2, Iter: 240, Loss: 1.05696\n",
            "[TRAIN] Epoch: 2, Iter: 320, Loss: 1.00084\n",
            "== [TRAIN] Epoch: 2, Accuracy: 0.607 ==>\n",
            "[VAL] Epoch: 2, Iter: 0, Loss: 1.19231\n",
            "=== [VAL] Epoch: 2, Iter: 39, Accuracy: 0.613 ===>\n",
            "====== Epoch 3 ======>\n",
            "[TRAIN] Epoch: 3, Iter: 0, Loss: 1.02784\n",
            "[TRAIN] Epoch: 3, Iter: 80, Loss: 0.92175\n",
            "[TRAIN] Epoch: 3, Iter: 160, Loss: 0.97940\n",
            "[TRAIN] Epoch: 3, Iter: 240, Loss: 0.85238\n",
            "[TRAIN] Epoch: 3, Iter: 320, Loss: 1.03494\n",
            "== [TRAIN] Epoch: 3, Accuracy: 0.679 ==>\n",
            "[VAL] Epoch: 3, Iter: 0, Loss: 0.89496\n",
            "=== [VAL] Epoch: 3, Iter: 39, Accuracy: 0.710 ===>\n",
            "====== Epoch 4 ======>\n",
            "[TRAIN] Epoch: 4, Iter: 0, Loss: 0.82814\n",
            "[TRAIN] Epoch: 4, Iter: 80, Loss: 0.81271\n",
            "[TRAIN] Epoch: 4, Iter: 160, Loss: 0.84868\n",
            "[TRAIN] Epoch: 4, Iter: 240, Loss: 0.72997\n",
            "[TRAIN] Epoch: 4, Iter: 320, Loss: 0.72125\n",
            "== [TRAIN] Epoch: 4, Accuracy: 0.729 ==>\n",
            "[VAL] Epoch: 4, Iter: 0, Loss: 0.81871\n",
            "=== [VAL] Epoch: 4, Iter: 39, Accuracy: 0.752 ===>\n",
            "====== Epoch 5 ======>\n",
            "[TRAIN] Epoch: 5, Iter: 0, Loss: 0.67141\n",
            "[TRAIN] Epoch: 5, Iter: 80, Loss: 0.60088\n",
            "[TRAIN] Epoch: 5, Iter: 160, Loss: 0.59776\n",
            "[TRAIN] Epoch: 5, Iter: 240, Loss: 0.60853\n",
            "[TRAIN] Epoch: 5, Iter: 320, Loss: 0.49339\n",
            "== [TRAIN] Epoch: 5, Accuracy: 0.771 ==>\n",
            "[VAL] Epoch: 5, Iter: 0, Loss: 0.77674\n",
            "=== [VAL] Epoch: 5, Iter: 39, Accuracy: 0.769 ===>\n",
            "====== Epoch 6 ======>\n",
            "[TRAIN] Epoch: 6, Iter: 0, Loss: 0.76322\n",
            "[TRAIN] Epoch: 6, Iter: 80, Loss: 0.50403\n",
            "[TRAIN] Epoch: 6, Iter: 160, Loss: 0.48220\n",
            "[TRAIN] Epoch: 6, Iter: 240, Loss: 0.58133\n",
            "[TRAIN] Epoch: 6, Iter: 320, Loss: 0.35814\n",
            "== [TRAIN] Epoch: 6, Accuracy: 0.803 ==>\n",
            "[VAL] Epoch: 6, Iter: 0, Loss: 0.52378\n",
            "=== [VAL] Epoch: 6, Iter: 39, Accuracy: 0.806 ===>\n",
            "====== Epoch 7 ======>\n",
            "[TRAIN] Epoch: 7, Iter: 0, Loss: 0.42578\n",
            "[TRAIN] Epoch: 7, Iter: 80, Loss: 0.53121\n",
            "[TRAIN] Epoch: 7, Iter: 160, Loss: 0.47951\n",
            "[TRAIN] Epoch: 7, Iter: 240, Loss: 0.48116\n",
            "[TRAIN] Epoch: 7, Iter: 320, Loss: 0.44983\n",
            "== [TRAIN] Epoch: 7, Accuracy: 0.825 ==>\n",
            "[VAL] Epoch: 7, Iter: 0, Loss: 0.51381\n",
            "=== [VAL] Epoch: 7, Iter: 39, Accuracy: 0.829 ===>\n",
            "====== Epoch 8 ======>\n",
            "[TRAIN] Epoch: 8, Iter: 0, Loss: 0.55676\n",
            "[TRAIN] Epoch: 8, Iter: 80, Loss: 0.38968\n",
            "[TRAIN] Epoch: 8, Iter: 160, Loss: 0.42853\n",
            "[TRAIN] Epoch: 8, Iter: 240, Loss: 0.49505\n",
            "[TRAIN] Epoch: 8, Iter: 320, Loss: 0.45247\n",
            "== [TRAIN] Epoch: 8, Accuracy: 0.840 ==>\n",
            "[VAL] Epoch: 8, Iter: 0, Loss: 0.51077\n",
            "=== [VAL] Epoch: 8, Iter: 39, Accuracy: 0.840 ===>\n",
            "====== Epoch 9 ======>\n",
            "[TRAIN] Epoch: 9, Iter: 0, Loss: 0.35549\n",
            "[TRAIN] Epoch: 9, Iter: 80, Loss: 0.58259\n",
            "[TRAIN] Epoch: 9, Iter: 160, Loss: 0.55687\n",
            "[TRAIN] Epoch: 9, Iter: 240, Loss: 0.48759\n",
            "[TRAIN] Epoch: 9, Iter: 320, Loss: 0.50097\n",
            "== [TRAIN] Epoch: 9, Accuracy: 0.856 ==>\n",
            "[VAL] Epoch: 9, Iter: 0, Loss: 0.36667\n",
            "=== [VAL] Epoch: 9, Iter: 39, Accuracy: 0.865 ===>\n",
            "====== Epoch 10 ======>\n",
            "[TRAIN] Epoch: 10, Iter: 0, Loss: 0.26170\n",
            "[TRAIN] Epoch: 10, Iter: 80, Loss: 0.33314\n",
            "[TRAIN] Epoch: 10, Iter: 160, Loss: 0.35943\n",
            "[TRAIN] Epoch: 10, Iter: 240, Loss: 0.42706\n",
            "[TRAIN] Epoch: 10, Iter: 320, Loss: 0.27622\n",
            "== [TRAIN] Epoch: 10, Accuracy: 0.873 ==>\n",
            "[VAL] Epoch: 10, Iter: 0, Loss: 0.31629\n",
            "=== [VAL] Epoch: 10, Iter: 39, Accuracy: 0.887 ===>\n",
            "====== Epoch 11 ======>\n",
            "[TRAIN] Epoch: 11, Iter: 0, Loss: 0.30817\n",
            "[TRAIN] Epoch: 11, Iter: 80, Loss: 0.23441\n",
            "[TRAIN] Epoch: 11, Iter: 160, Loss: 0.36882\n",
            "[TRAIN] Epoch: 11, Iter: 240, Loss: 0.31222\n",
            "[TRAIN] Epoch: 11, Iter: 320, Loss: 0.40225\n",
            "== [TRAIN] Epoch: 11, Accuracy: 0.885 ==>\n",
            "[VAL] Epoch: 11, Iter: 0, Loss: 0.45348\n",
            "=== [VAL] Epoch: 11, Iter: 39, Accuracy: 0.832 ===>\n",
            "====== Epoch 12 ======>\n",
            "[TRAIN] Epoch: 12, Iter: 0, Loss: 0.37397\n",
            "[TRAIN] Epoch: 12, Iter: 80, Loss: 0.27830\n",
            "[TRAIN] Epoch: 12, Iter: 160, Loss: 0.35139\n",
            "[TRAIN] Epoch: 12, Iter: 240, Loss: 0.22697\n",
            "[TRAIN] Epoch: 12, Iter: 320, Loss: 0.31162\n",
            "== [TRAIN] Epoch: 12, Accuracy: 0.893 ==>\n",
            "[VAL] Epoch: 12, Iter: 0, Loss: 0.33037\n",
            "=== [VAL] Epoch: 12, Iter: 39, Accuracy: 0.908 ===>\n",
            "====== Epoch 13 ======>\n",
            "[TRAIN] Epoch: 13, Iter: 0, Loss: 0.20834\n",
            "[TRAIN] Epoch: 13, Iter: 80, Loss: 0.34751\n",
            "[TRAIN] Epoch: 13, Iter: 160, Loss: 0.32820\n",
            "[TRAIN] Epoch: 13, Iter: 240, Loss: 0.26258\n",
            "[TRAIN] Epoch: 13, Iter: 320, Loss: 0.18337\n",
            "== [TRAIN] Epoch: 13, Accuracy: 0.903 ==>\n",
            "[VAL] Epoch: 13, Iter: 0, Loss: 0.26558\n",
            "=== [VAL] Epoch: 13, Iter: 39, Accuracy: 0.891 ===>\n",
            "====== Epoch 14 ======>\n",
            "[TRAIN] Epoch: 14, Iter: 0, Loss: 0.28957\n",
            "[TRAIN] Epoch: 14, Iter: 80, Loss: 0.38729\n",
            "[TRAIN] Epoch: 14, Iter: 160, Loss: 0.42570\n",
            "[TRAIN] Epoch: 14, Iter: 240, Loss: 0.16866\n",
            "[TRAIN] Epoch: 14, Iter: 320, Loss: 0.20350\n",
            "== [TRAIN] Epoch: 14, Accuracy: 0.910 ==>\n",
            "[VAL] Epoch: 14, Iter: 0, Loss: 0.28286\n",
            "=== [VAL] Epoch: 14, Iter: 39, Accuracy: 0.905 ===>\n",
            "====== Epoch 15 ======>\n",
            "[TRAIN] Epoch: 15, Iter: 0, Loss: 0.16171\n",
            "[TRAIN] Epoch: 15, Iter: 80, Loss: 0.17986\n",
            "[TRAIN] Epoch: 15, Iter: 160, Loss: 0.17220\n",
            "[TRAIN] Epoch: 15, Iter: 240, Loss: 0.24500\n",
            "[TRAIN] Epoch: 15, Iter: 320, Loss: 0.27920\n",
            "== [TRAIN] Epoch: 15, Accuracy: 0.919 ==>\n",
            "[VAL] Epoch: 15, Iter: 0, Loss: 0.33713\n",
            "=== [VAL] Epoch: 15, Iter: 39, Accuracy: 0.911 ===>\n",
            "====== Epoch 16 ======>\n",
            "[TRAIN] Epoch: 16, Iter: 0, Loss: 0.14778\n",
            "[TRAIN] Epoch: 16, Iter: 80, Loss: 0.16715\n",
            "[TRAIN] Epoch: 16, Iter: 160, Loss: 0.18241\n",
            "[TRAIN] Epoch: 16, Iter: 240, Loss: 0.35529\n",
            "[TRAIN] Epoch: 16, Iter: 320, Loss: 0.16710\n",
            "== [TRAIN] Epoch: 16, Accuracy: 0.925 ==>\n",
            "[VAL] Epoch: 16, Iter: 0, Loss: 0.21907\n",
            "=== [VAL] Epoch: 16, Iter: 39, Accuracy: 0.939 ===>\n",
            "====== Epoch 17 ======>\n",
            "[TRAIN] Epoch: 17, Iter: 0, Loss: 0.23681\n",
            "[TRAIN] Epoch: 17, Iter: 80, Loss: 0.13256\n",
            "[TRAIN] Epoch: 17, Iter: 160, Loss: 0.20251\n",
            "[TRAIN] Epoch: 17, Iter: 240, Loss: 0.18778\n",
            "[TRAIN] Epoch: 17, Iter: 320, Loss: 0.31319\n",
            "== [TRAIN] Epoch: 17, Accuracy: 0.932 ==>\n",
            "[VAL] Epoch: 17, Iter: 0, Loss: 0.18680\n",
            "=== [VAL] Epoch: 17, Iter: 39, Accuracy: 0.927 ===>\n",
            "====== Epoch 18 ======>\n",
            "[TRAIN] Epoch: 18, Iter: 0, Loss: 0.14230\n",
            "[TRAIN] Epoch: 18, Iter: 80, Loss: 0.24879\n",
            "[TRAIN] Epoch: 18, Iter: 160, Loss: 0.14295\n",
            "[TRAIN] Epoch: 18, Iter: 240, Loss: 0.19458\n",
            "[TRAIN] Epoch: 18, Iter: 320, Loss: 0.23333\n",
            "== [TRAIN] Epoch: 18, Accuracy: 0.936 ==>\n",
            "[VAL] Epoch: 18, Iter: 0, Loss: 0.20046\n",
            "=== [VAL] Epoch: 18, Iter: 39, Accuracy: 0.926 ===>\n",
            "====== Epoch 19 ======>\n",
            "[TRAIN] Epoch: 19, Iter: 0, Loss: 0.19016\n",
            "[TRAIN] Epoch: 19, Iter: 80, Loss: 0.07603\n",
            "[TRAIN] Epoch: 19, Iter: 160, Loss: 0.06518\n",
            "[TRAIN] Epoch: 19, Iter: 240, Loss: 0.14804\n",
            "[TRAIN] Epoch: 19, Iter: 320, Loss: 0.16547\n",
            "== [TRAIN] Epoch: 19, Accuracy: 0.941 ==>\n",
            "[VAL] Epoch: 19, Iter: 0, Loss: 0.18084\n",
            "=== [VAL] Epoch: 19, Iter: 39, Accuracy: 0.942 ===>\n",
            "====== Epoch 20 ======>\n",
            "[TRAIN] Epoch: 20, Iter: 0, Loss: 0.09628\n",
            "[TRAIN] Epoch: 20, Iter: 80, Loss: 0.11457\n",
            "[TRAIN] Epoch: 20, Iter: 160, Loss: 0.24996\n",
            "[TRAIN] Epoch: 20, Iter: 240, Loss: 0.09901\n",
            "[TRAIN] Epoch: 20, Iter: 320, Loss: 0.11477\n",
            "== [TRAIN] Epoch: 20, Accuracy: 0.946 ==>\n",
            "[VAL] Epoch: 20, Iter: 0, Loss: 0.15920\n",
            "=== [VAL] Epoch: 20, Iter: 39, Accuracy: 0.947 ===>\n",
            "====== Epoch 21 ======>\n",
            "[TRAIN] Epoch: 21, Iter: 0, Loss: 0.14602\n",
            "[TRAIN] Epoch: 21, Iter: 80, Loss: 0.20547\n",
            "[TRAIN] Epoch: 21, Iter: 160, Loss: 0.15393\n",
            "[TRAIN] Epoch: 21, Iter: 240, Loss: 0.17360\n",
            "[TRAIN] Epoch: 21, Iter: 320, Loss: 0.06561\n",
            "== [TRAIN] Epoch: 21, Accuracy: 0.948 ==>\n",
            "[VAL] Epoch: 21, Iter: 0, Loss: 0.19011\n",
            "=== [VAL] Epoch: 21, Iter: 39, Accuracy: 0.950 ===>\n",
            "====== Epoch 22 ======>\n",
            "[TRAIN] Epoch: 22, Iter: 0, Loss: 0.10435\n",
            "[TRAIN] Epoch: 22, Iter: 80, Loss: 0.08841\n",
            "[TRAIN] Epoch: 22, Iter: 160, Loss: 0.16614\n",
            "[TRAIN] Epoch: 22, Iter: 240, Loss: 0.13984\n",
            "[TRAIN] Epoch: 22, Iter: 320, Loss: 0.09566\n",
            "== [TRAIN] Epoch: 22, Accuracy: 0.954 ==>\n",
            "[VAL] Epoch: 22, Iter: 0, Loss: 0.20100\n",
            "=== [VAL] Epoch: 22, Iter: 39, Accuracy: 0.948 ===>\n",
            "====== Epoch 23 ======>\n",
            "[TRAIN] Epoch: 23, Iter: 0, Loss: 0.15465\n",
            "[TRAIN] Epoch: 23, Iter: 80, Loss: 0.11025\n",
            "[TRAIN] Epoch: 23, Iter: 160, Loss: 0.09241\n",
            "[TRAIN] Epoch: 23, Iter: 240, Loss: 0.22949\n",
            "[TRAIN] Epoch: 23, Iter: 320, Loss: 0.19548\n",
            "== [TRAIN] Epoch: 23, Accuracy: 0.957 ==>\n",
            "[VAL] Epoch: 23, Iter: 0, Loss: 0.08102\n",
            "=== [VAL] Epoch: 23, Iter: 39, Accuracy: 0.964 ===>\n",
            "====== Epoch 24 ======>\n",
            "[TRAIN] Epoch: 24, Iter: 0, Loss: 0.06661\n",
            "[TRAIN] Epoch: 24, Iter: 80, Loss: 0.18084\n",
            "[TRAIN] Epoch: 24, Iter: 160, Loss: 0.18352\n",
            "[TRAIN] Epoch: 24, Iter: 240, Loss: 0.07244\n",
            "[TRAIN] Epoch: 24, Iter: 320, Loss: 0.14338\n",
            "== [TRAIN] Epoch: 24, Accuracy: 0.959 ==>\n",
            "[VAL] Epoch: 24, Iter: 0, Loss: 0.18102\n",
            "=== [VAL] Epoch: 24, Iter: 39, Accuracy: 0.946 ===>\n",
            "====== Epoch 25 ======>\n",
            "[TRAIN] Epoch: 25, Iter: 0, Loss: 0.06171\n",
            "[TRAIN] Epoch: 25, Iter: 80, Loss: 0.05151\n",
            "[TRAIN] Epoch: 25, Iter: 160, Loss: 0.04228\n",
            "[TRAIN] Epoch: 25, Iter: 240, Loss: 0.06517\n",
            "[TRAIN] Epoch: 25, Iter: 320, Loss: 0.14061\n",
            "== [TRAIN] Epoch: 25, Accuracy: 0.962 ==>\n",
            "[VAL] Epoch: 25, Iter: 0, Loss: 0.20910\n",
            "=== [VAL] Epoch: 25, Iter: 39, Accuracy: 0.966 ===>\n",
            "====== Epoch 26 ======>\n",
            "[TRAIN] Epoch: 26, Iter: 0, Loss: 0.06352\n",
            "[TRAIN] Epoch: 26, Iter: 80, Loss: 0.14279\n",
            "[TRAIN] Epoch: 26, Iter: 160, Loss: 0.14853\n",
            "[TRAIN] Epoch: 26, Iter: 240, Loss: 0.10620\n",
            "[TRAIN] Epoch: 26, Iter: 320, Loss: 0.10632\n",
            "== [TRAIN] Epoch: 26, Accuracy: 0.962 ==>\n",
            "[VAL] Epoch: 26, Iter: 0, Loss: 0.10320\n",
            "=== [VAL] Epoch: 26, Iter: 39, Accuracy: 0.962 ===>\n",
            "====== Epoch 27 ======>\n",
            "[TRAIN] Epoch: 27, Iter: 0, Loss: 0.14612\n",
            "[TRAIN] Epoch: 27, Iter: 80, Loss: 0.07607\n",
            "[TRAIN] Epoch: 27, Iter: 160, Loss: 0.10213\n",
            "[TRAIN] Epoch: 27, Iter: 240, Loss: 0.16208\n",
            "[TRAIN] Epoch: 27, Iter: 320, Loss: 0.05429\n",
            "== [TRAIN] Epoch: 27, Accuracy: 0.967 ==>\n",
            "[VAL] Epoch: 27, Iter: 0, Loss: 0.17527\n",
            "=== [VAL] Epoch: 27, Iter: 39, Accuracy: 0.969 ===>\n",
            "====== Epoch 28 ======>\n",
            "[TRAIN] Epoch: 28, Iter: 0, Loss: 0.04197\n",
            "[TRAIN] Epoch: 28, Iter: 80, Loss: 0.14384\n",
            "[TRAIN] Epoch: 28, Iter: 160, Loss: 0.11762\n",
            "[TRAIN] Epoch: 28, Iter: 240, Loss: 0.05502\n",
            "[TRAIN] Epoch: 28, Iter: 320, Loss: 0.07520\n",
            "== [TRAIN] Epoch: 28, Accuracy: 0.967 ==>\n",
            "[VAL] Epoch: 28, Iter: 0, Loss: 0.09954\n",
            "=== [VAL] Epoch: 28, Iter: 39, Accuracy: 0.969 ===>\n",
            "====== Epoch 29 ======>\n",
            "[TRAIN] Epoch: 29, Iter: 0, Loss: 0.11146\n",
            "[TRAIN] Epoch: 29, Iter: 80, Loss: 0.05989\n",
            "[TRAIN] Epoch: 29, Iter: 160, Loss: 0.09998\n",
            "[TRAIN] Epoch: 29, Iter: 240, Loss: 0.10644\n",
            "[TRAIN] Epoch: 29, Iter: 320, Loss: 0.14355\n",
            "== [TRAIN] Epoch: 29, Accuracy: 0.969 ==>\n",
            "[VAL] Epoch: 29, Iter: 0, Loss: 0.23017\n",
            "=== [VAL] Epoch: 29, Iter: 39, Accuracy: 0.962 ===>\n",
            "====== Epoch 30 ======>\n",
            "[TRAIN] Epoch: 30, Iter: 0, Loss: 0.06885\n",
            "[TRAIN] Epoch: 30, Iter: 80, Loss: 0.08363\n",
            "[TRAIN] Epoch: 30, Iter: 160, Loss: 0.08146\n",
            "[TRAIN] Epoch: 30, Iter: 240, Loss: 0.09970\n",
            "[TRAIN] Epoch: 30, Iter: 320, Loss: 0.12215\n",
            "== [TRAIN] Epoch: 30, Accuracy: 0.970 ==>\n",
            "[VAL] Epoch: 30, Iter: 0, Loss: 0.15281\n",
            "=== [VAL] Epoch: 30, Iter: 39, Accuracy: 0.972 ===>\n",
            "====== Epoch 31 ======>\n",
            "[TRAIN] Epoch: 31, Iter: 0, Loss: 0.08625\n",
            "[TRAIN] Epoch: 31, Iter: 80, Loss: 0.08709\n",
            "[TRAIN] Epoch: 31, Iter: 160, Loss: 0.10660\n",
            "[TRAIN] Epoch: 31, Iter: 240, Loss: 0.06769\n",
            "[TRAIN] Epoch: 31, Iter: 320, Loss: 0.13366\n",
            "== [TRAIN] Epoch: 31, Accuracy: 0.972 ==>\n",
            "[VAL] Epoch: 31, Iter: 0, Loss: 0.15844\n",
            "=== [VAL] Epoch: 31, Iter: 39, Accuracy: 0.968 ===>\n",
            "====== Epoch 32 ======>\n",
            "[TRAIN] Epoch: 32, Iter: 0, Loss: 0.06484\n",
            "[TRAIN] Epoch: 32, Iter: 80, Loss: 0.08957\n",
            "[TRAIN] Epoch: 32, Iter: 160, Loss: 0.03733\n",
            "[TRAIN] Epoch: 32, Iter: 240, Loss: 0.08903\n",
            "[TRAIN] Epoch: 32, Iter: 320, Loss: 0.10898\n",
            "== [TRAIN] Epoch: 32, Accuracy: 0.973 ==>\n",
            "[VAL] Epoch: 32, Iter: 0, Loss: 0.22301\n",
            "=== [VAL] Epoch: 32, Iter: 39, Accuracy: 0.963 ===>\n",
            "====== Epoch 33 ======>\n",
            "[TRAIN] Epoch: 33, Iter: 0, Loss: 0.05142\n",
            "[TRAIN] Epoch: 33, Iter: 80, Loss: 0.03574\n",
            "[TRAIN] Epoch: 33, Iter: 160, Loss: 0.08195\n",
            "[TRAIN] Epoch: 33, Iter: 240, Loss: 0.02468\n",
            "[TRAIN] Epoch: 33, Iter: 320, Loss: 0.08523\n",
            "== [TRAIN] Epoch: 33, Accuracy: 0.973 ==>\n",
            "[VAL] Epoch: 33, Iter: 0, Loss: 0.11688\n",
            "=== [VAL] Epoch: 33, Iter: 39, Accuracy: 0.975 ===>\n",
            "====== Epoch 34 ======>\n",
            "[TRAIN] Epoch: 34, Iter: 0, Loss: 0.06665\n",
            "[TRAIN] Epoch: 34, Iter: 80, Loss: 0.05175\n",
            "[TRAIN] Epoch: 34, Iter: 160, Loss: 0.04543\n",
            "[TRAIN] Epoch: 34, Iter: 240, Loss: 0.04490\n",
            "[TRAIN] Epoch: 34, Iter: 320, Loss: 0.03341\n",
            "== [TRAIN] Epoch: 34, Accuracy: 0.974 ==>\n",
            "[VAL] Epoch: 34, Iter: 0, Loss: 0.20777\n",
            "=== [VAL] Epoch: 34, Iter: 39, Accuracy: 0.977 ===>\n",
            "====== Epoch 35 ======>\n",
            "[TRAIN] Epoch: 35, Iter: 0, Loss: 0.03573\n",
            "[TRAIN] Epoch: 35, Iter: 80, Loss: 0.02864\n",
            "[TRAIN] Epoch: 35, Iter: 160, Loss: 0.15993\n",
            "[TRAIN] Epoch: 35, Iter: 240, Loss: 0.12696\n",
            "[TRAIN] Epoch: 35, Iter: 320, Loss: 0.04699\n",
            "== [TRAIN] Epoch: 35, Accuracy: 0.974 ==>\n",
            "[VAL] Epoch: 35, Iter: 0, Loss: 0.14860\n",
            "=== [VAL] Epoch: 35, Iter: 39, Accuracy: 0.969 ===>\n",
            "====== Epoch 36 ======>\n",
            "[TRAIN] Epoch: 36, Iter: 0, Loss: 0.05450\n",
            "[TRAIN] Epoch: 36, Iter: 80, Loss: 0.08360\n",
            "[TRAIN] Epoch: 36, Iter: 160, Loss: 0.06778\n",
            "[TRAIN] Epoch: 36, Iter: 240, Loss: 0.01821\n",
            "[TRAIN] Epoch: 36, Iter: 320, Loss: 0.05413\n",
            "== [TRAIN] Epoch: 36, Accuracy: 0.975 ==>\n",
            "[VAL] Epoch: 36, Iter: 0, Loss: 0.16419\n",
            "=== [VAL] Epoch: 36, Iter: 39, Accuracy: 0.979 ===>\n",
            "====== Epoch 37 ======>\n",
            "[TRAIN] Epoch: 37, Iter: 0, Loss: 0.09320\n",
            "[TRAIN] Epoch: 37, Iter: 80, Loss: 0.05836\n",
            "[TRAIN] Epoch: 37, Iter: 160, Loss: 0.06293\n",
            "[TRAIN] Epoch: 37, Iter: 240, Loss: 0.09774\n",
            "[TRAIN] Epoch: 37, Iter: 320, Loss: 0.04810\n",
            "== [TRAIN] Epoch: 37, Accuracy: 0.977 ==>\n",
            "[VAL] Epoch: 37, Iter: 0, Loss: 0.12923\n",
            "=== [VAL] Epoch: 37, Iter: 39, Accuracy: 0.980 ===>\n",
            "====== Epoch 38 ======>\n",
            "[TRAIN] Epoch: 38, Iter: 0, Loss: 0.02872\n",
            "[TRAIN] Epoch: 38, Iter: 80, Loss: 0.01318\n",
            "[TRAIN] Epoch: 38, Iter: 160, Loss: 0.09397\n",
            "[TRAIN] Epoch: 38, Iter: 240, Loss: 0.09438\n",
            "[TRAIN] Epoch: 38, Iter: 320, Loss: 0.03617\n",
            "== [TRAIN] Epoch: 38, Accuracy: 0.976 ==>\n",
            "[VAL] Epoch: 38, Iter: 0, Loss: 0.13906\n",
            "=== [VAL] Epoch: 38, Iter: 39, Accuracy: 0.978 ===>\n",
            "====== Epoch 39 ======>\n",
            "[TRAIN] Epoch: 39, Iter: 0, Loss: 0.06192\n",
            "[TRAIN] Epoch: 39, Iter: 80, Loss: 0.04813\n",
            "[TRAIN] Epoch: 39, Iter: 160, Loss: 0.01526\n",
            "[TRAIN] Epoch: 39, Iter: 240, Loss: 0.12040\n",
            "[TRAIN] Epoch: 39, Iter: 320, Loss: 0.03459\n",
            "== [TRAIN] Epoch: 39, Accuracy: 0.978 ==>\n",
            "[VAL] Epoch: 39, Iter: 0, Loss: 0.19667\n",
            "=== [VAL] Epoch: 39, Iter: 39, Accuracy: 0.984 ===>\n",
            "[TEST] Epoch: 39, Iter: 0, Loss: 0.42063\n",
            "=== [TEST] Epoch: 39, Iter: 78, Accuracy: 0.886 ===>\n",
            "===== Best validation Accuracy: 0.984 =====>\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Build model RESNET18...\n",
            "Loading model config from /content/IFT6135-2025-First-Assignment/HW1_2025/assignment1_release/model_configs/resnet18.json\n",
            "########## RESNET18 CONFIG ################\n",
            "num_classes:\t10\n",
            "############################################\n",
            "Initialized RESNET18 model with 11173962 total parameters, of which 11173962 are learnable.\n",
            "====== Epoch 0 ======>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN] Epoch: 0, Iter: 0, Loss: 2.35414\n",
            "[TRAIN] Epoch: 0, Iter: 80, Loss: 1.58104\n",
            "[TRAIN] Epoch: 0, Iter: 160, Loss: 1.41598\n",
            "[TRAIN] Epoch: 0, Iter: 240, Loss: 1.36446\n",
            "[TRAIN] Epoch: 0, Iter: 320, Loss: 1.19514\n",
            "== [TRAIN] Epoch: 0, Accuracy: 0.478 ==>\n",
            "[VAL] Epoch: 0, Iter: 0, Loss: 1.48316\n",
            "=== [VAL] Epoch: 0, Iter: 39, Accuracy: 0.548 ===>\n",
            "====== Epoch 1 ======>\n",
            "[TRAIN] Epoch: 1, Iter: 0, Loss: 1.02808\n",
            "[TRAIN] Epoch: 1, Iter: 80, Loss: 0.96841\n",
            "[TRAIN] Epoch: 1, Iter: 160, Loss: 0.93292\n",
            "[TRAIN] Epoch: 1, Iter: 240, Loss: 0.91708\n",
            "[TRAIN] Epoch: 1, Iter: 320, Loss: 0.79370\n",
            "== [TRAIN] Epoch: 1, Accuracy: 0.662 ==>\n",
            "[VAL] Epoch: 1, Iter: 0, Loss: 1.08330\n",
            "=== [VAL] Epoch: 1, Iter: 39, Accuracy: 0.634 ===>\n",
            "====== Epoch 2 ======>\n",
            "[TRAIN] Epoch: 2, Iter: 0, Loss: 0.84451\n",
            "[TRAIN] Epoch: 2, Iter: 80, Loss: 0.78177\n",
            "[TRAIN] Epoch: 2, Iter: 160, Loss: 0.74784\n",
            "[TRAIN] Epoch: 2, Iter: 240, Loss: 0.84980\n",
            "[TRAIN] Epoch: 2, Iter: 320, Loss: 0.70575\n",
            "== [TRAIN] Epoch: 2, Accuracy: 0.740 ==>\n",
            "[VAL] Epoch: 2, Iter: 0, Loss: 0.93155\n",
            "=== [VAL] Epoch: 2, Iter: 39, Accuracy: 0.672 ===>\n",
            "====== Epoch 3 ======>\n",
            "[TRAIN] Epoch: 3, Iter: 0, Loss: 0.71085\n",
            "[TRAIN] Epoch: 3, Iter: 80, Loss: 0.64198\n",
            "[TRAIN] Epoch: 3, Iter: 160, Loss: 0.65109\n",
            "[TRAIN] Epoch: 3, Iter: 240, Loss: 0.51079\n",
            "[TRAIN] Epoch: 3, Iter: 320, Loss: 0.75802\n",
            "== [TRAIN] Epoch: 3, Accuracy: 0.783 ==>\n",
            "[VAL] Epoch: 3, Iter: 0, Loss: 0.82333\n",
            "=== [VAL] Epoch: 3, Iter: 39, Accuracy: 0.760 ===>\n",
            "====== Epoch 4 ======>\n",
            "[TRAIN] Epoch: 4, Iter: 0, Loss: 0.54210\n",
            "[TRAIN] Epoch: 4, Iter: 80, Loss: 0.62045\n",
            "[TRAIN] Epoch: 4, Iter: 160, Loss: 0.62322\n",
            "[TRAIN] Epoch: 4, Iter: 240, Loss: 0.45181\n",
            "[TRAIN] Epoch: 4, Iter: 320, Loss: 0.44739\n",
            "== [TRAIN] Epoch: 4, Accuracy: 0.813 ==>\n",
            "[VAL] Epoch: 4, Iter: 0, Loss: 0.50548\n",
            "=== [VAL] Epoch: 4, Iter: 39, Accuracy: 0.835 ===>\n",
            "====== Epoch 5 ======>\n",
            "[TRAIN] Epoch: 5, Iter: 0, Loss: 0.42216\n",
            "[TRAIN] Epoch: 5, Iter: 80, Loss: 0.33960\n",
            "[TRAIN] Epoch: 5, Iter: 160, Loss: 0.59745\n",
            "[TRAIN] Epoch: 5, Iter: 240, Loss: 0.46856\n",
            "[TRAIN] Epoch: 5, Iter: 320, Loss: 0.26867\n",
            "== [TRAIN] Epoch: 5, Accuracy: 0.833 ==>\n",
            "[VAL] Epoch: 5, Iter: 0, Loss: 0.43375\n",
            "=== [VAL] Epoch: 5, Iter: 39, Accuracy: 0.844 ===>\n",
            "====== Epoch 6 ======>\n",
            "[TRAIN] Epoch: 6, Iter: 0, Loss: 0.54487\n",
            "[TRAIN] Epoch: 6, Iter: 80, Loss: 0.49972\n",
            "[TRAIN] Epoch: 6, Iter: 160, Loss: 0.27124\n",
            "[TRAIN] Epoch: 6, Iter: 240, Loss: 0.41373\n",
            "[TRAIN] Epoch: 6, Iter: 320, Loss: 0.28137\n",
            "== [TRAIN] Epoch: 6, Accuracy: 0.850 ==>\n",
            "[VAL] Epoch: 6, Iter: 0, Loss: 0.50578\n",
            "=== [VAL] Epoch: 6, Iter: 39, Accuracy: 0.845 ===>\n",
            "====== Epoch 7 ======>\n",
            "[TRAIN] Epoch: 7, Iter: 0, Loss: 0.38188\n",
            "[TRAIN] Epoch: 7, Iter: 80, Loss: 0.29865\n",
            "[TRAIN] Epoch: 7, Iter: 160, Loss: 0.38231\n",
            "[TRAIN] Epoch: 7, Iter: 240, Loss: 0.34887\n",
            "[TRAIN] Epoch: 7, Iter: 320, Loss: 0.39369\n",
            "== [TRAIN] Epoch: 7, Accuracy: 0.862 ==>\n",
            "[VAL] Epoch: 7, Iter: 0, Loss: 0.46338\n",
            "=== [VAL] Epoch: 7, Iter: 39, Accuracy: 0.864 ===>\n",
            "====== Epoch 8 ======>\n",
            "[TRAIN] Epoch: 8, Iter: 0, Loss: 0.43687\n",
            "[TRAIN] Epoch: 8, Iter: 80, Loss: 0.33037\n",
            "[TRAIN] Epoch: 8, Iter: 160, Loss: 0.25127\n",
            "[TRAIN] Epoch: 8, Iter: 240, Loss: 0.41057\n",
            "[TRAIN] Epoch: 8, Iter: 320, Loss: 0.43592\n",
            "== [TRAIN] Epoch: 8, Accuracy: 0.874 ==>\n",
            "[VAL] Epoch: 8, Iter: 0, Loss: 0.31446\n",
            "=== [VAL] Epoch: 8, Iter: 39, Accuracy: 0.884 ===>\n",
            "====== Epoch 9 ======>\n",
            "[TRAIN] Epoch: 9, Iter: 0, Loss: 0.23092\n",
            "[TRAIN] Epoch: 9, Iter: 80, Loss: 0.34104\n",
            "[TRAIN] Epoch: 9, Iter: 160, Loss: 0.47792\n",
            "[TRAIN] Epoch: 9, Iter: 240, Loss: 0.38420\n",
            "[TRAIN] Epoch: 9, Iter: 320, Loss: 0.44072\n",
            "== [TRAIN] Epoch: 9, Accuracy: 0.885 ==>\n",
            "[VAL] Epoch: 9, Iter: 0, Loss: 0.22302\n",
            "=== [VAL] Epoch: 9, Iter: 39, Accuracy: 0.911 ===>\n",
            "====== Epoch 10 ======>\n",
            "[TRAIN] Epoch: 10, Iter: 0, Loss: 0.22215\n",
            "[TRAIN] Epoch: 10, Iter: 80, Loss: 0.39616\n",
            "[TRAIN] Epoch: 10, Iter: 160, Loss: 0.33729\n",
            "[TRAIN] Epoch: 10, Iter: 240, Loss: 0.36971\n",
            "[TRAIN] Epoch: 10, Iter: 320, Loss: 0.22767\n",
            "== [TRAIN] Epoch: 10, Accuracy: 0.895 ==>\n",
            "[VAL] Epoch: 10, Iter: 0, Loss: 0.29350\n",
            "=== [VAL] Epoch: 10, Iter: 39, Accuracy: 0.898 ===>\n",
            "====== Epoch 11 ======>\n",
            "[TRAIN] Epoch: 11, Iter: 0, Loss: 0.20865\n",
            "[TRAIN] Epoch: 11, Iter: 80, Loss: 0.23588\n",
            "[TRAIN] Epoch: 11, Iter: 160, Loss: 0.28670\n",
            "[TRAIN] Epoch: 11, Iter: 240, Loss: 0.27862\n",
            "[TRAIN] Epoch: 11, Iter: 320, Loss: 0.34642\n",
            "== [TRAIN] Epoch: 11, Accuracy: 0.905 ==>\n",
            "[VAL] Epoch: 11, Iter: 0, Loss: 0.33759\n",
            "=== [VAL] Epoch: 11, Iter: 39, Accuracy: 0.865 ===>\n",
            "====== Epoch 12 ======>\n",
            "[TRAIN] Epoch: 12, Iter: 0, Loss: 0.24622\n",
            "[TRAIN] Epoch: 12, Iter: 80, Loss: 0.17005\n",
            "[TRAIN] Epoch: 12, Iter: 160, Loss: 0.26774\n",
            "[TRAIN] Epoch: 12, Iter: 240, Loss: 0.25349\n",
            "[TRAIN] Epoch: 12, Iter: 320, Loss: 0.28518\n",
            "== [TRAIN] Epoch: 12, Accuracy: 0.910 ==>\n",
            "[VAL] Epoch: 12, Iter: 0, Loss: 0.24631\n",
            "=== [VAL] Epoch: 12, Iter: 39, Accuracy: 0.930 ===>\n",
            "====== Epoch 13 ======>\n",
            "[TRAIN] Epoch: 13, Iter: 0, Loss: 0.23507\n",
            "[TRAIN] Epoch: 13, Iter: 80, Loss: 0.28337\n",
            "[TRAIN] Epoch: 13, Iter: 160, Loss: 0.24060\n",
            "[TRAIN] Epoch: 13, Iter: 240, Loss: 0.21642\n",
            "[TRAIN] Epoch: 13, Iter: 320, Loss: 0.30763\n",
            "== [TRAIN] Epoch: 13, Accuracy: 0.917 ==>\n",
            "[VAL] Epoch: 13, Iter: 0, Loss: 0.29482\n",
            "=== [VAL] Epoch: 13, Iter: 39, Accuracy: 0.908 ===>\n",
            "====== Epoch 14 ======>\n",
            "[TRAIN] Epoch: 14, Iter: 0, Loss: 0.27629\n",
            "[TRAIN] Epoch: 14, Iter: 80, Loss: 0.34182\n",
            "[TRAIN] Epoch: 14, Iter: 160, Loss: 0.33406\n",
            "[TRAIN] Epoch: 14, Iter: 240, Loss: 0.17514\n",
            "[TRAIN] Epoch: 14, Iter: 320, Loss: 0.22048\n",
            "== [TRAIN] Epoch: 14, Accuracy: 0.923 ==>\n",
            "[VAL] Epoch: 14, Iter: 0, Loss: 0.22147\n",
            "=== [VAL] Epoch: 14, Iter: 39, Accuracy: 0.933 ===>\n",
            "====== Epoch 15 ======>\n",
            "[TRAIN] Epoch: 15, Iter: 0, Loss: 0.12538\n",
            "[TRAIN] Epoch: 15, Iter: 80, Loss: 0.18752\n",
            "[TRAIN] Epoch: 15, Iter: 160, Loss: 0.18801\n",
            "[TRAIN] Epoch: 15, Iter: 240, Loss: 0.27566\n",
            "[TRAIN] Epoch: 15, Iter: 320, Loss: 0.18163\n",
            "== [TRAIN] Epoch: 15, Accuracy: 0.931 ==>\n",
            "[VAL] Epoch: 15, Iter: 0, Loss: 0.29049\n",
            "=== [VAL] Epoch: 15, Iter: 39, Accuracy: 0.950 ===>\n",
            "====== Epoch 16 ======>\n",
            "[TRAIN] Epoch: 16, Iter: 0, Loss: 0.12630\n",
            "[TRAIN] Epoch: 16, Iter: 80, Loss: 0.18577\n",
            "[TRAIN] Epoch: 16, Iter: 160, Loss: 0.15929\n",
            "[TRAIN] Epoch: 16, Iter: 240, Loss: 0.30482\n",
            "[TRAIN] Epoch: 16, Iter: 320, Loss: 0.13673\n",
            "== [TRAIN] Epoch: 16, Accuracy: 0.935 ==>\n",
            "[VAL] Epoch: 16, Iter: 0, Loss: 0.26152\n",
            "=== [VAL] Epoch: 16, Iter: 39, Accuracy: 0.942 ===>\n",
            "====== Epoch 17 ======>\n",
            "[TRAIN] Epoch: 17, Iter: 0, Loss: 0.13162\n",
            "[TRAIN] Epoch: 17, Iter: 80, Loss: 0.12760\n",
            "[TRAIN] Epoch: 17, Iter: 160, Loss: 0.13643\n",
            "[TRAIN] Epoch: 17, Iter: 240, Loss: 0.29155\n",
            "[TRAIN] Epoch: 17, Iter: 320, Loss: 0.21925\n",
            "== [TRAIN] Epoch: 17, Accuracy: 0.940 ==>\n",
            "[VAL] Epoch: 17, Iter: 0, Loss: 0.20060\n",
            "=== [VAL] Epoch: 17, Iter: 39, Accuracy: 0.943 ===>\n",
            "====== Epoch 18 ======>\n",
            "[TRAIN] Epoch: 18, Iter: 0, Loss: 0.10927\n",
            "[TRAIN] Epoch: 18, Iter: 80, Loss: 0.21390\n",
            "[TRAIN] Epoch: 18, Iter: 160, Loss: 0.16506\n",
            "[TRAIN] Epoch: 18, Iter: 240, Loss: 0.16991\n",
            "[TRAIN] Epoch: 18, Iter: 320, Loss: 0.16920\n",
            "== [TRAIN] Epoch: 18, Accuracy: 0.944 ==>\n",
            "[VAL] Epoch: 18, Iter: 0, Loss: 0.22155\n",
            "=== [VAL] Epoch: 18, Iter: 39, Accuracy: 0.955 ===>\n",
            "====== Epoch 19 ======>\n",
            "[TRAIN] Epoch: 19, Iter: 0, Loss: 0.08059\n",
            "[TRAIN] Epoch: 19, Iter: 80, Loss: 0.05637\n",
            "[TRAIN] Epoch: 19, Iter: 160, Loss: 0.05657\n",
            "[TRAIN] Epoch: 19, Iter: 240, Loss: 0.13998\n",
            "[TRAIN] Epoch: 19, Iter: 320, Loss: 0.07182\n",
            "== [TRAIN] Epoch: 19, Accuracy: 0.950 ==>\n",
            "[VAL] Epoch: 19, Iter: 0, Loss: 0.23813\n",
            "=== [VAL] Epoch: 19, Iter: 39, Accuracy: 0.962 ===>\n",
            "====== Epoch 20 ======>\n",
            "[TRAIN] Epoch: 20, Iter: 0, Loss: 0.12818\n",
            "[TRAIN] Epoch: 20, Iter: 80, Loss: 0.12471\n",
            "[TRAIN] Epoch: 20, Iter: 160, Loss: 0.08287\n",
            "[TRAIN] Epoch: 20, Iter: 240, Loss: 0.11451\n",
            "[TRAIN] Epoch: 20, Iter: 320, Loss: 0.10470\n",
            "== [TRAIN] Epoch: 20, Accuracy: 0.952 ==>\n",
            "[VAL] Epoch: 20, Iter: 0, Loss: 0.13132\n",
            "=== [VAL] Epoch: 20, Iter: 39, Accuracy: 0.961 ===>\n",
            "====== Epoch 21 ======>\n",
            "[TRAIN] Epoch: 21, Iter: 0, Loss: 0.10380\n",
            "[TRAIN] Epoch: 21, Iter: 80, Loss: 0.15108\n",
            "[TRAIN] Epoch: 21, Iter: 160, Loss: 0.09461\n",
            "[TRAIN] Epoch: 21, Iter: 240, Loss: 0.16690\n",
            "[TRAIN] Epoch: 21, Iter: 320, Loss: 0.10401\n",
            "== [TRAIN] Epoch: 21, Accuracy: 0.955 ==>\n",
            "[VAL] Epoch: 21, Iter: 0, Loss: 0.17753\n",
            "=== [VAL] Epoch: 21, Iter: 39, Accuracy: 0.954 ===>\n",
            "====== Epoch 22 ======>\n",
            "[TRAIN] Epoch: 22, Iter: 0, Loss: 0.11222\n",
            "[TRAIN] Epoch: 22, Iter: 80, Loss: 0.05868\n",
            "[TRAIN] Epoch: 22, Iter: 160, Loss: 0.17901\n",
            "[TRAIN] Epoch: 22, Iter: 240, Loss: 0.17378\n",
            "[TRAIN] Epoch: 22, Iter: 320, Loss: 0.12697\n",
            "== [TRAIN] Epoch: 22, Accuracy: 0.959 ==>\n",
            "[VAL] Epoch: 22, Iter: 0, Loss: 0.16818\n",
            "=== [VAL] Epoch: 22, Iter: 39, Accuracy: 0.962 ===>\n",
            "====== Epoch 23 ======>\n",
            "[TRAIN] Epoch: 23, Iter: 0, Loss: 0.05468\n",
            "[TRAIN] Epoch: 23, Iter: 80, Loss: 0.08411\n",
            "[TRAIN] Epoch: 23, Iter: 160, Loss: 0.09840\n",
            "[TRAIN] Epoch: 23, Iter: 240, Loss: 0.10655\n",
            "[TRAIN] Epoch: 23, Iter: 320, Loss: 0.15270\n",
            "== [TRAIN] Epoch: 23, Accuracy: 0.961 ==>\n",
            "[VAL] Epoch: 23, Iter: 0, Loss: 0.24356\n",
            "=== [VAL] Epoch: 23, Iter: 39, Accuracy: 0.951 ===>\n",
            "====== Epoch 24 ======>\n",
            "[TRAIN] Epoch: 24, Iter: 0, Loss: 0.03510\n",
            "[TRAIN] Epoch: 24, Iter: 80, Loss: 0.04589\n",
            "[TRAIN] Epoch: 24, Iter: 160, Loss: 0.08421\n",
            "[TRAIN] Epoch: 24, Iter: 240, Loss: 0.06068\n",
            "[TRAIN] Epoch: 24, Iter: 320, Loss: 0.11604\n",
            "== [TRAIN] Epoch: 24, Accuracy: 0.962 ==>\n",
            "[VAL] Epoch: 24, Iter: 0, Loss: 0.14863\n",
            "=== [VAL] Epoch: 24, Iter: 39, Accuracy: 0.971 ===>\n",
            "====== Epoch 25 ======>\n",
            "[TRAIN] Epoch: 25, Iter: 0, Loss: 0.03290\n",
            "[TRAIN] Epoch: 25, Iter: 80, Loss: 0.07320\n",
            "[TRAIN] Epoch: 25, Iter: 160, Loss: 0.09753\n",
            "[TRAIN] Epoch: 25, Iter: 240, Loss: 0.12630\n",
            "[TRAIN] Epoch: 25, Iter: 320, Loss: 0.07276\n",
            "== [TRAIN] Epoch: 25, Accuracy: 0.966 ==>\n",
            "[VAL] Epoch: 25, Iter: 0, Loss: 0.22464\n",
            "=== [VAL] Epoch: 25, Iter: 39, Accuracy: 0.973 ===>\n",
            "====== Epoch 26 ======>\n",
            "[TRAIN] Epoch: 26, Iter: 0, Loss: 0.08051\n",
            "[TRAIN] Epoch: 26, Iter: 80, Loss: 0.10419\n",
            "[TRAIN] Epoch: 26, Iter: 160, Loss: 0.12115\n",
            "[TRAIN] Epoch: 26, Iter: 240, Loss: 0.04630\n",
            "[TRAIN] Epoch: 26, Iter: 320, Loss: 0.08108\n",
            "== [TRAIN] Epoch: 26, Accuracy: 0.969 ==>\n",
            "[VAL] Epoch: 26, Iter: 0, Loss: 0.18051\n",
            "=== [VAL] Epoch: 26, Iter: 39, Accuracy: 0.968 ===>\n",
            "====== Epoch 27 ======>\n",
            "[TRAIN] Epoch: 27, Iter: 0, Loss: 0.14669\n",
            "[TRAIN] Epoch: 27, Iter: 80, Loss: 0.07962\n",
            "[TRAIN] Epoch: 27, Iter: 160, Loss: 0.07253\n",
            "[TRAIN] Epoch: 27, Iter: 240, Loss: 0.05237\n",
            "[TRAIN] Epoch: 27, Iter: 320, Loss: 0.01431\n",
            "== [TRAIN] Epoch: 27, Accuracy: 0.971 ==>\n",
            "[VAL] Epoch: 27, Iter: 0, Loss: 0.16711\n",
            "=== [VAL] Epoch: 27, Iter: 39, Accuracy: 0.968 ===>\n",
            "====== Epoch 28 ======>\n",
            "[TRAIN] Epoch: 28, Iter: 0, Loss: 0.02589\n",
            "[TRAIN] Epoch: 28, Iter: 80, Loss: 0.08307\n",
            "[TRAIN] Epoch: 28, Iter: 160, Loss: 0.07756\n",
            "[TRAIN] Epoch: 28, Iter: 240, Loss: 0.11467\n",
            "[TRAIN] Epoch: 28, Iter: 320, Loss: 0.05609\n",
            "== [TRAIN] Epoch: 28, Accuracy: 0.972 ==>\n",
            "[VAL] Epoch: 28, Iter: 0, Loss: 0.19250\n",
            "=== [VAL] Epoch: 28, Iter: 39, Accuracy: 0.971 ===>\n",
            "====== Epoch 29 ======>\n",
            "[TRAIN] Epoch: 29, Iter: 0, Loss: 0.13605\n",
            "[TRAIN] Epoch: 29, Iter: 80, Loss: 0.07488\n",
            "[TRAIN] Epoch: 29, Iter: 160, Loss: 0.08000\n",
            "[TRAIN] Epoch: 29, Iter: 240, Loss: 0.10325\n",
            "[TRAIN] Epoch: 29, Iter: 320, Loss: 0.07358\n",
            "== [TRAIN] Epoch: 29, Accuracy: 0.972 ==>\n",
            "[VAL] Epoch: 29, Iter: 0, Loss: 0.14807\n",
            "=== [VAL] Epoch: 29, Iter: 39, Accuracy: 0.983 ===>\n",
            "====== Epoch 30 ======>\n",
            "[TRAIN] Epoch: 30, Iter: 0, Loss: 0.05879\n",
            "[TRAIN] Epoch: 30, Iter: 80, Loss: 0.09669\n",
            "[TRAIN] Epoch: 30, Iter: 160, Loss: 0.01740\n",
            "[TRAIN] Epoch: 30, Iter: 240, Loss: 0.04799\n",
            "[TRAIN] Epoch: 30, Iter: 320, Loss: 0.11787\n",
            "== [TRAIN] Epoch: 30, Accuracy: 0.977 ==>\n",
            "[VAL] Epoch: 30, Iter: 0, Loss: 0.27694\n",
            "=== [VAL] Epoch: 30, Iter: 39, Accuracy: 0.953 ===>\n",
            "====== Epoch 31 ======>\n",
            "[TRAIN] Epoch: 31, Iter: 0, Loss: 0.11956\n",
            "[TRAIN] Epoch: 31, Iter: 80, Loss: 0.11818\n",
            "[TRAIN] Epoch: 31, Iter: 160, Loss: 0.06643\n",
            "[TRAIN] Epoch: 31, Iter: 240, Loss: 0.05869\n",
            "[TRAIN] Epoch: 31, Iter: 320, Loss: 0.18372\n",
            "== [TRAIN] Epoch: 31, Accuracy: 0.976 ==>\n",
            "[VAL] Epoch: 31, Iter: 0, Loss: 0.12729\n",
            "=== [VAL] Epoch: 31, Iter: 39, Accuracy: 0.982 ===>\n",
            "====== Epoch 32 ======>\n",
            "[TRAIN] Epoch: 32, Iter: 0, Loss: 0.03595\n",
            "[TRAIN] Epoch: 32, Iter: 80, Loss: 0.04368\n",
            "[TRAIN] Epoch: 32, Iter: 160, Loss: 0.07448\n",
            "[TRAIN] Epoch: 32, Iter: 240, Loss: 0.08471\n",
            "[TRAIN] Epoch: 32, Iter: 320, Loss: 0.05074\n",
            "== [TRAIN] Epoch: 32, Accuracy: 0.977 ==>\n",
            "[VAL] Epoch: 32, Iter: 0, Loss: 0.18931\n",
            "=== [VAL] Epoch: 32, Iter: 39, Accuracy: 0.971 ===>\n",
            "====== Epoch 33 ======>\n",
            "[TRAIN] Epoch: 33, Iter: 0, Loss: 0.09455\n",
            "[TRAIN] Epoch: 33, Iter: 80, Loss: 0.01814\n",
            "[TRAIN] Epoch: 33, Iter: 160, Loss: 0.05233\n",
            "[TRAIN] Epoch: 33, Iter: 240, Loss: 0.02350\n",
            "[TRAIN] Epoch: 33, Iter: 320, Loss: 0.02749\n",
            "== [TRAIN] Epoch: 33, Accuracy: 0.978 ==>\n",
            "[VAL] Epoch: 33, Iter: 0, Loss: 0.13547\n",
            "=== [VAL] Epoch: 33, Iter: 39, Accuracy: 0.981 ===>\n",
            "====== Epoch 34 ======>\n",
            "[TRAIN] Epoch: 34, Iter: 0, Loss: 0.07788\n",
            "[TRAIN] Epoch: 34, Iter: 80, Loss: 0.02093\n",
            "[TRAIN] Epoch: 34, Iter: 160, Loss: 0.02067\n",
            "[TRAIN] Epoch: 34, Iter: 240, Loss: 0.02780\n",
            "[TRAIN] Epoch: 34, Iter: 320, Loss: 0.09545\n",
            "== [TRAIN] Epoch: 34, Accuracy: 0.979 ==>\n",
            "[VAL] Epoch: 34, Iter: 0, Loss: 0.19425\n",
            "=== [VAL] Epoch: 34, Iter: 39, Accuracy: 0.969 ===>\n",
            "====== Epoch 35 ======>\n",
            "[TRAIN] Epoch: 35, Iter: 0, Loss: 0.06190\n",
            "[TRAIN] Epoch: 35, Iter: 80, Loss: 0.03994\n",
            "[TRAIN] Epoch: 35, Iter: 160, Loss: 0.08708\n",
            "[TRAIN] Epoch: 35, Iter: 240, Loss: 0.01842\n",
            "[TRAIN] Epoch: 35, Iter: 320, Loss: 0.09198\n",
            "== [TRAIN] Epoch: 35, Accuracy: 0.979 ==>\n",
            "[VAL] Epoch: 35, Iter: 0, Loss: 0.12646\n",
            "=== [VAL] Epoch: 35, Iter: 39, Accuracy: 0.979 ===>\n",
            "====== Epoch 36 ======>\n",
            "[TRAIN] Epoch: 36, Iter: 0, Loss: 0.06330\n",
            "[TRAIN] Epoch: 36, Iter: 80, Loss: 0.06217\n",
            "[TRAIN] Epoch: 36, Iter: 160, Loss: 0.01497\n",
            "[TRAIN] Epoch: 36, Iter: 240, Loss: 0.02355\n",
            "[TRAIN] Epoch: 36, Iter: 320, Loss: 0.09650\n",
            "== [TRAIN] Epoch: 36, Accuracy: 0.981 ==>\n",
            "[VAL] Epoch: 36, Iter: 0, Loss: 0.19898\n",
            "=== [VAL] Epoch: 36, Iter: 39, Accuracy: 0.978 ===>\n",
            "====== Epoch 37 ======>\n",
            "[TRAIN] Epoch: 37, Iter: 0, Loss: 0.00597\n",
            "[TRAIN] Epoch: 37, Iter: 80, Loss: 0.05662\n",
            "[TRAIN] Epoch: 37, Iter: 160, Loss: 0.03844\n",
            "[TRAIN] Epoch: 37, Iter: 240, Loss: 0.07243\n",
            "[TRAIN] Epoch: 37, Iter: 320, Loss: 0.04506\n",
            "== [TRAIN] Epoch: 37, Accuracy: 0.979 ==>\n",
            "[VAL] Epoch: 37, Iter: 0, Loss: 0.17025\n",
            "=== [VAL] Epoch: 37, Iter: 39, Accuracy: 0.979 ===>\n",
            "====== Epoch 38 ======>\n",
            "[TRAIN] Epoch: 38, Iter: 0, Loss: 0.06296\n",
            "[TRAIN] Epoch: 38, Iter: 80, Loss: 0.02040\n",
            "[TRAIN] Epoch: 38, Iter: 160, Loss: 0.11126\n",
            "[TRAIN] Epoch: 38, Iter: 240, Loss: 0.04635\n",
            "[TRAIN] Epoch: 38, Iter: 320, Loss: 0.01691\n",
            "== [TRAIN] Epoch: 38, Accuracy: 0.983 ==>\n",
            "[VAL] Epoch: 38, Iter: 0, Loss: 0.15346\n",
            "=== [VAL] Epoch: 38, Iter: 39, Accuracy: 0.978 ===>\n",
            "====== Epoch 39 ======>\n",
            "[TRAIN] Epoch: 39, Iter: 0, Loss: 0.07498\n",
            "[TRAIN] Epoch: 39, Iter: 80, Loss: 0.05260\n",
            "[TRAIN] Epoch: 39, Iter: 160, Loss: 0.02412\n",
            "[TRAIN] Epoch: 39, Iter: 240, Loss: 0.05606\n",
            "[TRAIN] Epoch: 39, Iter: 320, Loss: 0.01702\n",
            "== [TRAIN] Epoch: 39, Accuracy: 0.983 ==>\n",
            "[VAL] Epoch: 39, Iter: 0, Loss: 0.12041\n",
            "=== [VAL] Epoch: 39, Iter: 39, Accuracy: 0.983 ===>\n",
            "[TEST] Epoch: 39, Iter: 0, Loss: 0.26272\n",
            "=== [TEST] Epoch: 39, Iter: 78, Accuracy: 0.905 ===>\n",
            "===== Best validation Accuracy: 0.983 =====>\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Build model RESNET18...\n",
            "Loading model config from /content/IFT6135-2025-First-Assignment/HW1_2025/assignment1_release/model_configs/resnet18.json\n",
            "########## RESNET18 CONFIG ################\n",
            "num_classes:\t10\n",
            "############################################\n",
            "Initialized RESNET18 model with 11173962 total parameters, of which 11173962 are learnable.\n",
            "====== Epoch 0 ======>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN] Epoch: 0, Iter: 0, Loss: 2.35414\n",
            "[TRAIN] Epoch: 0, Iter: 80, Loss: 1.42008\n",
            "[TRAIN] Epoch: 0, Iter: 160, Loss: 1.48056\n",
            "[TRAIN] Epoch: 0, Iter: 240, Loss: 1.20674\n",
            "[TRAIN] Epoch: 0, Iter: 320, Loss: 1.08871\n",
            "== [TRAIN] Epoch: 0, Accuracy: 0.520 ==>\n",
            "[VAL] Epoch: 0, Iter: 0, Loss: 1.14254\n",
            "=== [VAL] Epoch: 0, Iter: 39, Accuracy: 0.623 ===>\n",
            "====== Epoch 1 ======>\n",
            "[TRAIN] Epoch: 1, Iter: 0, Loss: 0.94476\n",
            "[TRAIN] Epoch: 1, Iter: 80, Loss: 0.88517\n",
            "[TRAIN] Epoch: 1, Iter: 160, Loss: 0.93420\n",
            "[TRAIN] Epoch: 1, Iter: 240, Loss: 0.92325\n",
            "[TRAIN] Epoch: 1, Iter: 320, Loss: 0.70693\n",
            "== [TRAIN] Epoch: 1, Accuracy: 0.677 ==>\n",
            "[VAL] Epoch: 1, Iter: 0, Loss: 0.90248\n",
            "=== [VAL] Epoch: 1, Iter: 39, Accuracy: 0.706 ===>\n",
            "====== Epoch 2 ======>\n",
            "[TRAIN] Epoch: 2, Iter: 0, Loss: 0.92170\n",
            "[TRAIN] Epoch: 2, Iter: 80, Loss: 0.70922\n",
            "[TRAIN] Epoch: 2, Iter: 160, Loss: 0.77679\n",
            "[TRAIN] Epoch: 2, Iter: 240, Loss: 0.76666\n",
            "[TRAIN] Epoch: 2, Iter: 320, Loss: 0.68475\n",
            "== [TRAIN] Epoch: 2, Accuracy: 0.746 ==>\n",
            "[VAL] Epoch: 2, Iter: 0, Loss: 0.79032\n",
            "=== [VAL] Epoch: 2, Iter: 39, Accuracy: 0.741 ===>\n",
            "====== Epoch 3 ======>\n",
            "[TRAIN] Epoch: 3, Iter: 0, Loss: 0.66243\n",
            "[TRAIN] Epoch: 3, Iter: 80, Loss: 0.51634\n",
            "[TRAIN] Epoch: 3, Iter: 160, Loss: 0.65457\n",
            "[TRAIN] Epoch: 3, Iter: 240, Loss: 0.57400\n",
            "[TRAIN] Epoch: 3, Iter: 320, Loss: 0.63235\n",
            "== [TRAIN] Epoch: 3, Accuracy: 0.788 ==>\n",
            "[VAL] Epoch: 3, Iter: 0, Loss: 0.70416\n",
            "=== [VAL] Epoch: 3, Iter: 39, Accuracy: 0.786 ===>\n",
            "====== Epoch 4 ======>\n",
            "[TRAIN] Epoch: 4, Iter: 0, Loss: 0.47401\n",
            "[TRAIN] Epoch: 4, Iter: 80, Loss: 0.55964\n",
            "[TRAIN] Epoch: 4, Iter: 160, Loss: 0.59204\n",
            "[TRAIN] Epoch: 4, Iter: 240, Loss: 0.52495\n",
            "[TRAIN] Epoch: 4, Iter: 320, Loss: 0.53226\n",
            "== [TRAIN] Epoch: 4, Accuracy: 0.815 ==>\n",
            "[VAL] Epoch: 4, Iter: 0, Loss: 0.43023\n",
            "=== [VAL] Epoch: 4, Iter: 39, Accuracy: 0.842 ===>\n",
            "====== Epoch 5 ======>\n",
            "[TRAIN] Epoch: 5, Iter: 0, Loss: 0.43928\n",
            "[TRAIN] Epoch: 5, Iter: 80, Loss: 0.35992\n",
            "[TRAIN] Epoch: 5, Iter: 160, Loss: 0.46581\n",
            "[TRAIN] Epoch: 5, Iter: 240, Loss: 0.48588\n",
            "[TRAIN] Epoch: 5, Iter: 320, Loss: 0.33377\n",
            "== [TRAIN] Epoch: 5, Accuracy: 0.833 ==>\n",
            "[VAL] Epoch: 5, Iter: 0, Loss: 0.38052\n",
            "=== [VAL] Epoch: 5, Iter: 39, Accuracy: 0.847 ===>\n",
            "====== Epoch 6 ======>\n",
            "[TRAIN] Epoch: 6, Iter: 0, Loss: 0.52226\n",
            "[TRAIN] Epoch: 6, Iter: 80, Loss: 0.43732\n",
            "[TRAIN] Epoch: 6, Iter: 160, Loss: 0.41013\n",
            "[TRAIN] Epoch: 6, Iter: 240, Loss: 0.48332\n",
            "[TRAIN] Epoch: 6, Iter: 320, Loss: 0.26455\n",
            "== [TRAIN] Epoch: 6, Accuracy: 0.852 ==>\n",
            "[VAL] Epoch: 6, Iter: 0, Loss: 0.44170\n",
            "=== [VAL] Epoch: 6, Iter: 39, Accuracy: 0.847 ===>\n",
            "====== Epoch 7 ======>\n",
            "[TRAIN] Epoch: 7, Iter: 0, Loss: 0.30910\n",
            "[TRAIN] Epoch: 7, Iter: 80, Loss: 0.37467\n",
            "[TRAIN] Epoch: 7, Iter: 160, Loss: 0.32207\n",
            "[TRAIN] Epoch: 7, Iter: 240, Loss: 0.29588\n",
            "[TRAIN] Epoch: 7, Iter: 320, Loss: 0.37254\n",
            "== [TRAIN] Epoch: 7, Accuracy: 0.867 ==>\n",
            "[VAL] Epoch: 7, Iter: 0, Loss: 0.39718\n",
            "=== [VAL] Epoch: 7, Iter: 39, Accuracy: 0.863 ===>\n",
            "====== Epoch 8 ======>\n",
            "[TRAIN] Epoch: 8, Iter: 0, Loss: 0.47269\n",
            "[TRAIN] Epoch: 8, Iter: 80, Loss: 0.27821\n",
            "[TRAIN] Epoch: 8, Iter: 160, Loss: 0.31457\n",
            "[TRAIN] Epoch: 8, Iter: 240, Loss: 0.40916\n",
            "[TRAIN] Epoch: 8, Iter: 320, Loss: 0.39907\n",
            "== [TRAIN] Epoch: 8, Accuracy: 0.880 ==>\n",
            "[VAL] Epoch: 8, Iter: 0, Loss: 0.43833\n",
            "=== [VAL] Epoch: 8, Iter: 39, Accuracy: 0.850 ===>\n",
            "====== Epoch 9 ======>\n",
            "[TRAIN] Epoch: 9, Iter: 0, Loss: 0.23020\n",
            "[TRAIN] Epoch: 9, Iter: 80, Loss: 0.38232\n",
            "[TRAIN] Epoch: 9, Iter: 160, Loss: 0.44322\n",
            "[TRAIN] Epoch: 9, Iter: 240, Loss: 0.52293\n",
            "[TRAIN] Epoch: 9, Iter: 320, Loss: 0.41151\n",
            "== [TRAIN] Epoch: 9, Accuracy: 0.888 ==>\n",
            "[VAL] Epoch: 9, Iter: 0, Loss: 0.18606\n",
            "=== [VAL] Epoch: 9, Iter: 39, Accuracy: 0.884 ===>\n",
            "====== Epoch 10 ======>\n",
            "[TRAIN] Epoch: 10, Iter: 0, Loss: 0.26075\n",
            "[TRAIN] Epoch: 10, Iter: 80, Loss: 0.29790\n",
            "[TRAIN] Epoch: 10, Iter: 160, Loss: 0.37159\n",
            "[TRAIN] Epoch: 10, Iter: 240, Loss: 0.40151\n",
            "[TRAIN] Epoch: 10, Iter: 320, Loss: 0.31730\n",
            "== [TRAIN] Epoch: 10, Accuracy: 0.898 ==>\n",
            "[VAL] Epoch: 10, Iter: 0, Loss: 0.30487\n",
            "=== [VAL] Epoch: 10, Iter: 39, Accuracy: 0.885 ===>\n",
            "====== Epoch 11 ======>\n",
            "[TRAIN] Epoch: 11, Iter: 0, Loss: 0.17267\n",
            "[TRAIN] Epoch: 11, Iter: 80, Loss: 0.22528\n",
            "[TRAIN] Epoch: 11, Iter: 160, Loss: 0.30099\n",
            "[TRAIN] Epoch: 11, Iter: 240, Loss: 0.26037\n",
            "[TRAIN] Epoch: 11, Iter: 320, Loss: 0.36003\n",
            "== [TRAIN] Epoch: 11, Accuracy: 0.909 ==>\n",
            "[VAL] Epoch: 11, Iter: 0, Loss: 0.23966\n",
            "=== [VAL] Epoch: 11, Iter: 39, Accuracy: 0.891 ===>\n",
            "====== Epoch 12 ======>\n",
            "[TRAIN] Epoch: 12, Iter: 0, Loss: 0.22390\n",
            "[TRAIN] Epoch: 12, Iter: 80, Loss: 0.15120\n",
            "[TRAIN] Epoch: 12, Iter: 160, Loss: 0.24852\n",
            "[TRAIN] Epoch: 12, Iter: 240, Loss: 0.24280\n",
            "[TRAIN] Epoch: 12, Iter: 320, Loss: 0.24271\n",
            "== [TRAIN] Epoch: 12, Accuracy: 0.914 ==>\n",
            "[VAL] Epoch: 12, Iter: 0, Loss: 0.29693\n",
            "=== [VAL] Epoch: 12, Iter: 39, Accuracy: 0.915 ===>\n",
            "====== Epoch 13 ======>\n",
            "[TRAIN] Epoch: 13, Iter: 0, Loss: 0.23463\n",
            "[TRAIN] Epoch: 13, Iter: 80, Loss: 0.24111\n",
            "[TRAIN] Epoch: 13, Iter: 160, Loss: 0.25344\n",
            "[TRAIN] Epoch: 13, Iter: 240, Loss: 0.25593\n",
            "[TRAIN] Epoch: 13, Iter: 320, Loss: 0.20506\n",
            "== [TRAIN] Epoch: 13, Accuracy: 0.925 ==>\n",
            "[VAL] Epoch: 13, Iter: 0, Loss: 0.15227\n",
            "=== [VAL] Epoch: 13, Iter: 39, Accuracy: 0.937 ===>\n",
            "====== Epoch 14 ======>\n",
            "[TRAIN] Epoch: 14, Iter: 0, Loss: 0.17695\n",
            "[TRAIN] Epoch: 14, Iter: 80, Loss: 0.25728\n",
            "[TRAIN] Epoch: 14, Iter: 160, Loss: 0.34484\n",
            "[TRAIN] Epoch: 14, Iter: 240, Loss: 0.14657\n",
            "[TRAIN] Epoch: 14, Iter: 320, Loss: 0.20820\n",
            "== [TRAIN] Epoch: 14, Accuracy: 0.925 ==>\n",
            "[VAL] Epoch: 14, Iter: 0, Loss: 0.24419\n",
            "=== [VAL] Epoch: 14, Iter: 39, Accuracy: 0.936 ===>\n",
            "====== Epoch 15 ======>\n",
            "[TRAIN] Epoch: 15, Iter: 0, Loss: 0.10950\n",
            "[TRAIN] Epoch: 15, Iter: 80, Loss: 0.15996\n",
            "[TRAIN] Epoch: 15, Iter: 160, Loss: 0.11267\n",
            "[TRAIN] Epoch: 15, Iter: 240, Loss: 0.18169\n",
            "[TRAIN] Epoch: 15, Iter: 320, Loss: 0.15043\n",
            "== [TRAIN] Epoch: 15, Accuracy: 0.935 ==>\n",
            "[VAL] Epoch: 15, Iter: 0, Loss: 0.29278\n",
            "=== [VAL] Epoch: 15, Iter: 39, Accuracy: 0.928 ===>\n",
            "====== Epoch 16 ======>\n",
            "[TRAIN] Epoch: 16, Iter: 0, Loss: 0.16053\n",
            "[TRAIN] Epoch: 16, Iter: 80, Loss: 0.18118\n",
            "[TRAIN] Epoch: 16, Iter: 160, Loss: 0.11547\n",
            "[TRAIN] Epoch: 16, Iter: 240, Loss: 0.17591\n",
            "[TRAIN] Epoch: 16, Iter: 320, Loss: 0.11707\n",
            "== [TRAIN] Epoch: 16, Accuracy: 0.940 ==>\n",
            "[VAL] Epoch: 16, Iter: 0, Loss: 0.16477\n",
            "=== [VAL] Epoch: 16, Iter: 39, Accuracy: 0.941 ===>\n",
            "====== Epoch 17 ======>\n",
            "[TRAIN] Epoch: 17, Iter: 0, Loss: 0.18734\n",
            "[TRAIN] Epoch: 17, Iter: 80, Loss: 0.10624\n",
            "[TRAIN] Epoch: 17, Iter: 160, Loss: 0.14657\n",
            "[TRAIN] Epoch: 17, Iter: 240, Loss: 0.22912\n",
            "[TRAIN] Epoch: 17, Iter: 320, Loss: 0.16699\n",
            "== [TRAIN] Epoch: 17, Accuracy: 0.944 ==>\n",
            "[VAL] Epoch: 17, Iter: 0, Loss: 0.22131\n",
            "=== [VAL] Epoch: 17, Iter: 39, Accuracy: 0.942 ===>\n",
            "====== Epoch 18 ======>\n",
            "[TRAIN] Epoch: 18, Iter: 0, Loss: 0.18968\n",
            "[TRAIN] Epoch: 18, Iter: 80, Loss: 0.22002\n",
            "[TRAIN] Epoch: 18, Iter: 160, Loss: 0.14858\n",
            "[TRAIN] Epoch: 18, Iter: 240, Loss: 0.14734\n",
            "[TRAIN] Epoch: 18, Iter: 320, Loss: 0.15031\n",
            "== [TRAIN] Epoch: 18, Accuracy: 0.950 ==>\n",
            "[VAL] Epoch: 18, Iter: 0, Loss: 0.24013\n",
            "=== [VAL] Epoch: 18, Iter: 39, Accuracy: 0.949 ===>\n",
            "====== Epoch 19 ======>\n",
            "[TRAIN] Epoch: 19, Iter: 0, Loss: 0.10138\n",
            "[TRAIN] Epoch: 19, Iter: 80, Loss: 0.12194\n",
            "[TRAIN] Epoch: 19, Iter: 160, Loss: 0.04785\n",
            "[TRAIN] Epoch: 19, Iter: 240, Loss: 0.08885\n",
            "[TRAIN] Epoch: 19, Iter: 320, Loss: 0.13571\n",
            "== [TRAIN] Epoch: 19, Accuracy: 0.952 ==>\n",
            "[VAL] Epoch: 19, Iter: 0, Loss: 0.21401\n",
            "=== [VAL] Epoch: 19, Iter: 39, Accuracy: 0.941 ===>\n",
            "====== Epoch 20 ======>\n",
            "[TRAIN] Epoch: 20, Iter: 0, Loss: 0.10275\n",
            "[TRAIN] Epoch: 20, Iter: 80, Loss: 0.12531\n",
            "[TRAIN] Epoch: 20, Iter: 160, Loss: 0.17672\n",
            "[TRAIN] Epoch: 20, Iter: 240, Loss: 0.13275\n",
            "[TRAIN] Epoch: 20, Iter: 320, Loss: 0.06297\n",
            "== [TRAIN] Epoch: 20, Accuracy: 0.955 ==>\n",
            "[VAL] Epoch: 20, Iter: 0, Loss: 0.27000\n",
            "=== [VAL] Epoch: 20, Iter: 39, Accuracy: 0.928 ===>\n",
            "====== Epoch 21 ======>\n",
            "[TRAIN] Epoch: 21, Iter: 0, Loss: 0.11714\n",
            "[TRAIN] Epoch: 21, Iter: 80, Loss: 0.15119\n",
            "[TRAIN] Epoch: 21, Iter: 160, Loss: 0.13323\n",
            "[TRAIN] Epoch: 21, Iter: 240, Loss: 0.15376\n",
            "[TRAIN] Epoch: 21, Iter: 320, Loss: 0.11411\n",
            "== [TRAIN] Epoch: 21, Accuracy: 0.959 ==>\n",
            "[VAL] Epoch: 21, Iter: 0, Loss: 0.18829\n",
            "=== [VAL] Epoch: 21, Iter: 39, Accuracy: 0.959 ===>\n",
            "====== Epoch 22 ======>\n",
            "[TRAIN] Epoch: 22, Iter: 0, Loss: 0.13780\n",
            "[TRAIN] Epoch: 22, Iter: 80, Loss: 0.05877\n",
            "[TRAIN] Epoch: 22, Iter: 160, Loss: 0.15654\n",
            "[TRAIN] Epoch: 22, Iter: 240, Loss: 0.21815\n",
            "[TRAIN] Epoch: 22, Iter: 320, Loss: 0.23613\n",
            "== [TRAIN] Epoch: 22, Accuracy: 0.958 ==>\n",
            "[VAL] Epoch: 22, Iter: 0, Loss: 0.17615\n",
            "=== [VAL] Epoch: 22, Iter: 39, Accuracy: 0.957 ===>\n",
            "====== Epoch 23 ======>\n",
            "[TRAIN] Epoch: 23, Iter: 0, Loss: 0.10194\n",
            "[TRAIN] Epoch: 23, Iter: 80, Loss: 0.13913\n",
            "[TRAIN] Epoch: 23, Iter: 160, Loss: 0.10029\n",
            "[TRAIN] Epoch: 23, Iter: 240, Loss: 0.10051\n",
            "[TRAIN] Epoch: 23, Iter: 320, Loss: 0.14971\n",
            "== [TRAIN] Epoch: 23, Accuracy: 0.962 ==>\n",
            "[VAL] Epoch: 23, Iter: 0, Loss: 0.13618\n",
            "=== [VAL] Epoch: 23, Iter: 39, Accuracy: 0.961 ===>\n",
            "====== Epoch 24 ======>\n",
            "[TRAIN] Epoch: 24, Iter: 0, Loss: 0.02169\n",
            "[TRAIN] Epoch: 24, Iter: 80, Loss: 0.05660\n",
            "[TRAIN] Epoch: 24, Iter: 160, Loss: 0.09560\n",
            "[TRAIN] Epoch: 24, Iter: 240, Loss: 0.10259\n",
            "[TRAIN] Epoch: 24, Iter: 320, Loss: 0.13491\n",
            "== [TRAIN] Epoch: 24, Accuracy: 0.964 ==>\n",
            "[VAL] Epoch: 24, Iter: 0, Loss: 0.08355\n",
            "=== [VAL] Epoch: 24, Iter: 39, Accuracy: 0.967 ===>\n",
            "====== Epoch 25 ======>\n",
            "[TRAIN] Epoch: 25, Iter: 0, Loss: 0.04253\n",
            "[TRAIN] Epoch: 25, Iter: 80, Loss: 0.07673\n",
            "[TRAIN] Epoch: 25, Iter: 160, Loss: 0.10839\n",
            "[TRAIN] Epoch: 25, Iter: 240, Loss: 0.09363\n",
            "[TRAIN] Epoch: 25, Iter: 320, Loss: 0.16039\n",
            "== [TRAIN] Epoch: 25, Accuracy: 0.966 ==>\n",
            "[VAL] Epoch: 25, Iter: 0, Loss: 0.18517\n",
            "=== [VAL] Epoch: 25, Iter: 39, Accuracy: 0.962 ===>\n",
            "====== Epoch 26 ======>\n",
            "[TRAIN] Epoch: 26, Iter: 0, Loss: 0.06052\n",
            "[TRAIN] Epoch: 26, Iter: 80, Loss: 0.13427\n",
            "[TRAIN] Epoch: 26, Iter: 160, Loss: 0.08609\n",
            "[TRAIN] Epoch: 26, Iter: 240, Loss: 0.03385\n",
            "[TRAIN] Epoch: 26, Iter: 320, Loss: 0.02455\n",
            "== [TRAIN] Epoch: 26, Accuracy: 0.967 ==>\n",
            "[VAL] Epoch: 26, Iter: 0, Loss: 0.05030\n",
            "=== [VAL] Epoch: 26, Iter: 39, Accuracy: 0.963 ===>\n",
            "====== Epoch 27 ======>\n",
            "[TRAIN] Epoch: 27, Iter: 0, Loss: 0.06920\n",
            "[TRAIN] Epoch: 27, Iter: 80, Loss: 0.12608\n",
            "[TRAIN] Epoch: 27, Iter: 160, Loss: 0.06950\n",
            "[TRAIN] Epoch: 27, Iter: 240, Loss: 0.11283\n",
            "[TRAIN] Epoch: 27, Iter: 320, Loss: 0.06709\n",
            "== [TRAIN] Epoch: 27, Accuracy: 0.969 ==>\n",
            "[VAL] Epoch: 27, Iter: 0, Loss: 0.12339\n",
            "=== [VAL] Epoch: 27, Iter: 39, Accuracy: 0.966 ===>\n",
            "====== Epoch 28 ======>\n",
            "[TRAIN] Epoch: 28, Iter: 0, Loss: 0.01738\n",
            "[TRAIN] Epoch: 28, Iter: 80, Loss: 0.14387\n",
            "[TRAIN] Epoch: 28, Iter: 160, Loss: 0.06580\n",
            "[TRAIN] Epoch: 28, Iter: 240, Loss: 0.07300\n",
            "[TRAIN] Epoch: 28, Iter: 320, Loss: 0.14989\n",
            "== [TRAIN] Epoch: 28, Accuracy: 0.972 ==>\n",
            "[VAL] Epoch: 28, Iter: 0, Loss: 0.18523\n",
            "=== [VAL] Epoch: 28, Iter: 39, Accuracy: 0.967 ===>\n",
            "====== Epoch 29 ======>\n",
            "[TRAIN] Epoch: 29, Iter: 0, Loss: 0.06897\n",
            "[TRAIN] Epoch: 29, Iter: 80, Loss: 0.06032\n",
            "[TRAIN] Epoch: 29, Iter: 160, Loss: 0.09564\n",
            "[TRAIN] Epoch: 29, Iter: 240, Loss: 0.05401\n",
            "[TRAIN] Epoch: 29, Iter: 320, Loss: 0.05879\n",
            "== [TRAIN] Epoch: 29, Accuracy: 0.972 ==>\n",
            "[VAL] Epoch: 29, Iter: 0, Loss: 0.11225\n",
            "=== [VAL] Epoch: 29, Iter: 39, Accuracy: 0.972 ===>\n",
            "====== Epoch 30 ======>\n",
            "[TRAIN] Epoch: 30, Iter: 0, Loss: 0.04605\n",
            "[TRAIN] Epoch: 30, Iter: 80, Loss: 0.08929\n",
            "[TRAIN] Epoch: 30, Iter: 160, Loss: 0.02667\n",
            "[TRAIN] Epoch: 30, Iter: 240, Loss: 0.08643\n",
            "[TRAIN] Epoch: 30, Iter: 320, Loss: 0.09775\n",
            "== [TRAIN] Epoch: 30, Accuracy: 0.973 ==>\n",
            "[VAL] Epoch: 30, Iter: 0, Loss: 0.09163\n",
            "=== [VAL] Epoch: 30, Iter: 39, Accuracy: 0.965 ===>\n",
            "====== Epoch 31 ======>\n",
            "[TRAIN] Epoch: 31, Iter: 0, Loss: 0.05716\n",
            "[TRAIN] Epoch: 31, Iter: 80, Loss: 0.09315\n",
            "[TRAIN] Epoch: 31, Iter: 160, Loss: 0.03651\n",
            "[TRAIN] Epoch: 31, Iter: 240, Loss: 0.03518\n",
            "[TRAIN] Epoch: 31, Iter: 320, Loss: 0.12160\n",
            "== [TRAIN] Epoch: 31, Accuracy: 0.976 ==>\n",
            "[VAL] Epoch: 31, Iter: 0, Loss: 0.14960\n",
            "=== [VAL] Epoch: 31, Iter: 39, Accuracy: 0.964 ===>\n",
            "====== Epoch 32 ======>\n",
            "[TRAIN] Epoch: 32, Iter: 0, Loss: 0.04228\n",
            "[TRAIN] Epoch: 32, Iter: 80, Loss: 0.07137\n",
            "[TRAIN] Epoch: 32, Iter: 160, Loss: 0.02477\n",
            "[TRAIN] Epoch: 32, Iter: 240, Loss: 0.05013\n",
            "[TRAIN] Epoch: 32, Iter: 320, Loss: 0.08445\n",
            "== [TRAIN] Epoch: 32, Accuracy: 0.975 ==>\n",
            "[VAL] Epoch: 32, Iter: 0, Loss: 0.11098\n",
            "=== [VAL] Epoch: 32, Iter: 39, Accuracy: 0.975 ===>\n",
            "====== Epoch 33 ======>\n",
            "[TRAIN] Epoch: 33, Iter: 0, Loss: 0.05492\n",
            "[TRAIN] Epoch: 33, Iter: 80, Loss: 0.06193\n",
            "[TRAIN] Epoch: 33, Iter: 160, Loss: 0.06364\n",
            "[TRAIN] Epoch: 33, Iter: 240, Loss: 0.03930\n",
            "[TRAIN] Epoch: 33, Iter: 320, Loss: 0.07212\n",
            "== [TRAIN] Epoch: 33, Accuracy: 0.974 ==>\n",
            "[VAL] Epoch: 33, Iter: 0, Loss: 0.13478\n",
            "=== [VAL] Epoch: 33, Iter: 39, Accuracy: 0.977 ===>\n",
            "====== Epoch 34 ======>\n",
            "[TRAIN] Epoch: 34, Iter: 0, Loss: 0.05697\n",
            "[TRAIN] Epoch: 34, Iter: 80, Loss: 0.06349\n",
            "[TRAIN] Epoch: 34, Iter: 160, Loss: 0.08451\n",
            "[TRAIN] Epoch: 34, Iter: 240, Loss: 0.02087\n",
            "[TRAIN] Epoch: 34, Iter: 320, Loss: 0.07145\n",
            "== [TRAIN] Epoch: 34, Accuracy: 0.978 ==>\n",
            "[VAL] Epoch: 34, Iter: 0, Loss: 0.16501\n",
            "=== [VAL] Epoch: 34, Iter: 39, Accuracy: 0.964 ===>\n",
            "====== Epoch 35 ======>\n",
            "[TRAIN] Epoch: 35, Iter: 0, Loss: 0.01286\n",
            "[TRAIN] Epoch: 35, Iter: 80, Loss: 0.01665\n",
            "[TRAIN] Epoch: 35, Iter: 160, Loss: 0.10538\n",
            "[TRAIN] Epoch: 35, Iter: 240, Loss: 0.05539\n",
            "[TRAIN] Epoch: 35, Iter: 320, Loss: 0.04404\n",
            "== [TRAIN] Epoch: 35, Accuracy: 0.977 ==>\n",
            "[VAL] Epoch: 35, Iter: 0, Loss: 0.16512\n",
            "=== [VAL] Epoch: 35, Iter: 39, Accuracy: 0.973 ===>\n",
            "====== Epoch 36 ======>\n",
            "[TRAIN] Epoch: 36, Iter: 0, Loss: 0.03495\n",
            "[TRAIN] Epoch: 36, Iter: 80, Loss: 0.05476\n",
            "[TRAIN] Epoch: 36, Iter: 160, Loss: 0.02513\n",
            "[TRAIN] Epoch: 36, Iter: 240, Loss: 0.03604\n",
            "[TRAIN] Epoch: 36, Iter: 320, Loss: 0.11790\n",
            "== [TRAIN] Epoch: 36, Accuracy: 0.979 ==>\n",
            "[VAL] Epoch: 36, Iter: 0, Loss: 0.17324\n",
            "=== [VAL] Epoch: 36, Iter: 39, Accuracy: 0.974 ===>\n",
            "====== Epoch 37 ======>\n",
            "[TRAIN] Epoch: 37, Iter: 0, Loss: 0.01144\n",
            "[TRAIN] Epoch: 37, Iter: 80, Loss: 0.05595\n",
            "[TRAIN] Epoch: 37, Iter: 160, Loss: 0.03825\n",
            "[TRAIN] Epoch: 37, Iter: 240, Loss: 0.02826\n",
            "[TRAIN] Epoch: 37, Iter: 320, Loss: 0.07212\n",
            "== [TRAIN] Epoch: 37, Accuracy: 0.980 ==>\n",
            "[VAL] Epoch: 37, Iter: 0, Loss: 0.09106\n",
            "=== [VAL] Epoch: 37, Iter: 39, Accuracy: 0.977 ===>\n",
            "====== Epoch 38 ======>\n",
            "[TRAIN] Epoch: 38, Iter: 0, Loss: 0.05592\n",
            "[TRAIN] Epoch: 38, Iter: 80, Loss: 0.07228\n",
            "[TRAIN] Epoch: 38, Iter: 160, Loss: 0.07723\n",
            "[TRAIN] Epoch: 38, Iter: 240, Loss: 0.09028\n",
            "[TRAIN] Epoch: 38, Iter: 320, Loss: 0.03882\n",
            "== [TRAIN] Epoch: 38, Accuracy: 0.979 ==>\n",
            "[VAL] Epoch: 38, Iter: 0, Loss: 0.10661\n",
            "=== [VAL] Epoch: 38, Iter: 39, Accuracy: 0.981 ===>\n",
            "====== Epoch 39 ======>\n",
            "[TRAIN] Epoch: 39, Iter: 0, Loss: 0.09500\n",
            "[TRAIN] Epoch: 39, Iter: 80, Loss: 0.02427\n",
            "[TRAIN] Epoch: 39, Iter: 160, Loss: 0.02781\n",
            "[TRAIN] Epoch: 39, Iter: 240, Loss: 0.03822\n",
            "[TRAIN] Epoch: 39, Iter: 320, Loss: 0.09399\n",
            "== [TRAIN] Epoch: 39, Accuracy: 0.981 ==>\n",
            "[VAL] Epoch: 39, Iter: 0, Loss: 0.17481\n",
            "=== [VAL] Epoch: 39, Iter: 39, Accuracy: 0.972 ===>\n",
            "[TEST] Epoch: 39, Iter: 0, Loss: 0.22655\n",
            "=== [TEST] Epoch: 39, Iter: 78, Accuracy: 0.876 ===>\n",
            "===== Best validation Accuracy: 0.981 =====>\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Build model RESNET18...\n",
            "Loading model config from /content/IFT6135-2025-First-Assignment/HW1_2025/assignment1_release/model_configs/resnet18.json\n",
            "########## RESNET18 CONFIG ################\n",
            "num_classes:\t10\n",
            "############################################\n",
            "Initialized RESNET18 model with 11173962 total parameters, of which 11173962 are learnable.\n",
            "====== Epoch 0 ======>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN] Epoch: 0, Iter: 0, Loss: 2.35414\n",
            "[TRAIN] Epoch: 0, Iter: 80, Loss: 1.72682\n",
            "[TRAIN] Epoch: 0, Iter: 160, Loss: 1.80058\n",
            "[TRAIN] Epoch: 0, Iter: 240, Loss: 1.56264\n",
            "[TRAIN] Epoch: 0, Iter: 320, Loss: 1.45335\n",
            "== [TRAIN] Epoch: 0, Accuracy: 0.381 ==>\n",
            "[VAL] Epoch: 0, Iter: 0, Loss: 1.52121\n",
            "=== [VAL] Epoch: 0, Iter: 39, Accuracy: 0.474 ===>\n",
            "====== Epoch 1 ======>\n",
            "[TRAIN] Epoch: 1, Iter: 0, Loss: 1.45164\n",
            "[TRAIN] Epoch: 1, Iter: 80, Loss: 1.37177\n",
            "[TRAIN] Epoch: 1, Iter: 160, Loss: 1.29110\n",
            "[TRAIN] Epoch: 1, Iter: 240, Loss: 1.32212\n",
            "[TRAIN] Epoch: 1, Iter: 320, Loss: 1.21282\n",
            "== [TRAIN] Epoch: 1, Accuracy: 0.510 ==>\n",
            "[VAL] Epoch: 1, Iter: 0, Loss: 1.36388\n",
            "=== [VAL] Epoch: 1, Iter: 39, Accuracy: 0.545 ===>\n",
            "====== Epoch 2 ======>\n",
            "[TRAIN] Epoch: 2, Iter: 0, Loss: 1.48306\n",
            "[TRAIN] Epoch: 2, Iter: 80, Loss: 1.28928\n",
            "[TRAIN] Epoch: 2, Iter: 160, Loss: 1.38964\n",
            "[TRAIN] Epoch: 2, Iter: 240, Loss: 1.25649\n",
            "[TRAIN] Epoch: 2, Iter: 320, Loss: 1.14172\n",
            "== [TRAIN] Epoch: 2, Accuracy: 0.558 ==>\n",
            "[VAL] Epoch: 2, Iter: 0, Loss: 1.23342\n",
            "=== [VAL] Epoch: 2, Iter: 39, Accuracy: 0.584 ===>\n",
            "====== Epoch 3 ======>\n",
            "[TRAIN] Epoch: 3, Iter: 0, Loss: 1.26961\n",
            "[TRAIN] Epoch: 3, Iter: 80, Loss: 1.03765\n",
            "[TRAIN] Epoch: 3, Iter: 160, Loss: 1.12659\n",
            "[TRAIN] Epoch: 3, Iter: 240, Loss: 1.07518\n",
            "[TRAIN] Epoch: 3, Iter: 320, Loss: 1.15377\n",
            "== [TRAIN] Epoch: 3, Accuracy: 0.598 ==>\n",
            "[VAL] Epoch: 3, Iter: 0, Loss: 1.16192\n",
            "=== [VAL] Epoch: 3, Iter: 39, Accuracy: 0.629 ===>\n",
            "====== Epoch 4 ======>\n",
            "[TRAIN] Epoch: 4, Iter: 0, Loss: 1.23695\n",
            "[TRAIN] Epoch: 4, Iter: 80, Loss: 1.11391\n",
            "[TRAIN] Epoch: 4, Iter: 160, Loss: 1.22911\n",
            "[TRAIN] Epoch: 4, Iter: 240, Loss: 1.10063\n",
            "[TRAIN] Epoch: 4, Iter: 320, Loss: 1.07682\n",
            "== [TRAIN] Epoch: 4, Accuracy: 0.627 ==>\n",
            "[VAL] Epoch: 4, Iter: 0, Loss: 1.08280\n",
            "=== [VAL] Epoch: 4, Iter: 39, Accuracy: 0.644 ===>\n",
            "====== Epoch 5 ======>\n",
            "[TRAIN] Epoch: 5, Iter: 0, Loss: 1.03971\n",
            "[TRAIN] Epoch: 5, Iter: 80, Loss: 0.87952\n",
            "[TRAIN] Epoch: 5, Iter: 160, Loss: 0.90133\n",
            "[TRAIN] Epoch: 5, Iter: 240, Loss: 1.15475\n",
            "[TRAIN] Epoch: 5, Iter: 320, Loss: 0.84300\n",
            "== [TRAIN] Epoch: 5, Accuracy: 0.649 ==>\n",
            "[VAL] Epoch: 5, Iter: 0, Loss: 0.96033\n",
            "=== [VAL] Epoch: 5, Iter: 39, Accuracy: 0.675 ===>\n",
            "====== Epoch 6 ======>\n",
            "[TRAIN] Epoch: 6, Iter: 0, Loss: 0.95396\n",
            "[TRAIN] Epoch: 6, Iter: 80, Loss: 0.98636\n",
            "[TRAIN] Epoch: 6, Iter: 160, Loss: 0.90323\n",
            "[TRAIN] Epoch: 6, Iter: 240, Loss: 1.00932\n",
            "[TRAIN] Epoch: 6, Iter: 320, Loss: 0.80858\n",
            "== [TRAIN] Epoch: 6, Accuracy: 0.669 ==>\n",
            "[VAL] Epoch: 6, Iter: 0, Loss: 0.96853\n",
            "=== [VAL] Epoch: 6, Iter: 39, Accuracy: 0.690 ===>\n",
            "====== Epoch 7 ======>\n",
            "[TRAIN] Epoch: 7, Iter: 0, Loss: 0.97774\n",
            "[TRAIN] Epoch: 7, Iter: 80, Loss: 0.97742\n",
            "[TRAIN] Epoch: 7, Iter: 160, Loss: 0.92821\n",
            "[TRAIN] Epoch: 7, Iter: 240, Loss: 0.85289\n",
            "[TRAIN] Epoch: 7, Iter: 320, Loss: 0.82669\n",
            "== [TRAIN] Epoch: 7, Accuracy: 0.686 ==>\n",
            "[VAL] Epoch: 7, Iter: 0, Loss: 0.93380\n",
            "=== [VAL] Epoch: 7, Iter: 39, Accuracy: 0.679 ===>\n",
            "====== Epoch 8 ======>\n",
            "[TRAIN] Epoch: 8, Iter: 0, Loss: 0.92162\n",
            "[TRAIN] Epoch: 8, Iter: 80, Loss: 0.94375\n",
            "[TRAIN] Epoch: 8, Iter: 160, Loss: 0.90038\n",
            "[TRAIN] Epoch: 8, Iter: 240, Loss: 0.92604\n",
            "[TRAIN] Epoch: 8, Iter: 320, Loss: 0.93358\n",
            "== [TRAIN] Epoch: 8, Accuracy: 0.702 ==>\n",
            "[VAL] Epoch: 8, Iter: 0, Loss: 0.89980\n",
            "=== [VAL] Epoch: 8, Iter: 39, Accuracy: 0.704 ===>\n",
            "====== Epoch 9 ======>\n",
            "[TRAIN] Epoch: 9, Iter: 0, Loss: 0.79318\n",
            "[TRAIN] Epoch: 9, Iter: 80, Loss: 0.88223\n",
            "[TRAIN] Epoch: 9, Iter: 160, Loss: 0.83263\n",
            "[TRAIN] Epoch: 9, Iter: 240, Loss: 0.78664\n",
            "[TRAIN] Epoch: 9, Iter: 320, Loss: 0.83808\n",
            "== [TRAIN] Epoch: 9, Accuracy: 0.718 ==>\n",
            "[VAL] Epoch: 9, Iter: 0, Loss: 0.81207\n",
            "=== [VAL] Epoch: 9, Iter: 39, Accuracy: 0.738 ===>\n",
            "====== Epoch 10 ======>\n",
            "[TRAIN] Epoch: 10, Iter: 0, Loss: 0.83915\n",
            "[TRAIN] Epoch: 10, Iter: 80, Loss: 0.77151\n",
            "[TRAIN] Epoch: 10, Iter: 160, Loss: 0.82807\n",
            "[TRAIN] Epoch: 10, Iter: 240, Loss: 0.84385\n",
            "[TRAIN] Epoch: 10, Iter: 320, Loss: 0.68274\n",
            "== [TRAIN] Epoch: 10, Accuracy: 0.732 ==>\n",
            "[VAL] Epoch: 10, Iter: 0, Loss: 0.76942\n",
            "=== [VAL] Epoch: 10, Iter: 39, Accuracy: 0.737 ===>\n",
            "====== Epoch 11 ======>\n",
            "[TRAIN] Epoch: 11, Iter: 0, Loss: 0.75159\n",
            "[TRAIN] Epoch: 11, Iter: 80, Loss: 0.75217\n",
            "[TRAIN] Epoch: 11, Iter: 160, Loss: 0.72727\n",
            "[TRAIN] Epoch: 11, Iter: 240, Loss: 0.70006\n",
            "[TRAIN] Epoch: 11, Iter: 320, Loss: 0.82045\n",
            "== [TRAIN] Epoch: 11, Accuracy: 0.743 ==>\n",
            "[VAL] Epoch: 11, Iter: 0, Loss: 0.79008\n",
            "=== [VAL] Epoch: 11, Iter: 39, Accuracy: 0.757 ===>\n",
            "====== Epoch 12 ======>\n",
            "[TRAIN] Epoch: 12, Iter: 0, Loss: 0.64321\n",
            "[TRAIN] Epoch: 12, Iter: 80, Loss: 0.70876\n",
            "[TRAIN] Epoch: 12, Iter: 160, Loss: 0.74153\n",
            "[TRAIN] Epoch: 12, Iter: 240, Loss: 0.72033\n",
            "[TRAIN] Epoch: 12, Iter: 320, Loss: 0.73705\n",
            "== [TRAIN] Epoch: 12, Accuracy: 0.754 ==>\n",
            "[VAL] Epoch: 12, Iter: 0, Loss: 0.78783\n",
            "=== [VAL] Epoch: 12, Iter: 39, Accuracy: 0.764 ===>\n",
            "====== Epoch 13 ======>\n",
            "[TRAIN] Epoch: 13, Iter: 0, Loss: 0.74804\n",
            "[TRAIN] Epoch: 13, Iter: 80, Loss: 0.68157\n",
            "[TRAIN] Epoch: 13, Iter: 160, Loss: 0.60592\n",
            "[TRAIN] Epoch: 13, Iter: 240, Loss: 0.64845\n",
            "[TRAIN] Epoch: 13, Iter: 320, Loss: 0.82780\n",
            "== [TRAIN] Epoch: 13, Accuracy: 0.762 ==>\n",
            "[VAL] Epoch: 13, Iter: 0, Loss: 0.67288\n",
            "=== [VAL] Epoch: 13, Iter: 39, Accuracy: 0.768 ===>\n",
            "====== Epoch 14 ======>\n",
            "[TRAIN] Epoch: 14, Iter: 0, Loss: 0.65388\n",
            "[TRAIN] Epoch: 14, Iter: 80, Loss: 0.85587\n",
            "[TRAIN] Epoch: 14, Iter: 160, Loss: 0.67663\n",
            "[TRAIN] Epoch: 14, Iter: 240, Loss: 0.71496\n",
            "[TRAIN] Epoch: 14, Iter: 320, Loss: 0.63966\n",
            "== [TRAIN] Epoch: 14, Accuracy: 0.773 ==>\n",
            "[VAL] Epoch: 14, Iter: 0, Loss: 0.66852\n",
            "=== [VAL] Epoch: 14, Iter: 39, Accuracy: 0.789 ===>\n",
            "====== Epoch 15 ======>\n",
            "[TRAIN] Epoch: 15, Iter: 0, Loss: 0.47765\n",
            "[TRAIN] Epoch: 15, Iter: 80, Loss: 0.68745\n",
            "[TRAIN] Epoch: 15, Iter: 160, Loss: 0.65410\n",
            "[TRAIN] Epoch: 15, Iter: 240, Loss: 0.60165\n",
            "[TRAIN] Epoch: 15, Iter: 320, Loss: 0.52824\n",
            "== [TRAIN] Epoch: 15, Accuracy: 0.784 ==>\n",
            "[VAL] Epoch: 15, Iter: 0, Loss: 0.64874\n",
            "=== [VAL] Epoch: 15, Iter: 39, Accuracy: 0.795 ===>\n",
            "====== Epoch 16 ======>\n",
            "[TRAIN] Epoch: 16, Iter: 0, Loss: 0.62260\n",
            "[TRAIN] Epoch: 16, Iter: 80, Loss: 0.49448\n",
            "[TRAIN] Epoch: 16, Iter: 160, Loss: 0.60204\n",
            "[TRAIN] Epoch: 16, Iter: 240, Loss: 0.61205\n",
            "[TRAIN] Epoch: 16, Iter: 320, Loss: 0.61609\n",
            "== [TRAIN] Epoch: 16, Accuracy: 0.793 ==>\n",
            "[VAL] Epoch: 16, Iter: 0, Loss: 0.67477\n",
            "=== [VAL] Epoch: 16, Iter: 39, Accuracy: 0.809 ===>\n",
            "====== Epoch 17 ======>\n",
            "[TRAIN] Epoch: 17, Iter: 0, Loss: 0.52752\n",
            "[TRAIN] Epoch: 17, Iter: 80, Loss: 0.57444\n",
            "[TRAIN] Epoch: 17, Iter: 160, Loss: 0.51473\n",
            "[TRAIN] Epoch: 17, Iter: 240, Loss: 0.76516\n",
            "[TRAIN] Epoch: 17, Iter: 320, Loss: 0.68800\n",
            "== [TRAIN] Epoch: 17, Accuracy: 0.801 ==>\n",
            "[VAL] Epoch: 17, Iter: 0, Loss: 0.60267\n",
            "=== [VAL] Epoch: 17, Iter: 39, Accuracy: 0.815 ===>\n",
            "====== Epoch 18 ======>\n",
            "[TRAIN] Epoch: 18, Iter: 0, Loss: 0.51553\n",
            "[TRAIN] Epoch: 18, Iter: 80, Loss: 0.64278\n",
            "[TRAIN] Epoch: 18, Iter: 160, Loss: 0.53931\n",
            "[TRAIN] Epoch: 18, Iter: 240, Loss: 0.48675\n",
            "[TRAIN] Epoch: 18, Iter: 320, Loss: 0.61283\n",
            "== [TRAIN] Epoch: 18, Accuracy: 0.808 ==>\n",
            "[VAL] Epoch: 18, Iter: 0, Loss: 0.54650\n",
            "=== [VAL] Epoch: 18, Iter: 39, Accuracy: 0.824 ===>\n",
            "====== Epoch 19 ======>\n",
            "[TRAIN] Epoch: 19, Iter: 0, Loss: 0.39156\n",
            "[TRAIN] Epoch: 19, Iter: 80, Loss: 0.54057\n",
            "[TRAIN] Epoch: 19, Iter: 160, Loss: 0.45817\n",
            "[TRAIN] Epoch: 19, Iter: 240, Loss: 0.47705\n",
            "[TRAIN] Epoch: 19, Iter: 320, Loss: 0.51568\n",
            "== [TRAIN] Epoch: 19, Accuracy: 0.819 ==>\n",
            "[VAL] Epoch: 19, Iter: 0, Loss: 0.51169\n",
            "=== [VAL] Epoch: 19, Iter: 39, Accuracy: 0.843 ===>\n",
            "====== Epoch 20 ======>\n",
            "[TRAIN] Epoch: 20, Iter: 0, Loss: 0.57826\n",
            "[TRAIN] Epoch: 20, Iter: 80, Loss: 0.50459\n",
            "[TRAIN] Epoch: 20, Iter: 160, Loss: 0.43931\n",
            "[TRAIN] Epoch: 20, Iter: 240, Loss: 0.44001\n",
            "[TRAIN] Epoch: 20, Iter: 320, Loss: 0.38316\n",
            "== [TRAIN] Epoch: 20, Accuracy: 0.825 ==>\n",
            "[VAL] Epoch: 20, Iter: 0, Loss: 0.44820\n",
            "=== [VAL] Epoch: 20, Iter: 39, Accuracy: 0.838 ===>\n",
            "====== Epoch 21 ======>\n",
            "[TRAIN] Epoch: 21, Iter: 0, Loss: 0.41732\n",
            "[TRAIN] Epoch: 21, Iter: 80, Loss: 0.59774\n",
            "[TRAIN] Epoch: 21, Iter: 160, Loss: 0.48303\n",
            "[TRAIN] Epoch: 21, Iter: 240, Loss: 0.49920\n",
            "[TRAIN] Epoch: 21, Iter: 320, Loss: 0.40077\n",
            "== [TRAIN] Epoch: 21, Accuracy: 0.833 ==>\n",
            "[VAL] Epoch: 21, Iter: 0, Loss: 0.51166\n",
            "=== [VAL] Epoch: 21, Iter: 39, Accuracy: 0.853 ===>\n",
            "====== Epoch 22 ======>\n",
            "[TRAIN] Epoch: 22, Iter: 0, Loss: 0.49675\n",
            "[TRAIN] Epoch: 22, Iter: 80, Loss: 0.49780\n",
            "[TRAIN] Epoch: 22, Iter: 160, Loss: 0.55328\n",
            "[TRAIN] Epoch: 22, Iter: 240, Loss: 0.50000\n",
            "[TRAIN] Epoch: 22, Iter: 320, Loss: 0.64171\n",
            "== [TRAIN] Epoch: 22, Accuracy: 0.839 ==>\n",
            "[VAL] Epoch: 22, Iter: 0, Loss: 0.49913\n",
            "=== [VAL] Epoch: 22, Iter: 39, Accuracy: 0.859 ===>\n",
            "====== Epoch 23 ======>\n",
            "[TRAIN] Epoch: 23, Iter: 0, Loss: 0.43349\n",
            "[TRAIN] Epoch: 23, Iter: 80, Loss: 0.57359\n",
            "[TRAIN] Epoch: 23, Iter: 160, Loss: 0.46658\n",
            "[TRAIN] Epoch: 23, Iter: 240, Loss: 0.40010\n",
            "[TRAIN] Epoch: 23, Iter: 320, Loss: 0.65348\n",
            "== [TRAIN] Epoch: 23, Accuracy: 0.845 ==>\n",
            "[VAL] Epoch: 23, Iter: 0, Loss: 0.43000\n",
            "=== [VAL] Epoch: 23, Iter: 39, Accuracy: 0.874 ===>\n",
            "====== Epoch 24 ======>\n",
            "[TRAIN] Epoch: 24, Iter: 0, Loss: 0.39317\n",
            "[TRAIN] Epoch: 24, Iter: 80, Loss: 0.36268\n",
            "[TRAIN] Epoch: 24, Iter: 160, Loss: 0.49743\n",
            "[TRAIN] Epoch: 24, Iter: 240, Loss: 0.38367\n",
            "[TRAIN] Epoch: 24, Iter: 320, Loss: 0.42774\n",
            "== [TRAIN] Epoch: 24, Accuracy: 0.853 ==>\n",
            "[VAL] Epoch: 24, Iter: 0, Loss: 0.44630\n",
            "=== [VAL] Epoch: 24, Iter: 39, Accuracy: 0.871 ===>\n",
            "====== Epoch 25 ======>\n",
            "[TRAIN] Epoch: 25, Iter: 0, Loss: 0.33894\n",
            "[TRAIN] Epoch: 25, Iter: 80, Loss: 0.38532\n",
            "[TRAIN] Epoch: 25, Iter: 160, Loss: 0.36949\n",
            "[TRAIN] Epoch: 25, Iter: 240, Loss: 0.33561\n",
            "[TRAIN] Epoch: 25, Iter: 320, Loss: 0.46778\n",
            "== [TRAIN] Epoch: 25, Accuracy: 0.860 ==>\n",
            "[VAL] Epoch: 25, Iter: 0, Loss: 0.39265\n",
            "=== [VAL] Epoch: 25, Iter: 39, Accuracy: 0.873 ===>\n",
            "====== Epoch 26 ======>\n",
            "[TRAIN] Epoch: 26, Iter: 0, Loss: 0.29454\n",
            "[TRAIN] Epoch: 26, Iter: 80, Loss: 0.41541\n",
            "[TRAIN] Epoch: 26, Iter: 160, Loss: 0.33394\n",
            "[TRAIN] Epoch: 26, Iter: 240, Loss: 0.31975\n",
            "[TRAIN] Epoch: 26, Iter: 320, Loss: 0.29929\n",
            "== [TRAIN] Epoch: 26, Accuracy: 0.864 ==>\n",
            "[VAL] Epoch: 26, Iter: 0, Loss: 0.37964\n",
            "=== [VAL] Epoch: 26, Iter: 39, Accuracy: 0.894 ===>\n",
            "====== Epoch 27 ======>\n",
            "[TRAIN] Epoch: 27, Iter: 0, Loss: 0.35300\n",
            "[TRAIN] Epoch: 27, Iter: 80, Loss: 0.36113\n",
            "[TRAIN] Epoch: 27, Iter: 160, Loss: 0.34936\n",
            "[TRAIN] Epoch: 27, Iter: 240, Loss: 0.41666\n",
            "[TRAIN] Epoch: 27, Iter: 320, Loss: 0.33130\n",
            "== [TRAIN] Epoch: 27, Accuracy: 0.871 ==>\n",
            "[VAL] Epoch: 27, Iter: 0, Loss: 0.35858\n",
            "=== [VAL] Epoch: 27, Iter: 39, Accuracy: 0.902 ===>\n",
            "====== Epoch 28 ======>\n",
            "[TRAIN] Epoch: 28, Iter: 0, Loss: 0.21887\n",
            "[TRAIN] Epoch: 28, Iter: 80, Loss: 0.48609\n",
            "[TRAIN] Epoch: 28, Iter: 160, Loss: 0.32033\n",
            "[TRAIN] Epoch: 28, Iter: 240, Loss: 0.41557\n",
            "[TRAIN] Epoch: 28, Iter: 320, Loss: 0.47074\n",
            "== [TRAIN] Epoch: 28, Accuracy: 0.875 ==>\n",
            "[VAL] Epoch: 28, Iter: 0, Loss: 0.35776\n",
            "=== [VAL] Epoch: 28, Iter: 39, Accuracy: 0.890 ===>\n",
            "====== Epoch 29 ======>\n",
            "[TRAIN] Epoch: 29, Iter: 0, Loss: 0.33357\n",
            "[TRAIN] Epoch: 29, Iter: 80, Loss: 0.38586\n",
            "[TRAIN] Epoch: 29, Iter: 160, Loss: 0.42587\n",
            "[TRAIN] Epoch: 29, Iter: 240, Loss: 0.44578\n",
            "[TRAIN] Epoch: 29, Iter: 320, Loss: 0.38196\n",
            "== [TRAIN] Epoch: 29, Accuracy: 0.882 ==>\n",
            "[VAL] Epoch: 29, Iter: 0, Loss: 0.39803\n",
            "=== [VAL] Epoch: 29, Iter: 39, Accuracy: 0.900 ===>\n",
            "====== Epoch 30 ======>\n",
            "[TRAIN] Epoch: 30, Iter: 0, Loss: 0.24554\n",
            "[TRAIN] Epoch: 30, Iter: 80, Loss: 0.36240\n",
            "[TRAIN] Epoch: 30, Iter: 160, Loss: 0.27014\n",
            "[TRAIN] Epoch: 30, Iter: 240, Loss: 0.30942\n",
            "[TRAIN] Epoch: 30, Iter: 320, Loss: 0.39159\n",
            "== [TRAIN] Epoch: 30, Accuracy: 0.887 ==>\n",
            "[VAL] Epoch: 30, Iter: 0, Loss: 0.35553\n",
            "=== [VAL] Epoch: 30, Iter: 39, Accuracy: 0.905 ===>\n",
            "====== Epoch 31 ======>\n",
            "[TRAIN] Epoch: 31, Iter: 0, Loss: 0.45520\n",
            "[TRAIN] Epoch: 31, Iter: 80, Loss: 0.29165\n",
            "[TRAIN] Epoch: 31, Iter: 160, Loss: 0.30085\n",
            "[TRAIN] Epoch: 31, Iter: 240, Loss: 0.28385\n",
            "[TRAIN] Epoch: 31, Iter: 320, Loss: 0.37978\n",
            "== [TRAIN] Epoch: 31, Accuracy: 0.891 ==>\n",
            "[VAL] Epoch: 31, Iter: 0, Loss: 0.30420\n",
            "=== [VAL] Epoch: 31, Iter: 39, Accuracy: 0.918 ===>\n",
            "====== Epoch 32 ======>\n",
            "[TRAIN] Epoch: 32, Iter: 0, Loss: 0.28346\n",
            "[TRAIN] Epoch: 32, Iter: 80, Loss: 0.29051\n",
            "[TRAIN] Epoch: 32, Iter: 160, Loss: 0.32182\n",
            "[TRAIN] Epoch: 32, Iter: 240, Loss: 0.41974\n",
            "[TRAIN] Epoch: 32, Iter: 320, Loss: 0.29261\n",
            "== [TRAIN] Epoch: 32, Accuracy: 0.893 ==>\n",
            "[VAL] Epoch: 32, Iter: 0, Loss: 0.31370\n",
            "=== [VAL] Epoch: 32, Iter: 39, Accuracy: 0.921 ===>\n",
            "====== Epoch 33 ======>\n",
            "[TRAIN] Epoch: 33, Iter: 0, Loss: 0.26027\n",
            "[TRAIN] Epoch: 33, Iter: 80, Loss: 0.21669\n",
            "[TRAIN] Epoch: 33, Iter: 160, Loss: 0.26947\n",
            "[TRAIN] Epoch: 33, Iter: 240, Loss: 0.32726\n",
            "[TRAIN] Epoch: 33, Iter: 320, Loss: 0.28637\n",
            "== [TRAIN] Epoch: 33, Accuracy: 0.899 ==>\n",
            "[VAL] Epoch: 33, Iter: 0, Loss: 0.27911\n",
            "=== [VAL] Epoch: 33, Iter: 39, Accuracy: 0.929 ===>\n",
            "====== Epoch 34 ======>\n",
            "[TRAIN] Epoch: 34, Iter: 0, Loss: 0.26807\n",
            "[TRAIN] Epoch: 34, Iter: 80, Loss: 0.27264\n",
            "[TRAIN] Epoch: 34, Iter: 160, Loss: 0.19515\n",
            "[TRAIN] Epoch: 34, Iter: 240, Loss: 0.33495\n",
            "[TRAIN] Epoch: 34, Iter: 320, Loss: 0.28940\n",
            "== [TRAIN] Epoch: 34, Accuracy: 0.905 ==>\n",
            "[VAL] Epoch: 34, Iter: 0, Loss: 0.30832\n",
            "=== [VAL] Epoch: 34, Iter: 39, Accuracy: 0.916 ===>\n",
            "====== Epoch 35 ======>\n",
            "[TRAIN] Epoch: 35, Iter: 0, Loss: 0.19222\n",
            "[TRAIN] Epoch: 35, Iter: 80, Loss: 0.31722\n",
            "[TRAIN] Epoch: 35, Iter: 160, Loss: 0.42004\n",
            "[TRAIN] Epoch: 35, Iter: 240, Loss: 0.29296\n",
            "[TRAIN] Epoch: 35, Iter: 320, Loss: 0.19933\n",
            "== [TRAIN] Epoch: 35, Accuracy: 0.908 ==>\n",
            "[VAL] Epoch: 35, Iter: 0, Loss: 0.27140\n",
            "=== [VAL] Epoch: 35, Iter: 39, Accuracy: 0.930 ===>\n",
            "====== Epoch 36 ======>\n",
            "[TRAIN] Epoch: 36, Iter: 0, Loss: 0.21070\n",
            "[TRAIN] Epoch: 36, Iter: 80, Loss: 0.29043\n",
            "[TRAIN] Epoch: 36, Iter: 160, Loss: 0.31534\n",
            "[TRAIN] Epoch: 36, Iter: 240, Loss: 0.26284\n",
            "[TRAIN] Epoch: 36, Iter: 320, Loss: 0.28794\n",
            "== [TRAIN] Epoch: 36, Accuracy: 0.916 ==>\n",
            "[VAL] Epoch: 36, Iter: 0, Loss: 0.27675\n",
            "=== [VAL] Epoch: 36, Iter: 39, Accuracy: 0.939 ===>\n",
            "====== Epoch 37 ======>\n",
            "[TRAIN] Epoch: 37, Iter: 0, Loss: 0.19024\n",
            "[TRAIN] Epoch: 37, Iter: 80, Loss: 0.31909\n",
            "[TRAIN] Epoch: 37, Iter: 160, Loss: 0.27121\n",
            "[TRAIN] Epoch: 37, Iter: 240, Loss: 0.20144\n",
            "[TRAIN] Epoch: 37, Iter: 320, Loss: 0.20622\n",
            "== [TRAIN] Epoch: 37, Accuracy: 0.915 ==>\n",
            "[VAL] Epoch: 37, Iter: 0, Loss: 0.27476\n",
            "=== [VAL] Epoch: 37, Iter: 39, Accuracy: 0.944 ===>\n",
            "====== Epoch 38 ======>\n",
            "[TRAIN] Epoch: 38, Iter: 0, Loss: 0.23380\n",
            "[TRAIN] Epoch: 38, Iter: 80, Loss: 0.18790\n",
            "[TRAIN] Epoch: 38, Iter: 160, Loss: 0.24840\n",
            "[TRAIN] Epoch: 38, Iter: 240, Loss: 0.26615\n",
            "[TRAIN] Epoch: 38, Iter: 320, Loss: 0.19292\n",
            "== [TRAIN] Epoch: 38, Accuracy: 0.923 ==>\n",
            "[VAL] Epoch: 38, Iter: 0, Loss: 0.26179\n",
            "=== [VAL] Epoch: 38, Iter: 39, Accuracy: 0.952 ===>\n",
            "====== Epoch 39 ======>\n",
            "[TRAIN] Epoch: 39, Iter: 0, Loss: 0.25199\n",
            "[TRAIN] Epoch: 39, Iter: 80, Loss: 0.23839\n",
            "[TRAIN] Epoch: 39, Iter: 160, Loss: 0.22667\n",
            "[TRAIN] Epoch: 39, Iter: 240, Loss: 0.21263\n",
            "[TRAIN] Epoch: 39, Iter: 320, Loss: 0.25308\n",
            "== [TRAIN] Epoch: 39, Accuracy: 0.927 ==>\n",
            "[VAL] Epoch: 39, Iter: 0, Loss: 0.26247\n",
            "=== [VAL] Epoch: 39, Iter: 39, Accuracy: 0.943 ===>\n",
            "[TEST] Epoch: 39, Iter: 0, Loss: 0.72231\n",
            "=== [TEST] Epoch: 39, Iter: 78, Accuracy: 0.764 ===>\n",
            "===== Best validation Accuracy: 0.952 =====>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "lHPh86lKX4Nb",
        "outputId": "6e52fa02-9588-4058-aa5a-191a6a591598"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/IFT6135-2025-First-Assignment/HW1_2025/assignment1_release'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat(df_all_resnet).to_csv('df_resnet18_five_lr.csv')"
      ],
      "metadata": {
        "id": "KvSrAUlOXYhX"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WyYaeuFQBNN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example to run MLP with 15 epochs\n",
        "config = Arguments(model='mlpmixer',\n",
        "                   model_config='/content/IFT6135-2025-First-Assignment/HW1_2025/assignment1_release/model_configs/mlpmixer.json',\n",
        "                   epochs=2, logdir=\"exps/mlpmixer\")\n",
        "main_entry(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNCWBaethidT",
        "outputId": "bc0dfbc7-dd25-41ea-e81a-fc357b46fbf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Build model MLPMIXER...\n",
            "Loading model config from /content/IFT6135-2025-First-Assignment/HW1_2025/assignment1_release/model_configs/mlpmixer.json\n",
            "########## MLPMIXER CONFIG ################\n",
            "num_classes:\t10\n",
            "img_size:\t32\n",
            "patch_size:\t4\n",
            "embed_dim:\t256\n",
            "num_blocks:\t4\n",
            "drop_rate:\t0.0\n",
            "activation:\tgelu\n",
            "############################################\n",
            "Initialized MLPMIXER model with 2188298 total parameters, of which 2188298 are learnable.\n",
            "====== Epoch 0 ======>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN] Epoch: 0, Iter: 0, Loss: 2.31901\n",
            "[TRAIN] Epoch: 0, Iter: 80, Loss: 1.57623\n",
            "[TRAIN] Epoch: 0, Iter: 160, Loss: 1.61766\n",
            "[TRAIN] Epoch: 0, Iter: 240, Loss: 1.41238\n",
            "[TRAIN] Epoch: 0, Iter: 320, Loss: 1.47204\n",
            "== [TRAIN] Epoch: 0, Accuracy: 0.421 ==>\n",
            "[VAL] Epoch: 0, Iter: 0, Loss: 1.39669\n",
            "=== [VAL] Epoch: 0, Iter: 39, Accuracy: 0.522 ===>\n",
            "====== Epoch 1 ======>\n",
            "[TRAIN] Epoch: 1, Iter: 0, Loss: 1.21684\n",
            "[TRAIN] Epoch: 1, Iter: 80, Loss: 1.32808\n",
            "[TRAIN] Epoch: 1, Iter: 160, Loss: 1.19022\n",
            "[TRAIN] Epoch: 1, Iter: 240, Loss: 1.21163\n",
            "[TRAIN] Epoch: 1, Iter: 320, Loss: 1.03568\n",
            "== [TRAIN] Epoch: 1, Accuracy: 0.561 ==>\n",
            "[VAL] Epoch: 1, Iter: 0, Loss: 1.21091\n",
            "=== [VAL] Epoch: 1, Iter: 39, Accuracy: 0.610 ===>\n",
            "[TEST] Epoch: 1, Iter: 0, Loss: 1.00693\n",
            "=== [TEST] Epoch: 1, Iter: 78, Accuracy: 0.599 ===>\n",
            "===== Best validation Accuracy: 0.610 =====>\n",
            "Writing training logs to exps/mlpmixer...\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2 (default, Feb 26 2020, 14:31:49) \n[GCC 6.3.0 20170516]"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "vscode": {
      "interpreter": {
        "hash": "81c564fb939afe7b3f114d194e01dc23538f9aaa81b9a9b61cd5d8751a87bdce"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}